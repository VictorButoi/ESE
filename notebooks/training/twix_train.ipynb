{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b121a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Imports\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('/storage/vbutoi/projects')\n",
    "sys.path.append('/storage/vbutoi/libraries')\n",
    "sys.path.append('/storage/vbutoi/projects/ESE')\n",
    "sys.path.append('/storage/vbutoi/projects/UniverSeg')\n",
    "\n",
    "# Regular schema dictates that we put DATAPATH\n",
    "os.environ['DATAPATH'] = ':'.join((\n",
    "       '/storage/vbutoi/datasets',\n",
    "))\n",
    "os.environ['WANDB_NOTEBOOK_NAME'] = 'train.ipynb'\n",
    "\n",
    "%load_ext yamlmagic\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933335cf",
   "metadata": {},
   "source": [
    "## Define said jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed8ce121",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            require(\n                [\n                    \"notebook/js/codecell\",\n                    \"codemirror/mode/yaml/yaml\"\n                ],\n                function(cc){\n                    cc.CodeCell.options_default.highlight_modes.magic_yaml = {\n                        reg: [\"^%%yaml\"]\n                    }\n                }\n            );\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%yaml default_cfg \n",
    "\n",
    "experiment:\n",
    "  seed: 42\n",
    "    \n",
    "dataloader:\n",
    "  batch_size: 8 \n",
    "  num_workers: 1\n",
    "  pin_memory: True \n",
    "\n",
    "optim: \n",
    "  _class: torch.optim.Adam\n",
    "  lr: 3.0e-4\n",
    "  weight_decay: 0.0 \n",
    "  \n",
    "train:\n",
    "  epochs: 1000 \n",
    "  eval_freq: 5 \n",
    "  # pretrained_dir: None # In case we want to load a pretrained model.\n",
    "\n",
    "log:\n",
    "  checkpoint_freq: 20 \n",
    "  root: '?'\n",
    "  metrics:\n",
    "    dice_score:\n",
    "      _fn: ionpy.metrics.dice_score\n",
    "      from_logits: True\n",
    "      batch_reduction: 'mean' \n",
    "      ignore_empty_labels: True \n",
    "      ignore_index: 0 # Ignore background class when reporting.\n",
    "\n",
    "######################\n",
    "# Cross-Entropy Loss #\n",
    "######################\n",
    "# loss_func: \n",
    "#   _class: ionpy.loss.PixelCELoss\n",
    "#   from_logits: True\n",
    "#   batch_reduction: 'mean' \n",
    "  \n",
    "#############\n",
    "# Dice Loss #\n",
    "#############\n",
    "loss_func: \n",
    "  _class: ionpy.loss.SoftDiceLoss\n",
    "  from_logits: True\n",
    "  batch_reduction: 'mean' \n",
    "  ignore_empty_labels: True \n",
    "  ignore_index: 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2ac20c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            require(\n                [\n                    \"notebook/js/codecell\",\n                    \"codemirror/mode/yaml/yaml\"\n                ],\n                function(cc){\n                    cc.CodeCell.options_default.highlight_modes.magic_yaml = {\n                        reg: [\"^%%yaml\"]\n                    }\n                }\n            );\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%yaml model_cfg  \n",
    "\n",
    "model:\n",
    "  _class: ese.experiment.models.UNet\n",
    "  filters: [64, 64, 64, 64, 64]\n",
    "  convs_per_block: 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07ee95bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            require(\n                [\n                    \"notebook/js/codecell\",\n                    \"codemirror/mode/yaml/yaml\"\n                ],\n                function(cc){\n                    cc.CodeCell.options_default.highlight_modes.magic_yaml = {\n                        reg: [\"^%%yaml\"]\n                    }\n                }\n            );\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%yaml dataset_cfg \n",
    "\n",
    "#######\n",
    "# WMH #\n",
    "#######\n",
    "data:\n",
    "  _class: ese.experiment.datasets.WMH\n",
    "  axis: 0\n",
    "  task: Amsterdam\n",
    "  slicing: dense \n",
    "  annotator: observer_o12\n",
    "  num_slices: 1\n",
    "  in_channels: 1\n",
    "  out_channels: 2 \n",
    "  version: 0.2\n",
    "  iters_per_epoch: 1000 \n",
    "  preload: True \n",
    "\n",
    "##################\n",
    "# OASIS 4-Labels #\n",
    "##################\n",
    "# data:\n",
    "#   _class: ese.experiment.datasets.OASIS\n",
    "#   axis: 0\n",
    "#   label_set: label4\n",
    "#   slicing: central \n",
    "#   num_slices: 1\n",
    "#   in_channels: 1\n",
    "#   out_channels: 5 \n",
    "#   central_width: 32\n",
    "#   version: 0.1\n",
    "#   preload: False \n",
    "\n",
    "###################\n",
    "# OASIS 35-Labels #\n",
    "###################\n",
    "# data:\n",
    "#   _class: ese.experiment.datasets.OASIS\n",
    "#   axis: 0\n",
    "#   label_set: label35\n",
    "#   slicing: central \n",
    "#   num_slices: 1\n",
    "#   in_channels: 1\n",
    "#   out_channels: 36 \n",
    "#   central_width: 32\n",
    "#   version: 0.1\n",
    "#   preload: False \n",
    "\n",
    "##############\n",
    "# CityScapes #\n",
    "##############\n",
    "# data:\n",
    "#   _class: ese.experiment.datasets.CityScapes\n",
    "#   in_channels: 3\n",
    "#   out_channels: 35\n",
    "\n",
    "##############\n",
    "# OxfordPets #\n",
    "##############\n",
    "# data:\n",
    "#   _class: ese.experiment.datasets.OxfordPets\n",
    "#   preload: True\n",
    "#   version: 0.1\n",
    "#   num_classes: all \n",
    "#   in_channels: 3\n",
    "#   out_channels: 38 # 37 + 1 (background)\n",
    "\n",
    "#####################\n",
    "# Binary OxfordPets #\n",
    "#####################\n",
    "# data:\n",
    "#   _class: ese.experiment.datasets.BinaryPets\n",
    "#   preload: True\n",
    "#   version: 0.1\n",
    "#   in_channels: 3\n",
    "#   out_channels: 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "289c8e7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            require(\n                [\n                    \"notebook/js/codecell\",\n                    \"codemirror/mode/yaml/yaml\"\n                ],\n                function(cc){\n                    cc.CodeCell.options_default.highlight_modes.magic_yaml = {\n                        reg: [\"^%%yaml\"]\n                    }\n                }\n            );\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%yaml lite_aug_cfg\n",
    "\n",
    "- RandomVariableElasticTransform:\n",
    "    p: 0.5\n",
    "    alpha: [1, 2] \n",
    "    sigma: [8, 10]\n",
    "- RandomHorizontalFlip:\n",
    "    p: 0.5\n",
    "- RandomVerticalFlip:\n",
    "    p: 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01c7ad0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            require(\n                [\n                    \"notebook/js/codecell\",\n                    \"codemirror/mode/yaml/yaml\"\n                ],\n                function(cc){\n                    cc.CodeCell.options_default.highlight_modes.magic_yaml = {\n                        reg: [\"^%%yaml\"]\n                    }\n                }\n            );\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%yaml callbacks_cfg\n",
    "\n",
    "callbacks:\n",
    "  step:\n",
    "    - ese.experiment.callbacks.ShowPredictions\n",
    "  epoch:\n",
    "    - ese.experiment.callbacks.WandbLogger\n",
    "    - ionpy.callbacks.ETA\n",
    "    - ionpy.callbacks.JobProgress\n",
    "    - ionpy.callbacks.TerminateOnNaN\n",
    "    - ionpy.callbacks.PrintLogged\n",
    "    - ionpy.callbacks.ModelCheckpoint:\n",
    "        monitor: dice_score\n",
    "        phase: val"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b506f2fe",
   "metadata": {},
   "source": [
    "## Debug Station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f4270fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup direcrtories\n",
    "train_root = '/storage/vbutoi/scratch/ESE/training'\n",
    "\n",
    "# WMH CONFIG\n",
    "exp_name = '01_04_24_WMH_AugEnsemble'\n",
    "mod_filters = [64, 64, 64, 64, 64]\n",
    "dl_bs = 8\n",
    "wmh_params = {\n",
    "    'log.metrics.dice_score.ignore_empty_labels': [False], # Set False for WMH, True otherwise.\n",
    "    'loss_func.ignore_empty_labels': [False], # Set False for WMH, True otherwise. USE FOR DICE\n",
    "}\n",
    "\n",
    "# BINARY PETS CONFIG\n",
    "# exp_name = '11_20_23_BinaryPets_CrossEntropy'\n",
    "# mod_filters = [64, 64, 64, 64, 64]\n",
    "# dl_bs = 8\n",
    "\n",
    "# OASIS 4-Label CONFIG\n",
    "# exp_name = '11_20_23_OASIS4_CrossEntropy'\n",
    "# mod_filters = [64, 64, 64, 64, 64]\n",
    "# dl_bs = 8\n",
    "\n",
    "# OASIS 35-Label CONFIG\n",
    "# exp_name = '11_20_23_OASIS35_CrossEntropy'\n",
    "# mod_filters = [64, 64, 64, 64, 64]\n",
    "# dl_bs = 8\n",
    "\n",
    "# CityScapes CONFIG\n",
    "# exp_name = '11_20_23_CityScapes_CrossEntropy'\n",
    "# mod_filters = [64, 64, 64, 64, 64]\n",
    "# dl_bs = 8\n",
    "\n",
    "# Setup the root.\n",
    "exp_root = f'{train_root}/{exp_name}'\n",
    "\n",
    "# Create the ablation options\n",
    "option_set = [\n",
    "    {\n",
    "        'experiment.seed': [40, 41, 42, 43],\n",
    "        'log.root': [exp_root],\n",
    "    }\n",
    "]\n",
    "# Update with Dataset Specific Parameters\n",
    "for option_dict in option_set:\n",
    "    option_dict.update(wmh_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0e2e8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from ionpy.util import Config\n",
    "from ionpy.util.config import check_missing\n",
    "from ese.scripts.utils import get_option_product\n",
    "\n",
    "# Assemble base config\n",
    "base_cfg = Config(default_cfg).update([model_cfg, dataset_cfg, callbacks_cfg])\n",
    "\n",
    "# Set the augmentation\n",
    "light_augmentations = sum([copy.deepcopy(lite_aug_cfg)], start=[])\n",
    "\n",
    "# Get the configs\n",
    "raw_cfgs = get_option_product(exp_name, option_set, base_cfg)\n",
    "\n",
    "cfgs = []\n",
    "for cfg in raw_cfgs:\n",
    "    cfg = cfg.set('augmentations', light_augmentations)\n",
    "    check_missing(cfg) # Verify there are no ? in config.\n",
    "    cfgs.append(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7904470",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cfgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2225fe62",
   "metadata": {},
   "source": [
    "## Running Jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbdcf3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ######## FOR DEBUGGING\n",
    "# from ese.experiment.experiment import run_ese_exp, CalibrationExperiment\n",
    "\n",
    "# run_ese_exp(\n",
    "#     config=cfgs[0], \n",
    "#     experiment_class=CalibrationExperiment,\n",
    "#     gpu='0',\n",
    "#     run_name='debug',\n",
    "#     show_examples=False,\n",
    "#     track_wandb=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05938b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initalized SliteRunner\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted job id: 338404.\n"
     ]
    }
   ],
   "source": [
    "# FOR SUBMISSION\n",
    "from ese.experiment.experiment import submit_ese_exps, CalibrationExperiment \n",
    "\n",
    "submit_ese_exps(\n",
    "    exp_root=exp_root,\n",
    "    experiment_class=CalibrationExperiment,\n",
    "    config_list=[cfgs[0]],\n",
    "    available_gpus=['1'],\n",
    "    track_wandb=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30bf2830",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage/vbutoi/projects/ionpy/util/libcheck.py:57: UserWarning: Using slow Pillow instead of Pillow-SIMD\n",
      "  warn(\"Using slow Pillow instead of Pillow-SIMD\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running CalibrationExperiment(\"/storage/vbutoi/scratch/ESE/training/debug/20240104_135747-PFNH-543820e5dcdbc1a4b51974a56cf416f5\")\n",
      "---\n",
      "augmentations:\n",
      "- RandomVariableElasticTransform:\n",
      "    alpha:\n",
      "    - 1\n",
      "    - 2\n",
      "    p: 0.5\n",
      "    sigma:\n",
      "    - 8\n",
      "    - 10\n",
      "- RandomHorizontalFlip:\n",
      "    p: 0.5\n",
      "- RandomVerticalFlip:\n",
      "    p: 0.5\n",
      "callbacks:\n",
      "  epoch:\n",
      "  - ese.experiment.callbacks.WandbLogger\n",
      "  - ionpy.callbacks.ETA\n",
      "  - ionpy.callbacks.JobProgress\n",
      "  - ionpy.callbacks.TerminateOnNaN\n",
      "  - ionpy.callbacks.PrintLogged\n",
      "  - ionpy.callbacks.ModelCheckpoint:\n",
      "      monitor: dice_score\n",
      "      phase: val\n",
      "data:\n",
      "  _class: ese.experiment.datasets.WMH\n",
      "  annotator: observer_o12\n",
      "  axis: 0\n",
      "  iters_per_epoch: 1000\n",
      "  num_slices: 1\n",
      "  preload: true\n",
      "  slicing: dense\n",
      "  task: Amsterdam\n",
      "  version: 0.2\n",
      "dataloader:\n",
      "  batch_size: 8\n",
      "  num_workers: 1\n",
      "  pin_memory: true\n",
      "experiment:\n",
      "  seed: 40\n",
      "log:\n",
      "  checkpoint_freq: 20\n",
      "  metrics:\n",
      "    dice_score:\n",
      "      _fn: ionpy.metrics.dice_score\n",
      "      batch_reduction: mean\n",
      "      from_logits: true\n",
      "      ignore_empty_labels: false\n",
      "      ignore_index: 0\n",
      "  root: /storage/vbutoi/scratch/ESE/training/debug\n",
      "  wandb_string: exp_name:01_04_24_WMH_AugEnsemble-seed:40-filters:[64,64,64,64,64]-ignore_empty_labels:False-ignore_empty_labels:False\n",
      "loss_func:\n",
      "  _class: ionpy.loss.SoftDiceLoss\n",
      "  batch_reduction: mean\n",
      "  from_logits: true\n",
      "  ignore_empty_labels: false\n",
      "  ignore_index: 0\n",
      "model:\n",
      "  _class: ese.experiment.models.UNet\n",
      "  convs_per_block: 3\n",
      "  filters:\n",
      "  - 64\n",
      "  - 64\n",
      "  - 64\n",
      "  - 64\n",
      "  - 64\n",
      "  in_channels: 1\n",
      "  out_channels: 2\n",
      "optim:\n",
      "  _class: torch.optim.Adam\n",
      "  lr: 0.0003\n",
      "  weight_decay: 0.0\n",
      "train:\n",
      "  epochs: 1000\n",
      "  eval_freq: 5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find train.ipynb.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvbutoi\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/storage/vbutoi/scratch/ESE/training/debug/wandb/run-20240104_135837-zag52s2w</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/vbutoi/SemanticCalibration/runs/zag52s2w' target=\"_blank\">solar-dust-386</a></strong> to <a href='https://wandb.ai/vbutoi/SemanticCalibration' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/vbutoi/SemanticCalibration' target=\"_blank\">https://wandb.ai/vbutoi/SemanticCalibration</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/vbutoi/SemanticCalibration/runs/zag52s2w' target=\"_blank\">https://wandb.ai/vbutoi/SemanticCalibration/runs/zag52s2w</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/vbutoi/envs/UniverSegTF/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/conda/conda-bld/pytorch_1670525539683/work/aten/src/ATen/native/TensorShape.cpp:3190.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpointing with tag:last at epoch:0\n",
      "ETA (0/999): 2024-01-04 13:59:13 - 00:00:00 remaining\n",
      "Logged @ Epoch 0\n",
      "metric         train       val\n",
      "----------  --------  --------\n",
      "dice_score  0.167379  0.325349\n",
      "loss        0.799555  0.626772\n",
      "Checkpointing with tag:max-val-dice_score at epoch:0\n",
      "Start epoch 1\n",
      "ETA (1/999): 2024-01-04 19:40:19 - 05:40:45 remaining\n",
      "Logged @ Epoch 1\n",
      "metric         train\n",
      "----------  --------\n",
      "dice_score  0.358116\n",
      "loss        0.593157\n",
      "Start epoch 2\n",
      "ETA (2/999): 2024-01-04 19:39:21 - 05:39:27 remaining\n",
      "Logged @ Epoch 2\n",
      "metric         train\n",
      "----------  --------\n",
      "dice_score  0.453615\n",
      "loss        0.498473\n",
      "Start epoch 3\n",
      "ETA (3/999): 2024-01-04 19:39:15 - 05:39:00 remaining\n",
      "Logged @ Epoch 3\n",
      "metric         train\n",
      "----------  --------\n",
      "dice_score  0.494633\n",
      "loss        0.466475\n",
      "Start epoch 4\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m######## FOR DEBUGGING\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mese\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperiment\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperiment\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m run_ese_exp, CalibrationExperiment\n\u001b[0;32m----> 4\u001b[0m \u001b[43mrun_ese_exp\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfgs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexperiment_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCalibrationExperiment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgpu\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m0\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdebug\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshow_examples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrack_wandb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     11\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/envs/UniverSegTF/lib/python3.9/site-packages/pydantic/decorator.py:40\u001b[0m, in \u001b[0;36mpydantic.decorator.validate_arguments.validate.wrapper_function\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/envs/UniverSegTF/lib/python3.9/site-packages/pydantic/decorator.py:134\u001b[0m, in \u001b[0;36mpydantic.decorator.ValidatedFunction.call\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/envs/UniverSegTF/lib/python3.9/site-packages/pydantic/decorator.py:206\u001b[0m, in \u001b[0;36mpydantic.decorator.ValidatedFunction.execute\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/storage/vbutoi/projects/ESE/ese/experiment/experiment/runner.py:37\u001b[0m, in \u001b[0;36mrun_ese_exp\u001b[0;34m(config, experiment_class, gpu, run_name, show_examples, track_wandb)\u001b[0m\n\u001b[1;32m     34\u001b[0m     cfg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mremove(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mese.experiment.callbacks.WandbLogger\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# Run the experiment.\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m \u001b[43mslite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_exp\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexperiment_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_object\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mConfig\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgpu\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgpu\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/envs/UniverSegTF/lib/python3.9/site-packages/pydantic/decorator.py:40\u001b[0m, in \u001b[0;36mpydantic.decorator.validate_arguments.validate.wrapper_function\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/envs/UniverSegTF/lib/python3.9/site-packages/pydantic/decorator.py:134\u001b[0m, in \u001b[0;36mpydantic.decorator.ValidatedFunction.call\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/envs/UniverSegTF/lib/python3.9/site-packages/pydantic/decorator.py:206\u001b[0m, in \u001b[0;36mpydantic.decorator.ValidatedFunction.execute\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/storage/vbutoi/projects/ionpy/slite/runner.py:33\u001b[0m, in \u001b[0;36mrun_exp\u001b[0;34m(exp_class, exp_object, gpu)\u001b[0m\n\u001b[1;32m     30\u001b[0m     exp \u001b[38;5;241m=\u001b[39m exp_class(exp_object)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Run the experiment.\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m \u001b[43mexp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/storage/vbutoi/projects/ESE/ese/experiment/experiment/ese_exp.py:149\u001b[0m, in \u001b[0;36mCalibrationExperiment.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 149\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/storage/vbutoi/projects/ionpy/experiment/train.py:177\u001b[0m, in \u001b[0;36mTrainExperiment.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStart epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_epoch \u001b[38;5;241m=\u001b[39m epoch\n\u001b[0;32m--> 177\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_phase\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m eval_freq \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m (epoch \u001b[38;5;241m%\u001b[39m eval_freq \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m epoch \u001b[38;5;241m==\u001b[39m epochs \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_phase(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m\"\u001b[39m, epoch)\n",
      "File \u001b[0;32m/storage/vbutoi/projects/ionpy/experiment/train.py:212\u001b[0m, in \u001b[0;36mTrainExperiment.run_phase\u001b[0;34m(self, phase, epoch)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dl):\n\u001b[1;32m    204\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_step(\n\u001b[1;32m    205\u001b[0m         batch_idx\u001b[38;5;241m=\u001b[39mbatch_idx,\n\u001b[1;32m    206\u001b[0m         batch\u001b[38;5;241m=\u001b[39mbatch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    210\u001b[0m         phase\u001b[38;5;241m=\u001b[39mphase\n\u001b[1;32m    211\u001b[0m     )\n\u001b[0;32m--> 212\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    213\u001b[0m     meters\u001b[38;5;241m.\u001b[39mupdate(metrics)\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_callbacks(\n\u001b[1;32m    215\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m    216\u001b[0m         epoch\u001b[38;5;241m=\u001b[39mepoch, \n\u001b[1;32m    217\u001b[0m         batch_idx\u001b[38;5;241m=\u001b[39mbatch_idx, \n\u001b[1;32m    218\u001b[0m         phase\u001b[38;5;241m=\u001b[39mphase\n\u001b[1;32m    219\u001b[0m     )\n",
      "File \u001b[0;32m/storage/vbutoi/projects/ionpy/experiment/train.py:242\u001b[0m, in \u001b[0;36mTrainExperiment.compute_metrics\u001b[0;34m(self, outputs)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_metrics\u001b[39m(\u001b[38;5;28mself\u001b[39m, outputs):\n\u001b[0;32m--> 242\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43moutputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mloss\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m}\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m name, fn \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetric_fns\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    244\u001b[0m         value \u001b[38;5;241m=\u001b[39m fn(outputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mypred\u001b[39m\u001b[38;5;124m\"\u001b[39m], outputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mytrue\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "######## FOR DEBUGGING\n",
    "from ese.experiment.experiment import run_ese_exp, CalibrationExperiment\n",
    "\n",
    "run_ese_exp(\n",
    "    config=cfgs[0], \n",
    "    experiment_class=CalibrationExperiment,\n",
    "    gpu='0',\n",
    "    run_name='debug',\n",
    "    show_examples=False,\n",
    "    track_wandb=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UniverSegTF",
   "language": "python",
   "name": "universegtf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
