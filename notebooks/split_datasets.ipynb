{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_integer(s):\n",
    "    try:\n",
    "        int(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = pathlib.Path(\"/storage/vbutoi/datasets/WMH\")\n",
    "splits = [\"training\", \"test\", \"additional_annotations\"]\n",
    "\n",
    "all_dirs = []\n",
    "\n",
    "for split in splits:\n",
    "    split_path = root / split\n",
    "    for subdir in split_path.iterdir():\n",
    "        print(subdir)\n",
    "        all_dirs.append(subdir)\n",
    "        for l3_dir in subdir.iterdir():\n",
    "            if not is_integer(str(l3_dir.name)):\n",
    "                print(l3_dir)\n",
    "                all_dirs.append(l3_dir)\n",
    "                for l4_dir in l3_dir.iterdir():\n",
    "                    if not is_integer(str(l4_dir.name)):\n",
    "                        print(l4_dir)\n",
    "                        all_dirs.append(l4_dir)\n",
    "                        for l5_dir in l4_dir.iterdir():\n",
    "                            if not is_integer(str(l5_dir.name)):\n",
    "                                print(l5_dir)\n",
    "                                all_dirs.append(l5_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_dirs = []\n",
    "for path in all_dirs:\n",
    "    all_other_dirs = [p for p in all_dirs if p != path]\n",
    "    is_subdir = False\n",
    "    for other_path in all_other_dirs:\n",
    "        if path in other_path.parents:\n",
    "            is_subdir = True\n",
    "            break\n",
    "    if not is_subdir:\n",
    "        unique_dirs.append(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import nibabel.processing as nip\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "def resample_nib(img, voxel_spacing=(1, 1, 1), order=3):\n",
    "    \"\"\"Resamples the nifti from its original spacing to another specified spacing\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    img: nibabel image\n",
    "    voxel_spacing: a tuple of 3 integers specifying the desired new spacing\n",
    "    order: the order of interpolation\n",
    "    \n",
    "    Returns:\n",
    "    ----------\n",
    "    new_img: The resampled nibabel image \n",
    "    \n",
    "    \"\"\"\n",
    "    # resample to new voxel spacing based on the current x-y-z-orientation\n",
    "    aff = img.affine\n",
    "    shp = img.shape\n",
    "    zms = img.header.get_zooms()\n",
    "    # Calculate new shape\n",
    "    new_shp = tuple(np.rint([\n",
    "        shp[0] * zms[0] / voxel_spacing[0],\n",
    "        shp[1] * zms[1] / voxel_spacing[1],\n",
    "        shp[2] * zms[2] / voxel_spacing[2]\n",
    "        ]).astype(int))\n",
    "    new_aff = nib.affines.rescale_affine(aff, shp, voxel_spacing, new_shp)\n",
    "    new_img = nip.resample_from_to(img, (new_shp, new_aff), order=order, cval=-1024)\n",
    "    return new_img\n",
    "\n",
    "\n",
    "def resample_mask_to(msk, to_img):\n",
    "    \"\"\"Resamples the nifti mask from its original spacing to a new spacing specified by its corresponding image\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    msk: The nibabel nifti mask to be resampled\n",
    "    to_img: The nibabel image that acts as a template for resampling\n",
    "    \n",
    "    Returns:\n",
    "    ----------\n",
    "    new_msk: The resampled nibabel mask \n",
    "    \n",
    "    \"\"\"\n",
    "    to_img.header['bitpix'] = 8\n",
    "    to_img.header['datatype'] = 2  # uint8\n",
    "    new_msk = nib.processing.resample_from_to(msk, to_img, order=0)\n",
    "    return new_msk\n",
    "\n",
    "\n",
    "def pad_image_numpy(image_array, target_width, target_height):\n",
    "    # Convert the NumPy array to a Pillow image\n",
    "    original_image = Image.fromarray(image_array)\n",
    "\n",
    "    # Get the original dimensions\n",
    "    original_width, original_height = original_image.size\n",
    "\n",
    "    # Calculate the amount of padding needed\n",
    "    width_padding = target_width - original_width\n",
    "    height_padding = target_height - original_height\n",
    "\n",
    "    # Calculate the padding borders\n",
    "    left_padding = width_padding // 2\n",
    "    right_padding = width_padding - left_padding\n",
    "    top_padding = height_padding // 2\n",
    "    bottom_padding = height_padding - top_padding\n",
    "\n",
    "    # Get the border pixel value\n",
    "    border_pixel = original_image.getpixel((10, 10))\n",
    "\n",
    "    # Create a new image with the desired dimensions and fill with border pixel\n",
    "    padded_image = Image.new(original_image.mode, (target_width, target_height), border_pixel)\n",
    "\n",
    "    # Paste the original image onto the padded image with padding borders\n",
    "    padded_image.paste(original_image, (left_padding, top_padding))\n",
    "\n",
    "    # Convert the padded image back to a NumPy array\n",
    "    padded_image_array = np.array(padded_image)\n",
    "\n",
    "    return padded_image_array\n",
    "\n",
    "def normalize_image(image):\n",
    "    # Convert the image to floating point format\n",
    "    image = image.astype(np.float32)\n",
    "\n",
    "    # Normalize the image between 0 and 1\n",
    "    normalized_image = (image - np.min(image)) / (np.max(image) - np.min(image))\n",
    "    \n",
    "    return normalized_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def proc_WMH(data_dirs, modalities, show=False):\n",
    "    proc_root = pathlib.Path(\"/storage/vbutoi/datasets/WMH/processed\") \n",
    "    for ud in data_dirs:\n",
    "        split_args = str(ud).split(\"/\")\n",
    "        split = split_args[-3]\n",
    "        datacenter = split_args[-2]\n",
    "        modality = split_args[-1]\n",
    "        print(split, datacenter, modality)\n",
    "        for subj in ud.iterdir():\n",
    "            for axis in [0, 1, 2]:\n",
    "                \n",
    "                final_res = [256, 256]\n",
    "                \n",
    "                image_dict = {}\n",
    "                # Get the slices for each modality.\n",
    "                for mod_idx, modality in enumerate(modalities):\n",
    "                    image_dir = subj / pathlib.Path(f\"pre/{modality}.nii.gz\")\n",
    "                    img_volume = resample_nib(nib.load(image_dir))\n",
    "                    mid_axis_slice = img_volume.get_fdata().shape[axis] // 2 \n",
    "                    img_modality_slice = np.take(img_volume.get_fdata(), mid_axis_slice, axis=axis)\n",
    "                    \n",
    "                    # Normalize percentile\n",
    "                    lower = np.percentile(img_modality_slice[img_modality_slice>0], q=0.5)\n",
    "                    upper = np.percentile(img_modality_slice[img_modality_slice>0], q=99.5)\n",
    "                    clipped_image = np.clip(img_modality_slice, a_min=lower, a_max=upper)\n",
    "\n",
    "                    # Make the image square\n",
    "                    sqr_img = pad_image_numpy(clipped_image, 256, 256)\n",
    "\n",
    "                    # Normalize the now square image\n",
    "                    norm_img = normalize_image(sqr_img)\n",
    "            \n",
    "                    image_dict[modality] = norm_img \n",
    "\n",
    "                # Get the label slice\n",
    "                seg_dir = subj / \"wmh.nii.gz\"\n",
    "                seg = resample_mask_to(nib.load(seg_dir), img_volume)\n",
    "                seg_slice = np.take(seg.get_fdata(), mid_axis_slice, axis=axis)\n",
    "                binary_seg_slice = np.uint8(seg_slice == 1)\n",
    "                sqr_seg = pad_image_numpy(binary_seg_slice, 256, 256)\n",
    "                image_dict[\"seg\"] = seg\n",
    "                \n",
    "                if show:\n",
    "                    # Plot the slices\n",
    "                    f, axarr = plt.subplots(1, len(modalities) + 1, figsize=(5 * (len(modalities) + 1), 5))\n",
    "                    im = axarr[0].imshow(sqr_seg)\n",
    "                    axarr[0].set_title(\"Label\")\n",
    "                    f.colorbar(im, ax=axarr[0], orientation='vertical') \n",
    "                    for mod_idx, modality in enumerate(modalities):\n",
    "                        im = axarr[mod_idx + 1].imshow(image_dict[modality])\n",
    "                        axarr[mod_idx + 1].set_title(modality)\n",
    "                        f.colorbar(im, ax=axarr[mod_idx + 1], orientation='vertical')\n",
    "                    plt.show()  \n",
    "\n",
    "            print(seg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_WMH(unique_dirs, modalities=[\"FLAIR\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thunderpack import ThunderDB\n",
    "\n",
    "def thunderify_WMH(datacenter, modality, version=0.1):\n",
    "\n",
    "    source_dir = pathlib.Path(\"/storage/vbutoi/datasets/WMH/thunder\")\n",
    "    with ThunderDB.open(source_dir + 'data', 'c') as db:\n",
    "        db['metadata'] = {\n",
    "            'version': version, \n",
    "            'n_samples': None\n",
    "        }\n",
    "        \n",
    "        keys = []\n",
    "        for i in range(100):\n",
    "            key = f'sample{i:02d}'\n",
    "            x = np.random.normal(size=(128,128))\n",
    "            y = np.random.normal(size=(128,128))\n",
    "            # Thunderpack will serialize the tuple and numpy arrays automatically\n",
    "            db[key] = (x, y) \n",
    "            keys.append(key)\n",
    "\n",
    "        db['samples'] = keys"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SAM",
   "language": "python",
   "name": "sam"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
