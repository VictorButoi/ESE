{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook is all about really crunnching when we have an image what we would 'like' to be\n",
    "# called calibrated and not. Basically, what averages will we be happy with, and which will we not.\n",
    "from ese.experiment.metrics.calibration.pixelwise import TL_ECE\n",
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Bad half-boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's make the ground truth, which is a 10x10 tensor with a white square in the middle\n",
    "# we will slice off the right side of the square to make our contradiction.\n",
    "ground_truth1 = torch.zeros(10, 10)\n",
    "ground_truth1[3:7, 3:7] = 1\n",
    "ground_truth1[3:7, 6] = 0\n",
    "ground_truth1[3, 4:7] = 0\n",
    "\n",
    "plt.imshow(ground_truth1, cmap='gray')  \n",
    "plt.title('Ground Truth 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's now make some predictions that we want to break the ECE metric.\n",
    "# The way we do this is by making predictions in the same bin have wildly different accuracies.\n",
    "# First we make a confidence map where the boundary of the square is 0.6 and the middle is 0.1\n",
    "# and the rest if 0\n",
    "fore_conf_map1= torch.zeros(10, 10)\n",
    "fore_conf_map1[3:7, 3:7] = 0.5\n",
    "fore_conf_map1[4:6, 4:6] = 1.0\n",
    "back_conf_map1 = 1 - fore_conf_map1\n",
    "chann_conf_map1 = torch.stack([back_conf_map1, fore_conf_map1], dim=0)\n",
    "# Get the argmax\n",
    "conf_map1 = torch.max(chann_conf_map1, dim=0).values\n",
    "\n",
    "plt.imshow(fore_conf_map1, vmin=0, vmax=1, cmap='gray')\n",
    "plt.colorbar(label=\"Confidence\")\n",
    "plt.title(\"Confidence Map 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we adversarily make our pred predict exactly half of the 0.5 area correctly (the top left) and the other half incorrectly (the bottom right).\n",
    "pred_map1 = torch.argmax(chann_conf_map1, dim=0)\n",
    "\n",
    "plt.imshow(pred_map1, cmap='gray')\n",
    "plt.title(\"Prediction Map 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paradoxically, this will have an ECE of 0!\n",
    "cal_err = TL_ECE(\n",
    "    num_bins=10,\n",
    "    pred_map=pred_map1,\n",
    "    conf_map=conf_map1,\n",
    "    label_map=ground_truth1\n",
    ")[\"cal_score\"]\n",
    "print(\"ECE: \", cal_err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I would actually argue this is a bad adversary because this is what calibration is meant to do, half of the pixels at the border are correct and half are wrong... thus 0.5. But it IS illustrative of a different problem, that is that different parts of the image and somehow compensate for each other. For example, working still with one object, consider the following example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: A Boundary Case ... Literally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's make the ground truth, which is a 10x10 tensor with a white square in the middle\n",
    "# we will slice off the right side of the square to make our contradiction.\n",
    "ground_truth2 = torch.zeros(10, 10)\n",
    "ground_truth2[2:8, 2:8] = 1\n",
    "\n",
    "plt.imshow(ground_truth2, cmap='gray')  \n",
    "plt.title('Ground Truth 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's now make some predictions that we want to break the ECE metric.\n",
    "# The way we do this is by making predictions in the same bin have wildly different accuracies.\n",
    "# First we make a confidence map where the boundary of the square is 0.6 and the middle is 0.1\n",
    "# and the rest if 0\n",
    "fore_conf_map2 = torch.zeros(10, 10)\n",
    "fore_conf_map2[1:9, 1:9] = 0.5\n",
    "fore_conf_map2[3:7, 3:7] = 1 \n",
    "fore_conf_map2[3, 3:7] = 0.5\n",
    "fore_conf_map2[6, 3:7] = 0.5\n",
    "\n",
    "back_conf_map2 = 1 - fore_conf_map2\n",
    "chann_conf_map2 = torch.stack([back_conf_map2, fore_conf_map2], dim=0)\n",
    "# Get the argmax\n",
    "conf_map2 = torch.max(chann_conf_map2, dim=0).values\n",
    "\n",
    "plt.imshow(fore_conf_map2, vmin=0, vmax=1, cmap='gray')\n",
    "plt.colorbar(label=\"Confidence\")\n",
    "plt.title(\"Confidence Map 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we adversarily make our pred predict exactly half of the 0.5 area correctly (the top left) and the other half incorrectly (the bottom right).\n",
    "pred_map2 = torch.argmax(chann_conf_map2, dim=0)\n",
    "plt.imshow(pred_map2, cmap='gray')\n",
    "plt.title(\"Prediction Map 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paradoxically, this will have an ECE of 0!\n",
    "cal_err = TL_ECE(\n",
    "    num_bins=10,\n",
    "    pred_map=pred_map2,\n",
    "    conf_map=conf_map2,\n",
    "    label_map=ground_truth2\n",
    ")[\"cal_score\"]\n",
    "print(\"ECE: \", cal_err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here we observe a different kind of failure case. Regardless of how we choose to decide the coinflip at the label, the border of pixels can be COMPLETELY incorrect and ECE report the model is perfectly calibrated. This would be ok, except that pixels at the boundary with low confidence are significantly more likely to be wrong in comparison to pixels which are more inwards, thus this failure case means that perfectly calibrated models CAN just ignore the boundary as long as the distribution of confidence goes slightly inwards.\n",
    "\n",
    "## Maybe a way to show how much a problem this can be is we look at how the confidence changes as we go further from the boundary and the accuracy going from the boundary, if the accuracy line goes up BEFORE the confidence line then this problem can be present."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UniverSegTF",
   "language": "python",
   "name": "universegtf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
