{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the directory containing pickle files\n",
    "dir_path = '/storage/vbutoi/scratch/ESE/records/WMH_aug_runs'\n",
    "\n",
    "# List all pickle files in the directory\n",
    "pickle_files = [f for f in os.listdir(dir_path) if f.endswith('.pkl')]\n",
    "\n",
    "# Initialize an empty DataFrame\n",
    "all_logs = pd.DataFrame()\n",
    "\n",
    "# Iterate through each pickle file and append its contents to the DataFrame\n",
    "for p_file in pickle_files:\n",
    "    file_path = os.path.join(dir_path, p_file)\n",
    "    temp_df = pd.read_pickle(file_path)\n",
    "    all_logs = pd.concat([all_logs, temp_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolate the cases which have no-label and cases where there is at least some label.\n",
    "def has_label(value):\n",
    "    return (value != 0.0)\n",
    "\n",
    "# Add some new useful columns\n",
    "all_logs['has_label'] = all_logs['gt_lab_amount'].apply(has_label) \n",
    "\n",
    "def reorder_splits(df):\n",
    "    train_logs = df[df['split'] == 'train']\n",
    "    val_logs = df[df['split'] == 'val']\n",
    "    cal_logs = df[df['split'] == 'cal']\n",
    "    fixed_df = pd.concat([train_logs, val_logs, cal_logs])\n",
    "    return fixed_df\n",
    "\n",
    "# Set the rows so that it's train, val, cal\n",
    "all_logs = reorder_splits(all_logs)\n",
    "\n",
    "# Now we want to collapse the data by subject, so we can get the mean metric score for each subject.\n",
    "logs_per_subject = all_logs.groupby(['data_idx', 'cal_metric', 'bin_weighting', 'task', 'split']).agg({\n",
    "    'pred_lab_amount': 'mean',\n",
    "    'gt_lab_amount': 'mean',\n",
    "    'cal_score': 'mean',\n",
    "    'accuracy': 'mean',\n",
    "    'dice': 'mean',\n",
    "    'lab_w_accuracy': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "logs_per_subject = reorder_splits(logs_per_subject)\n",
    "\n",
    "# Group the metrics by important factors\n",
    "grouped_logs = all_logs.groupby(['task', 'cal_metric', 'split'])\n",
    "grouped_logs_per_subject = logs_per_subject.groupby(['task', 'cal_metric', 'split'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 20})  \n",
    "\n",
    "# accuracy correlation\n",
    "acc_corr = grouped_logs.apply(lambda x: x['accuracy'].corr(x['cal_score'])).reset_index(name='correlation')\n",
    "acc_corr = reorder_splits(acc_corr)\n",
    "acc_corr['eval_metric'] = 'accuracy'\n",
    "\n",
    "# dice correlations\n",
    "dice_corr = grouped_logs.apply(lambda x: x['dice'].corr(x['cal_score'])).reset_index(name='correlation')\n",
    "dice_corr = reorder_splits(dice_corr)\n",
    "dice_corr['eval_metric'] = 'dice'\n",
    "\n",
    "# Combine the two\n",
    "correlations = pd.concat([acc_corr, dice_corr])\n",
    "\n",
    "g = sns.catplot(data=correlations, \n",
    "                x=\"eval_metric\", \n",
    "                y=\"correlation\", \n",
    "                hue='cal_metric', \n",
    "                col=\"split\", \n",
    "                row=\"task\",\n",
    "                kind=\"bar\", \n",
    "                height=8, \n",
    "                aspect=1)\n",
    "# Set the y lim between - 1 and 1\n",
    "g.set(ylim=(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 25})  \n",
    "\n",
    "# Accuracy correlations \n",
    "acc_subj_correlations = grouped_logs_per_subject.apply(lambda x: x['accuracy'].corr(x['cal_score'])).reset_index(name='correlation')\n",
    "acc_subj_correlations = reorder_splits(acc_subj_correlations)\n",
    "acc_subj_correlations['eval_metric'] = 'accuracy'\n",
    "\n",
    "# Dice correlations\n",
    "dice_subject_correlations = grouped_logs_per_subject.apply(lambda x: x['dice'].corr(x['cal_score'])).reset_index(name='correlation')\n",
    "dice_subject_correlations = reorder_splits(dice_subject_correlations)\n",
    "dice_subject_correlations['eval_metric'] = 'dice'\n",
    "\n",
    "# Combine the two\n",
    "subject_correlations = pd.concat([acc_subj_correlations, dice_subject_correlations])\n",
    "\n",
    "g = sns.catplot(data=subject_correlations, \n",
    "                x=\"eval_metric\", \n",
    "                y=\"correlation\", \n",
    "                hue='cal_metric', \n",
    "                col=\"split\", \n",
    "                row=\"task\",\n",
    "                kind=\"bar\", \n",
    "                height=8, \n",
    "                aspect=1)\n",
    "# Set the y lim between - 1 and 1\n",
    "g.set(ylim=(-1, 1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UniverSegTF",
   "language": "python",
   "name": "universegtf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
