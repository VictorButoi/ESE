{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the directory containing pickle files\n",
    "dir_path = '/storage/vbutoi/scratch/ESE/records/WMH_aug_runs'\n",
    "\n",
    "# List all pickle files in the directory\n",
    "pickle_files = [f for f in os.listdir(dir_path) if f.endswith('.pkl')]\n",
    "\n",
    "# Initialize an empty DataFrame\n",
    "all_logs = pd.DataFrame()\n",
    "\n",
    "# Iterate through each pickle file and append its contents to the DataFrame\n",
    "for p_file in pickle_files:\n",
    "    file_path = os.path.join(dir_path, p_file)\n",
    "    temp_df = pd.read_pickle(file_path)\n",
    "    all_logs = pd.concat([all_logs, temp_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at the particular comparison we want to make."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolate the cases which have no-label and cases where there is at least some label.\n",
    "def has_label(value):\n",
    "    return (value != 0.0)\n",
    "\n",
    "# Add some new useful columns\n",
    "all_logs['has_label'] = all_logs['gt_lab_amount'].apply(has_label) \n",
    "\n",
    "def reorder_splits(df):\n",
    "    train_logs = df[df['split'] == 'train']\n",
    "    val_logs = df[df['split'] == 'val']\n",
    "    cal_logs = df[df['split'] == 'cal']\n",
    "    fixed_df = pd.concat([train_logs, val_logs, cal_logs])\n",
    "    return fixed_df\n",
    "\n",
    "# Set the rows so that it's train, val, cal\n",
    "all_logs = reorder_splits(all_logs)\n",
    "\n",
    "# Now we want to collapse the data by subject, so we can get the mean metric score for each subject.\n",
    "logs_per_subject = all_logs.groupby(['data_idx', 'cal_metric', 'bin_weighting', 'task', 'split']).agg({\n",
    "    'pred_lab_amount': 'mean',\n",
    "    'gt_lab_amount': 'mean',\n",
    "    'cal_score': 'mean',\n",
    "    'accuracy': 'mean',\n",
    "    'dice': 'mean',\n",
    "    'lab_w_accuracy': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "logs_per_subject = reorder_splits(logs_per_subject)\n",
    "\n",
    "# Group the metrics by important factors\n",
    "grouped_logs = all_logs.groupby(['task', 'cal_metric', 'split'])\n",
    "grouped_logs_per_subject = logs_per_subject.groupby(['task', 'cal_metric', 'split'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_per_subject"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ECE vs ReCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "# Define the custom function to calculate and annotate correlation\n",
    "def annotate_correlation(data, **kws):\n",
    "    x, y = data['ECE'], data['ReCE']\n",
    "    r, _ = pearsonr(x, y)\n",
    "    ax = plt.gca()\n",
    "    ax.text(.1, .9, f'r = {r:.2f}', transform=ax.transAxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 20})  \n",
    "# POplt.rcParams.update({'font.size': 20})  vot the DataFrame\n",
    "pivot_df = logs_per_subject.pivot(index=['data_idx', 'task', 'split', 'gt_lab_amount'], columns='cal_metric', values='cal_score').reset_index()\n",
    "sorted_pivot_df = reorder_splits(pivot_df)\n",
    "\n",
    "# Now plot the scatter plot with each task as a different column\n",
    "g = sns.relplot(data=sorted_pivot_df, \n",
    "            x='ECE', \n",
    "            y='ReCE', \n",
    "            col='split', \n",
    "            row='task',\n",
    "            hue='gt_lab_amount',\n",
    "            height=8,\n",
    "            s=100)\n",
    "\n",
    "# Map the custom function onto the FacetGrid\n",
    "g.map_dataframe(annotate_correlation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation Comparison: Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 20})  \n",
    "\n",
    "for metric in [\"ECE\", \"ReCE\"]:\n",
    "    g = sns.relplot(\n",
    "        data=all_logs[all_logs['cal_metric'] == metric],\n",
    "        x='accuracy',\n",
    "        y='cal_score',\n",
    "        col='split',\n",
    "        hue='task',\n",
    "        kind='scatter',\n",
    "        height=8,\n",
    "        facet_kws={\"sharex\": False},\n",
    "        alpha=0.5,\n",
    "        aspect=1\n",
    "        )\n",
    "    g.axes.flat[0].set_ylabel(metric)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 20})  \n",
    "\n",
    "acc_corr = grouped_logs.apply(lambda x: x['accuracy'].corr(x['cal_score'])).reset_index(name='accuracy correlation')\n",
    "acc_corr = reorder_splits(acc_corr)\n",
    "g = sns.catplot(data=acc_corr, \n",
    "                x=\"task\", \n",
    "                y=\"accuracy correlation\", \n",
    "                hue='cal_metric', \n",
    "                col=\"split\", \n",
    "                kind=\"bar\", \n",
    "                height=8, \n",
    "                aspect=1)\n",
    "# Set the y lim between - 1 and 1\n",
    "g.set(ylim=(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 20})  \n",
    "\n",
    "for metric in [\"ECE\", \"ReCE\"]:\n",
    "    g = sns.relplot(\n",
    "        data=logs_per_subject[logs_per_subject['cal_metric'] == metric],\n",
    "        x='accuracy',\n",
    "        y='cal_score',\n",
    "        col='split',\n",
    "        hue='task',\n",
    "        kind='scatter',\n",
    "        s=100,\n",
    "        height=8,\n",
    "        facet_kws={\"sharex\": False},\n",
    "        alpha=0.8,\n",
    "        aspect=1\n",
    "        )\n",
    "    g.axes.flat[0].set_ylabel(metric)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 25})  \n",
    "\n",
    "# Group by the three columns and apply correlation\n",
    "acc_subj_correlations = grouped_logs_per_subject.apply(lambda x: x['accuracy'].corr(x['cal_score'])).reset_index(name='accuracy correlation')\n",
    "acc_subj_correlations = reorder_splits(acc_subj_correlations)\n",
    "g = sns.catplot(data=acc_subj_correlations, \n",
    "                x=\"task\", \n",
    "                y=\"accuracy correlation\", \n",
    "                hue='cal_metric', \n",
    "                col=\"split\", \n",
    "                kind=\"bar\", \n",
    "                height=8, \n",
    "                aspect=1)\n",
    "# Set the y lim between - 1 and 1\n",
    "g.set(ylim=(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation Comparison: Dice Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 20})  \n",
    "\n",
    "for metric in [\"ECE\", \"ReCE\"]:\n",
    "    g = sns.relplot(\n",
    "        data=all_logs[all_logs['cal_metric'] == metric],\n",
    "        x='dice',\n",
    "        y='cal_score',\n",
    "        col='split',\n",
    "        hue='task',\n",
    "        kind='scatter',\n",
    "        height=8,\n",
    "        facet_kws={\"sharex\": False},\n",
    "        alpha=0.5,\n",
    "        aspect=1\n",
    "        )\n",
    "    g.axes.flat[0].set_ylabel(metric)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 20})  \n",
    "\n",
    "dice_correlations = grouped_logs.apply(lambda x: x['dice'].corr(x['cal_score'])).reset_index(name='dice correlation')\n",
    "dice_correlations = reorder_splits(dice_correlations)\n",
    "g = sns.catplot(data=dice_correlations, \n",
    "                x=\"task\", \n",
    "                y=\"dice correlation\", \n",
    "                hue='cal_metric', \n",
    "                col=\"split\", \n",
    "                kind=\"bar\", \n",
    "                height=8, \n",
    "                aspect=1)\n",
    "# Set the y lim between - 1 and 1\n",
    "g.set(ylim=(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 20})  \n",
    "\n",
    "for metric in [\"ECE\", \"ReCE\"]:\n",
    "    g = sns.relplot(\n",
    "        data=logs_per_subject[logs_per_subject['cal_metric'] == metric],\n",
    "        x='dice',\n",
    "        y='cal_score',\n",
    "        col='split',\n",
    "        hue='task',\n",
    "        kind='scatter',\n",
    "        s=100,\n",
    "        height=8,\n",
    "        facet_kws={\"sharex\": False},\n",
    "        alpha=0.8,\n",
    "        aspect=1\n",
    "        )\n",
    "    g.axes.flat[0].set_ylabel(metric)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.rcParams.update({'font.size': 25})  \n",
    "\n",
    "# Group by the three columns and apply correlation\n",
    "dice_subject_correlations = grouped_logs_per_subject.apply(lambda x: x['dice'].corr(x['cal_score'])).reset_index(name='dice correlation')\n",
    "dice_subject_correlations = reorder_splits(dice_subject_correlations)\n",
    "g = sns.catplot(data=dice_subject_correlations, \n",
    "                x=\"task\", \n",
    "                y=\"dice correlation\", \n",
    "                hue='cal_metric', \n",
    "                col=\"split\", \n",
    "                kind=\"bar\", \n",
    "                height=8, \n",
    "                aspect=1)\n",
    "# Set the y lim between - 1 and 1\n",
    "g.set(ylim=(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation Comparison: Groundtruth Label Amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 18})  \n",
    "\n",
    "for metric in [\"ECE\", \"ReCE\"]:\n",
    "    g = sns.relplot(\n",
    "        data=all_logs[all_logs['cal_metric'] == metric],\n",
    "        x='gt_lab_amount',\n",
    "        y='cal_score',\n",
    "        col='split',\n",
    "        hue='task',\n",
    "        kind='scatter',\n",
    "        height=8,\n",
    "        facet_kws={\"sharex\": False},\n",
    "        alpha=0.5,\n",
    "        aspect=1)\n",
    "    g.axes.flat[0].set_ylabel(metric)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 25})  \n",
    "\n",
    "# Group by the three columns and apply correlation\n",
    "label_amount_correlations = grouped_logs.apply(lambda x: x['gt_lab_amount'].corr(x['cal_score'])).reset_index(name='label amount correlation')\n",
    "label_amount_correlations = reorder_splits(label_amount_correlations)\n",
    "g = sns.catplot(data=label_amount_correlations, \n",
    "                x=\"task\", \n",
    "                y=\"label amount correlation\", \n",
    "                hue='cal_metric', \n",
    "                col=\"split\", \n",
    "                kind=\"bar\", \n",
    "                height=8, \n",
    "                aspect=1)\n",
    "# Set the y lim between - 1 and 1\n",
    "g.set(ylim=(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 18})  \n",
    "\n",
    "for metric in [\"ECE\", \"ReCE\"]:\n",
    "    g = sns.relplot(\n",
    "        data=logs_per_subject[logs_per_subject['cal_metric'] == metric],\n",
    "        x='gt_lab_amount',\n",
    "        y='cal_score',\n",
    "        col='split',\n",
    "        hue='task',\n",
    "        kind='scatter',\n",
    "        s=100,\n",
    "        height=8,\n",
    "        facet_kws={\"sharex\": False},\n",
    "        alpha=0.8,\n",
    "        aspect=1)\n",
    "    g.axes.flat[0].set_ylabel(metric)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.rcParams.update({'font.size': 25})  \n",
    "\n",
    "# Group by the three columns and apply correlation\n",
    "label_amount_subject_correlations = grouped_logs_per_subject.apply(lambda x: x['gt_lab_amount'].corr(x['cal_score'])).reset_index(name='label amount correlation')\n",
    "label_amount_subject_correlations = reorder_splits(label_amount_subject_correlations)\n",
    "sns.catplot(data=label_amount_subject_correlations, \n",
    "            x=\"task\", \n",
    "            y=\"label amount correlation\", \n",
    "            hue='cal_metric', \n",
    "            col=\"split\", \n",
    "            kind=\"bar\", \n",
    "            height=8, \n",
    "            aspect=1)\n",
    "# Set the y lim between - 1 and 1\n",
    "g.set(ylim=(-1, 1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UniverSegTF",
   "language": "python",
   "name": "universegtf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
