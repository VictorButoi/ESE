{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/storage/vbutoi/projects')\n",
    "sys.path.append('/storage/vbutoi/libraries')\n",
    "sys.path.append('/storage/vbutoi/projects/ESE')\n",
    "sys.path.append('/storage/vbutoi/projects/UniverSeg')\n",
    "\n",
    "from ionpy.analysis import ResultsLoader\n",
    "from ese.experiment.experiment import CalibrationExperiment\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "import os \n",
    "os.environ['DATAPATH'] = ':'.join((\n",
    "       '/storage/vbutoi/datasets',\n",
    "))\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '3' \n",
    "\n",
    "%load_ext yamlmagic\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results loader object does everything\n",
    "rs = ResultsLoader()\n",
    "root = \"/storage/vbutoi/scratch/ESE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = f\"{root}/09_18_23_BinaryPetsPilot\"\n",
    "\n",
    "dfc = rs.load_configs(\n",
    "    path,\n",
    "    properties=False,\n",
    ")\n",
    "\n",
    "df = rs.load_metrics(dfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_exp = rs.get_experiment(\n",
    "    df=df,\n",
    "    exp_class=CalibrationExperiment,\n",
    "    metric=\"val-dice_score\",\n",
    "    checkpoint=\"max-val-dice_score\",\n",
    "    device=\"cuda\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_exp.vis_loss_curves(height=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%yaml dataset_cfg \n",
    "\n",
    "_class: ese.experiment.datasets.BinaryPets\n",
    "split: cal\n",
    "preload: True\n",
    "version: 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ionpy.experiment.util import absolute_import\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataset_cls = absolute_import(dataset_cfg.pop(\"_class\"))\n",
    "BinaryPet_Dataset = dataset_cls(**dataset_cfg)\n",
    "binarypets_dataloader = DataLoader(BinaryPet_Dataset, batch_size=1, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ionpy.util.torchutils import to_device\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def get_dataset_perf(\n",
    "        exp, \n",
    "        dataloader, \n",
    "        ):\n",
    "\n",
    "    items = []\n",
    "    with torch.no_grad():\n",
    "        for _, batch in tqdm(enumerate(dataloader), total=len(dataloader)):\n",
    "            \n",
    "            # Get your image label pair and define some regions.\n",
    "            x, y = to_device(batch, exp.device)\n",
    "            # Get the prediction\n",
    "            yhat = exp.model(x)  \n",
    "            # Extract predictions\n",
    "            soft_pred = torch.softmax(yhat, axis=1)\n",
    "            hard_pred = torch.argmax(soft_pred, axis=1)\n",
    "            # Get the confidence map\n",
    "            conf_map = torch.max(soft_pred, axis=1)[0]\n",
    "            # Wrap it in an item\n",
    "            items.append({\n",
    "                \"image\": x.cpu().squeeze(),\n",
    "                \"label\": y.cpu().squeeze(),\n",
    "                \"conf_map\": conf_map.cpu().squeeze(),\n",
    "                \"pred_map\": hard_pred.cpu().squeeze(),\n",
    "            })\n",
    "\n",
    "    return items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_perf is a dict where each item is the subj id\n",
    "# with the y, ypred, yloss, ydice\n",
    "predictions_list = get_dataset_perf(\n",
    "    exp=best_exp, \n",
    "    dataloader=binarypets_dataloader\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%yaml metric_cfg \n",
    "\n",
    "ECE:\n",
    "    func: ese.experiment.metrics.pixelwise.ECE\n",
    "    color: blue\n",
    "ACE:\n",
    "    func: ese.experiment.metrics.pixelwise.ACE\n",
    "    color: goldenrod\n",
    "Island_ECE:\n",
    "    func: ese.experiment.metrics.pixelwise.Island_ECE \n",
    "    color: lightgreen \n",
    "ReCE:\n",
    "    func: ese.experiment.metrics.regionwise.ReCE\n",
    "    color: green"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ese.experiment.analysis.diagrams import subject_diagram\n",
    "\n",
    "subject_diagram(\n",
    "    num_subjects=10,\n",
    "    subject_list=predictions_list,\n",
    "    num_bins=10,\n",
    "    class_type=\"Multi-class\",\n",
    "    metric_cfg=metric_cfg,\n",
    "    bin_weighting=\"proportional\",\n",
    "    show_analysis_plots=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ese.experiment.analysis.diagrams import score_histogram_diagram \n",
    "\n",
    "score_histogram_diagram(\n",
    "    subject_list=predictions_list,\n",
    "    num_bins=10,\n",
    "    metrics=[\"ECE\", \"ReCE\"],\n",
    "    class_type=\"Multi-class\",\n",
    "    bin_weighting=\"proportional\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ese.experiment.analysis.diagrams import score_histogram_diagram \n",
    "\n",
    "score_histogram_diagram(\n",
    "    subject_list=predictions_list,\n",
    "    num_bins=10,\n",
    "    metrics=[\"ECE\", \"ReCE\"],\n",
    "    bin_weighting=\"proportional\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UniverSegTF",
   "language": "python",
   "name": "universegtf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
