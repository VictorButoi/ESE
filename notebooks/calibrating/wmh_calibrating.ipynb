{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/storage/vbutoi/projects')\n",
    "sys.path.append('/storage/vbutoi/libraries')\n",
    "sys.path.append('/storage/vbutoi/projects/ESE')\n",
    "sys.path.append('/storage/vbutoi/projects/UniverSeg')\n",
    "import torch\n",
    "torch.set_printoptions(linewidth=200)\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "import os \n",
    "os.environ['DATAPATH'] = ':'.join((\n",
    "       '/storage/vbutoi/datasets',\n",
    "))\n",
    "\n",
    "# Results loader object does everything\n",
    "from ionpy.analysis import ResultsLoader\n",
    "from pathlib import Path\n",
    "root = Path(\"/storage/vbutoi/scratch/ESE\")\n",
    "rs = ResultsLoader()\n",
    "\n",
    "# For using code without restarting.\n",
    "%load_ext autoreload\n",
    "%autoreload \n",
    "# For using yaml configs.\n",
    "%load_ext yamlmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            require(\n                [\n                    \"notebook/js/codecell\",\n                    \"codemirror/mode/yaml/yaml\"\n                ],\n                function(cc){\n                    cc.CodeCell.options_default.highlight_modes.magic_yaml = {\n                        reg: [\"^%%yaml\"]\n                    }\n                }\n            );\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%yaml calibration_config\n",
    "\n",
    "experiment:\n",
    "  seed: 42\n",
    "    \n",
    "data:\n",
    "  preload: True\n",
    "  iters_per_epoch: 100\n",
    "\n",
    "dataloader:\n",
    "  batch_size: 1 \n",
    "  num_workers: 1\n",
    "  pin_memory: True \n",
    "\n",
    "optim: \n",
    "  _class: torch.optim.Adam\n",
    "  lr: 3.0e-4\n",
    "  weight_decay: 0.0 \n",
    "\n",
    "train:\n",
    "  epochs: 1000 \n",
    "  eval_freq: 10 \n",
    "  pretrained_dir: /storage/vbutoi/scratch/ESE/training/10_23_23_Dense_WMH \n",
    "\n",
    "log:\n",
    "  checkpoint_freq: 5 \n",
    "  root: '?'\n",
    "  metrics:\n",
    "    ece_loss:\n",
    "      _fn: ese.experiment.metrics.ece_loss\n",
    "      from_logits: True\n",
    "    elm_loss:\n",
    "      _fn: ese.experiment.metrics.elm_loss\n",
    "      from_logits: True\n",
    "\n",
    "loss_func: \n",
    "  _class: ionpy.loss.PixelCELoss \n",
    "  from_logits: True \n",
    "  batch_reduction: 'mean' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            require(\n                [\n                    \"notebook/js/codecell\",\n                    \"codemirror/mode/yaml/yaml\"\n                ],\n                function(cc){\n                    cc.CodeCell.options_default.highlight_modes.magic_yaml = {\n                        reg: [\"^%%yaml\"]\n                    }\n                }\n            );\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%yaml calibrator_model_cfg  \n",
    "\n",
    "model:\n",
    "  _class: '?'\n",
    "  num_classes: 2\n",
    "  image_channels: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            require(\n                [\n                    \"notebook/js/codecell\",\n                    \"codemirror/mode/yaml/yaml\"\n                ],\n                function(cc){\n                    cc.CodeCell.options_default.highlight_modes.magic_yaml = {\n                        reg: [\"^%%yaml\"]\n                    }\n                }\n            );\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%yaml callbacks_cfg\n",
    "\n",
    "callbacks:\n",
    "  step:\n",
    "    - ese.experiment.callbacks.ShowPredictions\n",
    "  epoch:\n",
    "    - ese.experiment.callbacks.WandbLogger\n",
    "    - ionpy.callbacks.ETA\n",
    "    - ionpy.callbacks.JobProgress\n",
    "    - ionpy.callbacks.TerminateOnNaN\n",
    "    - ionpy.callbacks.PrintLogged\n",
    "    - ionpy.callbacks.ModelCheckpoint:\n",
    "        monitor: ece_loss \n",
    "        phase: val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup direcrtories\n",
    "calibration_root = '/storage/vbutoi/scratch/ESE/calibration'\n",
    "\n",
    "# WMH CONFIG\n",
    "exp_name = '01_02_24_WMH_FIXED'\n",
    "\n",
    "# Setup the root.\n",
    "exp_root = f'{calibration_root}/{exp_name}'\n",
    "\n",
    "# Create the ablation options\n",
    "option_set = [\n",
    "    {\n",
    "        'log.root': [exp_root],\n",
    "        'optim.lr': [3e-4],\n",
    "        'model._class': ['ese.experiment.models.calibrators.Temperature_Scaling',\n",
    "                         'ese.experiment.models.calibrators.Vector_Scaling',\n",
    "                         'ese.experiment.models.calibrators.Dirichlet_Scaling',\n",
    "                         'ese.experiment.models.calibrators.LTS'],\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ese.scripts.utils import get_option_product\n",
    "from ionpy.util import Config\n",
    "\n",
    "# Assemble base config\n",
    "base_cfg = Config(calibration_config).update([calibrator_model_cfg, callbacks_cfg])\n",
    "\n",
    "# Get the configs\n",
    "cfgs = get_option_product(exp_name, option_set, base_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cfgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage/vbutoi/projects/ionpy/util/libcheck.py:57: UserWarning: Using slow Pillow instead of Pillow-SIMD\n",
      "  warn(\"Using slow Pillow instead of Pillow-SIMD\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b9f40e5ef2746f6b79868f11f0ef0b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "370798449c09443bb9c9f09cdcb00212",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage/vbutoi/projects/ionpy/util/libcheck.py:57: UserWarning: Using slow Pillow instead of Pillow-SIMD\n",
      "  warn(\"Using slow Pillow instead of Pillow-SIMD\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PostHocExperiment(\"/storage/vbutoi/scratch/ESE/calibration/debug/20240102_195845-V7SZ-7600aa1224f792b414a07227dacea150\")\n",
      "---\n",
      "callbacks:\n",
      "  epoch:\n",
      "  - ese.experiment.callbacks.WandbLogger\n",
      "  - ionpy.callbacks.ETA\n",
      "  - ionpy.callbacks.JobProgress\n",
      "  - ionpy.callbacks.TerminateOnNaN\n",
      "  - ionpy.callbacks.PrintLogged\n",
      "  - ionpy.callbacks.ModelCheckpoint:\n",
      "      monitor: ece_loss\n",
      "      phase: val\n",
      "data:\n",
      "  preload: true\n",
      "dataloader:\n",
      "  batch_size: 1\n",
      "  num_workers: 1\n",
      "  pin_memory: true\n",
      "experiment:\n",
      "  seed: 42\n",
      "log:\n",
      "  checkpoint_freq: 5\n",
      "  metrics:\n",
      "    ece_loss:\n",
      "      _fn: ese.experiment.metrics.ece_loss\n",
      "      from_logits: true\n",
      "    elm_loss:\n",
      "      _fn: ese.experiment.metrics.elm_loss\n",
      "      from_logits: true\n",
      "  root: /storage/vbutoi/scratch/ESE/calibration/debug\n",
      "  wandb_string: exp_name:01_02_24_WMH_FIXED-lr:0.0003-_class:ese.experiment.models.calibrators.Temperature_Scaling\n",
      "loss_func:\n",
      "  _class: ionpy.loss.PixelCELoss\n",
      "  batch_reduction: mean\n",
      "  from_logits: true\n",
      "model:\n",
      "  _class: ese.experiment.models.calibrators.Temperature_Scaling\n",
      "  image_channels: 1\n",
      "  num_classes: 2\n",
      "optim:\n",
      "  _class: torch.optim.Adam\n",
      "  lr: 0.0003\n",
      "  weight_decay: 0.0\n",
      "train:\n",
      "  epochs: 1000\n",
      "  eval_freq: 10\n",
      "  pretrained_dir: /storage/vbutoi/scratch/ESE/training/10_23_23_Dense_WMH\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvbutoi\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/storage/vbutoi/scratch/ESE/calibration/debug/wandb/run-20240102_200615-6baq2sm8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/vbutoi/SemanticCalibration/runs/6baq2sm8' target=\"_blank\">decent-fire-312</a></strong> to <a href='https://wandb.ai/vbutoi/SemanticCalibration' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/vbutoi/SemanticCalibration' target=\"_blank\">https://wandb.ai/vbutoi/SemanticCalibration</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/vbutoi/SemanticCalibration/runs/6baq2sm8' target=\"_blank\">https://wandb.ai/vbutoi/SemanticCalibration/runs/6baq2sm8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start epoch 0\n",
      "Checkpointing with tag:last at epoch:0\n",
      "ETA (0/999): 2024-01-02 20:06:29 - 00:00:00 remaining\n",
      "Logged @ Epoch 0\n",
      "metric          train          val\n",
      "--------  -----------  -----------\n",
      "ece_loss  0.000773359  0.000944342\n",
      "elm_loss  0.00118331   0.00128661\n",
      "loss      0.0060991    0.00744823\n",
      "Checkpointing with tag:min-val-ece_loss at epoch:0\n",
      "Start epoch 1\n",
      "ETA (1/999): 2024-01-02 20:36:44 - 00:30:13 remaining\n",
      "Logged @ Epoch 1\n",
      "metric          train\n",
      "--------  -----------\n",
      "ece_loss  0.000830933\n",
      "elm_loss  0.00119056\n",
      "loss      0.00666023\n",
      "Start epoch 2\n",
      "ETA (2/999): 2024-01-02 20:36:54 - 00:30:21 remaining\n",
      "Logged @ Epoch 2\n",
      "metric         train\n",
      "--------  ----------\n",
      "ece_loss  0.00118119\n",
      "elm_loss  0.00169741\n",
      "loss      0.00794123\n",
      "Start epoch 3\n",
      "ETA (3/999): 2024-01-02 20:36:52 - 00:30:17 remaining\n",
      "Logged @ Epoch 3\n",
      "metric          train\n",
      "--------  -----------\n",
      "ece_loss  0.000870721\n",
      "elm_loss  0.00140647\n",
      "loss      0.00687687\n",
      "Start epoch 4\n",
      "ETA (4/999): 2024-01-02 20:36:55 - 00:30:19 remaining\n",
      "Logged @ Epoch 4\n",
      "metric          train\n",
      "--------  -----------\n",
      "ece_loss  0.000904986\n",
      "elm_loss  0.00131541\n",
      "loss      0.00602079\n",
      "Start epoch 5\n",
      "Checkpointing with tag:last at epoch:5\n",
      "ETA (5/999): 2024-01-02 20:36:53 - 00:30:14 remaining\n",
      "Logged @ Epoch 5\n",
      "metric          train\n",
      "--------  -----------\n",
      "ece_loss  0.000636288\n",
      "elm_loss  0.00109405\n",
      "loss      0.0058038\n",
      "Start epoch 6\n",
      "ETA (6/999): 2024-01-02 20:36:43 - 00:30:03 remaining\n",
      "Logged @ Epoch 6\n",
      "metric          train\n",
      "--------  -----------\n",
      "ece_loss  0.000509746\n",
      "elm_loss  0.000959343\n",
      "loss      0.00500495\n",
      "Start epoch 7\n",
      "ETA (7/999): 2024-01-02 20:36:35 - 00:29:53 remaining\n",
      "Logged @ Epoch 7\n",
      "metric         train\n",
      "--------  ----------\n",
      "ece_loss  0.00085033\n",
      "elm_loss  0.00134483\n",
      "loss      0.00640405\n",
      "Start epoch 8\n",
      "ETA (8/999): 2024-01-02 20:36:31 - 00:29:47 remaining\n",
      "Logged @ Epoch 8\n",
      "metric         train\n",
      "--------  ----------\n",
      "ece_loss  0.0013705\n",
      "elm_loss  0.00182205\n",
      "loss      0.0081526\n",
      "Start epoch 9\n",
      "ETA (9/999): 2024-01-02 20:36:28 - 00:29:43 remaining\n",
      "Logged @ Epoch 9\n",
      "metric          train\n",
      "--------  -----------\n",
      "ece_loss  0.000982234\n",
      "elm_loss  0.00156937\n",
      "loss      0.00678304\n",
      "Start epoch 10\n",
      "Checkpointing with tag:last at epoch:10\n",
      "ETA (10/999): 2024-01-02 20:37:37 - 00:30:48 remaining\n",
      "Logged @ Epoch 10\n",
      "metric         train         val\n",
      "--------  ----------  ----------\n",
      "ece_loss  0.00127004  0.00124017\n",
      "elm_loss  0.00177608  0.00148564\n",
      "loss      0.00894637  0.00832965\n",
      "Start epoch 11\n",
      "ETA (11/999): 2024-01-02 20:38:10 - 00:31:19 remaining\n",
      "Logged @ Epoch 11\n",
      "metric          train\n",
      "--------  -----------\n",
      "ece_loss  0.000956871\n",
      "elm_loss  0.00136692\n",
      "loss      0.00655801\n",
      "Start epoch 12\n",
      "ETA (12/999): 2024-01-02 20:38:26 - 00:31:34 remaining\n",
      "Logged @ Epoch 12\n",
      "metric         train\n",
      "--------  ----------\n",
      "ece_loss  0.00108385\n",
      "elm_loss  0.00159827\n",
      "loss      0.00801514\n",
      "Start epoch 13\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mese\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperiment\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperiment\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m run_ese_exp, PostHocExperiment\n\u001b[0;32m----> 3\u001b[0m \u001b[43mrun_ese_exp\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfgs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexperiment_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPostHocExperiment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgpu\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m0\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdebug\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshow_examples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrack_wandb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     10\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/envs/UniverSegTF/lib/python3.9/site-packages/pydantic/decorator.py:40\u001b[0m, in \u001b[0;36mpydantic.decorator.validate_arguments.validate.wrapper_function\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/envs/UniverSegTF/lib/python3.9/site-packages/pydantic/decorator.py:134\u001b[0m, in \u001b[0;36mpydantic.decorator.ValidatedFunction.call\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/envs/UniverSegTF/lib/python3.9/site-packages/pydantic/decorator.py:206\u001b[0m, in \u001b[0;36mpydantic.decorator.ValidatedFunction.execute\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/storage/vbutoi/projects/ESE/ese/experiment/experiment/runner.py:36\u001b[0m, in \u001b[0;36mrun_ese_exp\u001b[0;34m(config, experiment_class, gpu, run_name, show_examples, track_wandb)\u001b[0m\n\u001b[1;32m     33\u001b[0m     cfg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mremove(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mese.experiment.callbacks.WandbLogger\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# Run the experiment.\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m \u001b[43mslite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_exp\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexperiment_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_object\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mConfig\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgpu\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgpu\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/envs/UniverSegTF/lib/python3.9/site-packages/pydantic/decorator.py:40\u001b[0m, in \u001b[0;36mpydantic.decorator.validate_arguments.validate.wrapper_function\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/envs/UniverSegTF/lib/python3.9/site-packages/pydantic/decorator.py:134\u001b[0m, in \u001b[0;36mpydantic.decorator.ValidatedFunction.call\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/envs/UniverSegTF/lib/python3.9/site-packages/pydantic/decorator.py:206\u001b[0m, in \u001b[0;36mpydantic.decorator.ValidatedFunction.execute\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/storage/vbutoi/projects/ionpy/slite/runner.py:33\u001b[0m, in \u001b[0;36mrun_exp\u001b[0;34m(exp_class, exp_object, gpu)\u001b[0m\n\u001b[1;32m     30\u001b[0m     exp \u001b[38;5;241m=\u001b[39m exp_class(exp_object)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Run the experiment.\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m \u001b[43mexp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/storage/vbutoi/projects/ESE/ese/experiment/experiment/posthoc_exp.py:100\u001b[0m, in \u001b[0;36mPostHocExperiment.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 100\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/storage/vbutoi/projects/ionpy/experiment/train.py:177\u001b[0m, in \u001b[0;36mTrainExperiment.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStart epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_epoch \u001b[38;5;241m=\u001b[39m epoch\n\u001b[0;32m--> 177\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_phase\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m eval_freq \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m (epoch \u001b[38;5;241m%\u001b[39m eval_freq \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m epoch \u001b[38;5;241m==\u001b[39m epochs \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_phase(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m\"\u001b[39m, epoch)\n",
      "File \u001b[0;32m/storage/vbutoi/projects/ionpy/experiment/train.py:203\u001b[0m, in \u001b[0;36mTrainExperiment.run_phase\u001b[0;34m(self, phase, epoch)\u001b[0m\n\u001b[1;32m    199\u001b[0m meters \u001b[38;5;241m=\u001b[39m MeterDict()\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(grad_enabled):\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;66;03m# with torch.inference_mode(not grad_enabled):\u001b[39;00m\n\u001b[0;32m--> 203\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dl):\n\u001b[1;32m    204\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_step(\n\u001b[1;32m    205\u001b[0m             batch_idx\u001b[38;5;241m=\u001b[39mbatch_idx,\n\u001b[1;32m    206\u001b[0m             batch\u001b[38;5;241m=\u001b[39mbatch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    210\u001b[0m             phase\u001b[38;5;241m=\u001b[39mphase\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m         metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_metrics(outputs)\n",
      "File \u001b[0;32m~/envs/UniverSegTF/lib/python3.9/site-packages/torch/utils/data/dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    626\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    627\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 628\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    631\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    632\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/envs/UniverSegTF/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1305\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1302\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1303\u001b[0m     \u001b[38;5;66;03m# no valid `self._rcvd_idx` is found (i.e., didn't break)\u001b[39;00m\n\u001b[1;32m   1304\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_persistent_workers:\n\u001b[0;32m-> 1305\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_shutdown_workers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1306\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n\u001b[1;32m   1308\u001b[0m \u001b[38;5;66;03m# Now `self._rcvd_idx` is the batch index we want to fetch\u001b[39;00m\n\u001b[1;32m   1309\u001b[0m \n\u001b[1;32m   1310\u001b[0m \u001b[38;5;66;03m# Check if the next sample has already been generated\u001b[39;00m\n",
      "File \u001b[0;32m~/envs/UniverSegTF/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1430\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._shutdown_workers\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1425\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mark_worker_as_unavailable(worker_id, shutdown\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1426\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workers:\n\u001b[1;32m   1427\u001b[0m     \u001b[38;5;66;03m# We should be able to join here, but in case anything went\u001b[39;00m\n\u001b[1;32m   1428\u001b[0m     \u001b[38;5;66;03m# wrong, we set a timeout and if the workers fail to join,\u001b[39;00m\n\u001b[1;32m   1429\u001b[0m     \u001b[38;5;66;03m# they are killed in the `finally` block.\u001b[39;00m\n\u001b[0;32m-> 1430\u001b[0m     \u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMP_STATUS_CHECK_INTERVAL\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1431\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m q \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_queues:\n\u001b[1;32m   1432\u001b[0m     q\u001b[38;5;241m.\u001b[39mcancel_join_thread()\n",
      "File \u001b[0;32m~/envs/UniverSegTF/lib/python3.9/multiprocessing/process.py:149\u001b[0m, in \u001b[0;36mBaseProcess.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent_pid \u001b[38;5;241m==\u001b[39m os\u001b[38;5;241m.\u001b[39mgetpid(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcan only join a child process\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcan only join a started process\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 149\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_popen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    151\u001b[0m     _children\u001b[38;5;241m.\u001b[39mdiscard(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m~/envs/UniverSegTF/lib/python3.9/multiprocessing/popen_fork.py:40\u001b[0m, in \u001b[0;36mPopen.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmultiprocessing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconnection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m wait\n\u001b[0;32m---> 40\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msentinel\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     41\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# This shouldn't block if wait() returned successfully.\u001b[39;00m\n",
      "File \u001b[0;32m~/envs/UniverSegTF/lib/python3.9/multiprocessing/connection.py:931\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    928\u001b[0m     deadline \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic() \u001b[38;5;241m+\u001b[39m timeout\n\u001b[1;32m    930\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 931\u001b[0m     ready \u001b[38;5;241m=\u001b[39m \u001b[43mselector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    932\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ready:\n\u001b[1;32m    933\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [key\u001b[38;5;241m.\u001b[39mfileobj \u001b[38;5;28;01mfor\u001b[39;00m (key, events) \u001b[38;5;129;01min\u001b[39;00m ready]\n",
      "File \u001b[0;32m~/envs/UniverSegTF/lib/python3.9/selectors.py:416\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 416\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from ese.experiment.experiment import run_ese_exp, PostHocExperiment\n",
    "\n",
    "run_ese_exp(\n",
    "    config=cfgs[0], \n",
    "    experiment_class=PostHocExperiment,\n",
    "    gpu='0',\n",
    "    run_name='debug',\n",
    "    show_examples=False,\n",
    "    track_wandb=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # FOR SUBMISSION\n",
    "# from ese.experiment.experiment import submit_ese_exps, PostHocExperiment\n",
    "\n",
    "# submit_ese_exps(\n",
    "#     exp_root=exp_root,\n",
    "#     experiment_class=PostHocExperiment,\n",
    "#     config_list=cfgs,\n",
    "#     available_gpus=['0', '1', '2', '3'],\n",
    "#     track_wandb=True\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UniverSegTF",
   "language": "python",
   "name": "universegtf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
