{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/storage/vbutoi/projects')\n",
    "sys.path.append('/storage/vbutoi/libraries')\n",
    "sys.path.append('/storage/vbutoi/projects/ESE')\n",
    "sys.path.append('/storage/vbutoi/projects/UniverSeg')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "import os \n",
    "os.environ['DATAPATH'] = ':'.join((\n",
    "       '/storage/vbutoi/datasets',\n",
    "))\n",
    "\n",
    "# Results loader object does everything\n",
    "from ionpy.analysis import ResultsLoader\n",
    "from pathlib import Path\n",
    "root = Path(\"/storage/vbutoi/scratch/ESE\")\n",
    "rs = ResultsLoader()\n",
    "\n",
    "# For using code without restarting.\n",
    "%load_ext autoreload\n",
    "%autoreload \n",
    "# For using yaml configs.\n",
    "%load_ext yamlmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%yaml results_cfg \n",
    "\n",
    "# EXPERIMENT SETS:\n",
    "# - WMH Calibration (no weighting): 01_29_24_WMH_Base\n",
    "# - WMH Only Foreground Loss: 01_29_24_WMH_Foreground\n",
    "# - WMH Balanced Loss: 01_21_24_Balanced_CE_Calibrators\n",
    "# - CityScapes Calibration: 01_30_24_CityScapes_WeightedEnsembles\n",
    "\n",
    "log:\n",
    "    root: /storage/vbutoi/scratch/ESE/inference\n",
    "    add_dice_loss_rows: True\n",
    "    load_pixel_meters: True \n",
    "    drop_nan_metric_rows: True \n",
    "    remove_shared_columns: False \n",
    "    add_baseline_rows: True \n",
    "    equal_rows_per_cfg_assert: False\n",
    "    inference_group: \"01_31_24_CityScapes_AllCalibrators\"\n",
    "    # min_fg_pixels: 100\n",
    "    \n",
    "calibration:\n",
    "    num_bins: 15\n",
    "    square_diff: False \n",
    "    neighborhood_width: 3\n",
    "\n",
    "# cal_metrics:\n",
    "#     - ECE:\n",
    "#         _fn: ese.experiment.metrics.ece.ece_loss\n",
    "#     - Edge-ECE:\n",
    "#         _fn: ese.experiment.metrics.ece.edge_ece_loss\n",
    "#     # - CW-ECE:\n",
    "#     #     _fn: ese.experiment.metrics.ece.cw_ece_loss\n",
    "#     - ELM:\n",
    "#         _fn: ese.experiment.metrics.elm.elm_loss\n",
    "\n",
    "#     - Foreground-ECE:\n",
    "#         _fn: ese.experiment.metrics.ece.ece_loss\n",
    "#         ignore_index: 0\n",
    "#     - Foreground-Edge-ECE:\n",
    "#         _fn: ese.experiment.metrics.ece.edge_ece_loss\n",
    "#         ignore_index: 0       \n",
    "#     # - Foreground-CW-ECE:\n",
    "#     #     _fn: ese.experiment.metrics.ece.cw_ece_loss\n",
    "#     #     ignore_index: 0\n",
    "#     - Foreground-ELM:\n",
    "#         _fn: ese.experiment.metrics.elm.elm_loss\n",
    "#         ignore_index: 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ese.experiment.analysis.analyze_inf import load_cal_inference_stats\n",
    "\n",
    "image_info_df = load_cal_inference_stats(\n",
    "    results_cfg=results_cfg,\n",
    "    load_cached=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_info_df['calibrator'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We are going to remove the case where there are very few pixels, cause unrealistic outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the image_info_df by method name, so everything appears nicely\n",
    "image_info_df = image_info_df.sort_values(by=['method_name', 'calibrator'])\n",
    "# Make sure that the model_class 'Uncalibrated' is first\n",
    "image_info_df['calibrator'] = image_info_df['calibrator'].astype('category')\n",
    "image_info_df['calibrator'] = image_info_df['calibrator'].cat.reorder_categories([\n",
    "    'Uncalibrated',\n",
    "    'Vanilla',\n",
    "    'Temperature_Scaling', \n",
    "    'Vector_Scaling', \n",
    "    'Dirichlet_Scaling',\n",
    "    'LTS', \n",
    "    'NECTAR_Scaling'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_info_df['method_name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_info_df['ensemble_w_metric'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only the rows corresponding to group methods\n",
    "image_info_df = image_info_df[image_info_df['model_type'] == 'group']\n",
    "# group_methods_df = image_info_df\n",
    "\n",
    "image_info_df['method_name'] = image_info_df['method_name'].astype('category')\n",
    "image_info_df['method_name'] = image_info_df['method_name'].cat.reorder_categories([\n",
    "    'Average UNet',\n",
    "    'Ensemble (mean, logits)', \n",
    "    'Ensemble (mean, probs)', \n",
    "    'Ensemble (product, probs)', \n",
    "    # 'UNet (seed=40)', \n",
    "    # 'UNet (seed=41)', \n",
    "    # 'UNet (seed=42)', \n",
    "    # 'UNet (seed=43)', \n",
    "    ])\n",
    "\n",
    "# image_info_df['ensemble_w_metric'] = image_info_df['ensemble_w_metric'].astype('category')\n",
    "# image_info_df['ensemble_w_metric'] = image_info_df['ensemble_w_metric'].cat.reorder_categories([\n",
    "#     'None',\n",
    "#     'val-loss',\n",
    "#     'val-dice_score',\n",
    "#     'val-ece_loss',\n",
    "#     'val-elm_loss'\n",
    "# ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's looks at the calibration scores of our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.catplot(\n",
    "    data=image_info_df,\n",
    "    x=\"calibrator\",\n",
    "    y=\"ECE\",\n",
    "    hue=\"method_name\",\n",
    "    kind=\"bar\",\n",
    "    height=6,\n",
    "    aspect=2\n",
    ")\n",
    "# Set column spacingj\n",
    "g.fig.subplots_adjust(wspace=0.5)\n",
    "# # Set the y-axis limits\n",
    "# g.set(ylim=(0.0, 0.25))\n",
    "# Set the title of the plot\n",
    "g.fig.suptitle(\"ECE by Calibration Method and Model Class\")\n",
    "# Move the title slightly up\n",
    "g.fig.subplots_adjust(top=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.catplot(\n",
    "    data=image_info_df,\n",
    "    x=\"calibrator\",\n",
    "    y=\"Foreground-ECE\",\n",
    "    hue=\"method_name\",\n",
    "    kind=\"bar\",\n",
    "    height=6,\n",
    "    aspect=2\n",
    ")\n",
    "# Set column spacing\n",
    "# # Set the y-axis limits\n",
    "# g.set(ylim=(0.0, 0.25))\n",
    "# Set the title of the plot\n",
    "g.fig.suptitle(\"Foreground ECE by Calibration Method and Model Class\")\n",
    "# Move the title slightly up\n",
    "g.fig.subplots_adjust(top=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g = sns.catplot(\n",
    "#     data=image_info_df,\n",
    "#     x=\"calibrator\",\n",
    "#     y=\"CW-ECE\",\n",
    "#     hue=\"method_name\",\n",
    "#     kind=\"bar\",\n",
    "#     height=6,\n",
    "#     aspect=2\n",
    "# )\n",
    "# # Set column spacing\n",
    "# # # Set the y-axis limits\n",
    "# # g.set(ylim=(0.0, 0.25))\n",
    "# g.fig.suptitle(\"CW ECE by Calibration Method and Model Class\")\n",
    "# # Move the title slightly up\n",
    "# g.fig.subplots_adjust(top=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.catplot(\n",
    "    data=image_info_df,\n",
    "    x=\"calibrator\",\n",
    "    y=\"Edge-ECE\",\n",
    "    hue=\"method_name\",\n",
    "    kind=\"bar\",\n",
    "    height=6,\n",
    "    aspect=2\n",
    ")\n",
    "# Set column spacing\n",
    "# # Set the y-axis limits\n",
    "# g.set(ylim=(0.0, 0.25))\n",
    "g.fig.suptitle(\"Edge ECE by Calibration Method and Model Class\")\n",
    "# Move the title slightly up\n",
    "g.fig.subplots_adjust(top=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.catplot(\n",
    "    data=image_info_df,\n",
    "    x=\"calibrator\",\n",
    "    y=\"ELM\",\n",
    "    hue=\"method_name\",\n",
    "    kind=\"bar\",\n",
    "    height=6,\n",
    "    aspect=2\n",
    ")\n",
    "# Set column spacing\n",
    "# # Set the y-axis limits\n",
    "# g.set(ylim=(0.0, 0.25))\n",
    "g.fig.suptitle(\"ELM by Calibration Method and Model Class\")\n",
    "# Move the title slightly up\n",
    "g.fig.subplots_adjust(top=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we can look at the quality averages themselves, first looking slice-wise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_df = image_info_df.groupby([\"method_name\", \"calibrator\", \"image_metric\", \"ensemble\"])['metric_score'].mean().reset_index()\n",
    "dice_table = image_info_df[image_info_df[\"image_metric\"] == \"Dice\"]\n",
    "dice_loss_table = image_info_df[image_info_df[\"image_metric\"] == \"Dice Loss\"]\n",
    "hd95_table = image_info_df[image_info_df[\"image_metric\"] == \"HD95\"]\n",
    "# Sort these by method name so they are consistent in the figures\n",
    "dice_table = dice_table.sort_values(by=['method_name'])\n",
    "dice_loss_table = dice_loss_table.sort_values(by=['method_name'])\n",
    "hd95_table = hd95_table.sort_values(by=['method_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pickled df corresponding to the upper-bound of the uncalibrated UNets\n",
    "from ese.experiment.analysis.analysis_utils.inference_utils import load_upperbound_df \n",
    "\n",
    "# Fill the column corresponding to slice_idx with string 'None'\n",
    "upperbound_df = load_upperbound_df(results_cfg['log'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if upperbound_df is not None:\n",
    "    dice_ub_df = upperbound_df[upperbound_df[\"image_metric\"] == \"Dice\"]\n",
    "    dice_loss_ub_df = upperbound_df[upperbound_df[\"image_metric\"] == \"Dice Loss\"]\n",
    "    hd_ub_df = upperbound_df[upperbound_df[\"image_metric\"] == \"HD95\"]\n",
    "    # De Nan the dice_ub_df\n",
    "    dice_ub_df = dice_ub_df[dice_ub_df['metric_score'].notna()]\n",
    "    dice_loss_ub_df = dice_loss_ub_df[dice_loss_ub_df['metric_score'].notna()]\n",
    "    hd_ub_df = hd_ub_df[hd_ub_df['metric_score'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upperbound_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ese.experiment.analysis.analysis_utils.plot_utils import plot_upperbound_line\n",
    "\n",
    "# g = sns.catplot(\n",
    "#     data=dice_loss_table,\n",
    "#     x=\"calibrator\",\n",
    "#     y=\"metric_score\",\n",
    "#     hue=\"method_name\",\n",
    "#     # hue=\"ensemble_w_metric\",\n",
    "#     # col=\"method_name\",\n",
    "#     kind=\"bar\",\n",
    "#     height=6,\n",
    "#     aspect=2\n",
    "# )\n",
    "# num_calibrators = len(image_info_df['calibrator'].unique())\n",
    "# if upperbound_df is not None:\n",
    "#     plot_upperbound_line(dice_loss_ub_df[\"metric_score\"], num_calibrators=num_calibrators)\n",
    "# # Set the title of the bar plot\n",
    "# g.fig.suptitle(\"WMH Dice Loss for Different Calibration Methods (Per Slice)\")\n",
    "# # Give the title a bit of spacing from the plot\n",
    "# g.fig.subplots_adjust(top=0.90)\n",
    "# # Set the y axis to be between 0.5 and 1.0\n",
    "# calibrators_width = num_calibrators - 1\n",
    "# g.set(xlim=(-0.8, calibrators_width + 0.8))\n",
    "# g.set(ylim=(0.15, 0.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ese.experiment.analysis.analysis_utils.plot_utils import plot_upperbound_line\n",
    "\n",
    "g = sns.catplot(\n",
    "    data=dice_loss_table,\n",
    "    x=\"calibrator\",\n",
    "    y=\"metric_score\",\n",
    "    hue=\"method_name\",\n",
    "    # hue=\"ensemble_w_metric\",\n",
    "    # col=\"method_name\",\n",
    "    kind=\"bar\",\n",
    "    height=6,\n",
    "    aspect=2\n",
    ")\n",
    "num_calibrators = len(image_info_df['calibrator'].unique())\n",
    "if upperbound_df is not None:\n",
    "    plot_upperbound_line(dice_loss_ub_df[\"metric_score\"], num_calibrators=num_calibrators)\n",
    "# Set the title of the bar plot\n",
    "g.fig.suptitle(\"CityScapes Dice Loss for Different Calibration Methods (Per Slice)\")\n",
    "# Give the title a bit of spacing from the plot\n",
    "g.fig.subplots_adjust(top=0.90)\n",
    "# Set the y axis to be between 0.5 and 1.0\n",
    "calibrators_width = num_calibrators - 1\n",
    "g.set(xlim=(-0.8, calibrators_width + 0.8))\n",
    "g.set(ylim=(0.17, 0.35))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g = sns.catplot(\n",
    "#     data=hd95_table,\n",
    "#     x=\"calibrator\",\n",
    "#     y=\"metric_score\",\n",
    "#     hue=\"method_name\",\n",
    "#     # hue=\"ensemble_w_metric\",\n",
    "#     # col=\"method_name\",\n",
    "#     kind=\"bar\",\n",
    "#     height=6,\n",
    "#     aspect=2\n",
    "# )\n",
    "# num_calibrators = len(image_info_df['calibrator'].unique())\n",
    "# if upperbound_df is not None:\n",
    "#     plot_upperbound_line(hd_ub_df[\"metric_score\"], num_calibrators=num_calibrators)\n",
    "# # Set the title of the bar plot\n",
    "# g.fig.suptitle(\"WMH Hausdorff Distance for Different Calibration Methods (Per Slice)\")\n",
    "# # Give the title a bit of spacing from the plot\n",
    "# g.fig.subplots_adjust(top=0.90)\n",
    "# # Set the y axis to be between 0.5 and 1.0\n",
    "# calibrators_width = num_calibrators - 1\n",
    "# g.set(xlim=(-0.8, calibrators_width + 0.8))\n",
    "# g.set(ylim=(3.5, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.catplot(\n",
    "    data=hd95_table,\n",
    "    x=\"calibrator\",\n",
    "    y=\"metric_score\",\n",
    "    hue=\"method_name\",\n",
    "    # hue=\"ensemble_w_metric\",\n",
    "    # col=\"method_name\",\n",
    "    kind=\"bar\",\n",
    "    height=6,\n",
    "    aspect=2\n",
    ")\n",
    "num_calibrators = len(image_info_df['calibrator'].unique())\n",
    "if upperbound_df is not None:\n",
    "    plot_upperbound_line(hd_ub_df[\"metric_score\"], num_calibrators=num_calibrators)\n",
    "# Set the title of the bar plot\n",
    "g.fig.suptitle(\"CityScapes Hausdorff Distance for Different Calibration Methods (Per Slice)\")\n",
    "# Give the title a bit of spacing from the plot\n",
    "g.fig.subplots_adjust(top=0.90)\n",
    "# Set the y axis to be between 0.5 and 1.0\n",
    "calibrators_width = num_calibrators - 1\n",
    "g.set(xlim=(-0.8, calibrators_width + 0.8))\n",
    "g.set(ylim=(27, 52))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we want to consider these averaged within subjects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subj_image_info_df = image_info_df.groupby([\"method_name\", \"model_class\", \"qual_metric\", \"ensemble\", \"data_id\"])['qual_score'].mean().reset_index()\n",
    "\n",
    "# subject_dice_table = subj_image_info_df[subj_image_info_df[\"qual_metric\"] == \"Dice\"]\n",
    "# subject_hd95_table = subj_image_info_df[subj_image_info_df[\"qual_metric\"] == \"HD95\"]\n",
    "# # sort these by method name so they are consistent in the tables\n",
    "# subject_dice_table = subject_dice_table.sort_values(by=['method_name'])\n",
    "# subject_hd95_table = subject_hd95_table.sort_values(by=['method_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g = sns.catplot(\n",
    "#     data=subject_hd95_table,\n",
    "#     x=\"model_class\",\n",
    "#     y=\"qual_score\",\n",
    "#     hue=\"method_name\",\n",
    "#     kind=\"bar\",\n",
    "#     height=4,\n",
    "#     aspect=2\n",
    "# )\n",
    "# # Set the title of the bar plot\n",
    "# g.fig.suptitle(\"Hausdorff Distance for Different Calibration Methods (Per Subject)\")\n",
    "# # Give the title a bit of spacing from the plot\n",
    "# g.fig.subplots_adjust(top=0.90)\n",
    "# # Set the y axis to be between 4 and 8\n",
    "# g.set(ylim=(4, 14))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g = sns.catplot(\n",
    "#     data=subject_dice_table,\n",
    "#     x=\"model_class\",\n",
    "#     y=\"qual_score\",\n",
    "#     hue=\"method_name\",\n",
    "#     kind=\"bar\",\n",
    "#     height=4,\n",
    "#     aspect=2\n",
    "# )\n",
    "# # Set the title of the bar plot\n",
    "# g.fig.suptitle(\"Dice Score for Different Calibration Methods (Per Subject)\")\n",
    "# # Give the title a bit of spacing from the plot\n",
    "# g.fig.subplots_adjust(top=0.90)\n",
    "# # Set the y axis to be between 0.5 and 1.0\n",
    "# g.set(ylim=(0.6, 0.9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make some tables to show these relationships in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Custom formatting function to display 3 significant digits\n",
    "# def format_sigfigs(x, num_sigfigs):\n",
    "#     if isinstance(x, (int, float)):\n",
    "#         format_str = '{:.' + str(num_sigfigs) + 'g}'\n",
    "#         return format_str.format(x)  # Using format to display in scientific notation with specified significant digits\n",
    "#     else:\n",
    "#         return x  # Return the value as is if it's not numeric\n",
    "\n",
    "# # Applying the formatting function to the pivot table\n",
    "# formatted_dice_table = dice_table.applymap(format_sigfigs, num_sigfigs=3)\n",
    "# # Applying the formatting function to the pivot table\n",
    "# formatted_hd95_table = hd95_table.applymap(format_sigfigs, num_sigfigs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# formatted_dice_table.pivot(index='method_name', columns='model_class', values='qual_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# formatted_hd95_table.pivot(index='method_name', columns='model_class', values='qual_score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's look first at the distribution of errors per configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ese.experiment.analysis.plot_utils import build_ensemble_vs_individual_cmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dice_image_df = image_info_df[image_info_df['qual_metric'] == 'Dice']\n",
    "# # Use seaborn to create KDE plot for each configuration\n",
    "# g = sns.displot(\n",
    "#     data=dice_image_df.sort_values('configuration'), \n",
    "#     x='qual_score', \n",
    "#     hue='configuration', \n",
    "#     kind='kde',\n",
    "#     palette=build_ensemble_vs_individual_cmap(dice_image_df),\n",
    "#     alpha=0.8\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dice_image_subject_df = dice_image_df.groupby(['configuration', 'data_id'])['qual_score'].mean().reset_index()\n",
    "# g = sns.displot(\n",
    "#     data=dice_image_subject_df.sort_values('configuration'), \n",
    "#     x='qual_score', \n",
    "#     hue='configuration', \n",
    "#     kind='kde',\n",
    "#     palette=build_ensemble_vs_individual_cmap(dice_image_df),\n",
    "#     alpha=0.8\n",
    "#     )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UniverSegTF",
   "language": "python",
   "name": "universegtf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
