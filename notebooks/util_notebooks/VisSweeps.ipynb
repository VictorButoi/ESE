{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/storage/vbutoi/projects')\n",
    "sys.path.append('/storage/vbutoi/libraries')\n",
    "sys.path.append('/storage/vbutoi/projects/ESE')\n",
    "sys.path.append('/storage/vbutoi/projects/UniverSeg')\n",
    "\n",
    "import os \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "# Ionpy imports\n",
    "from ionpy.analysis import ResultsLoader\n",
    "# Local imports\n",
    "from ese.analysis.analyze_inf import load_cal_inference_stats\n",
    "from ese.analysis.analysis_utils.plot_utils import get_prop_color_palette\n",
    "from ese.analysis.analysis_utils.parse_sweep import get_global_optimal_parameter, get_per_subject_optimal_values\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.set_context(\"talk\")\n",
    "os.environ['DATAPATH'] = ':'.join((\n",
    "       '/storage/vbutoi/datasets',\n",
    "))\n",
    "root = Path(\"/storage/vbutoi/scratch/ESE\")\n",
    "pd.set_option('display.max_rows', 50)\n",
    "rs = ResultsLoader()\n",
    "\n",
    "# For using code without restarting.\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# For using yaml configs.\n",
    "%load_ext yamlmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%yaml results_cfg \n",
    "\n",
    "log:\n",
    "    root: '/storage/vbutoi/scratch/ESE/inference/11_04_24_UVS_ACDC_ICCrossEval'\n",
    "    inference_group: \n",
    "        - 'Sweep_Threshold'\n",
    "        # - 'Sweep_Temperature'\n",
    "\n",
    "options:\n",
    "    verify_graceful_exit: True\n",
    "    equal_rows_per_cfg_assert: False "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful cell for controlling the plotting functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ######This cells controls what gets plotted in the following cells so we don't have to change each one\n",
    "x_key = 'threshold'\n",
    "y_key = 'hard_RAVE'\n",
    "xtick_range = np.arange(0, 1.1, 0.1)\n",
    "cmap = 'viridis_r'\n",
    "aspect = 1\n",
    "x_lims = (0, 1)\n",
    "y_lims = (-0.5, 2)\n",
    "\n",
    "# x_key = 'temperature'\n",
    "# y_key = 'soft_RAVE'\n",
    "# xtick_range = np.arange(0, 3.1, 0.1)\n",
    "# cmap = 'magma_r'\n",
    "# aspect = 2\n",
    "# x_lims = (0, 3.0)\n",
    "# y_lims = (-0.5, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting Calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_df = load_cal_inference_stats(\n",
    "    results_cfg=results_cfg,\n",
    "    load_cached=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for ikey in inference_df.keys():\n",
    "#     print(ikey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only keep the rows where the image_metric is 'Dice'\n",
    "inference_df = inference_df[inference_df['image_metric'] == 'Dice']\n",
    "# Rename the column metric score for this new df to Dice\n",
    "inference_df = inference_df.rename(columns={'metric_score': 'Dice'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_df['split'] = 'train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_keep = [\n",
    "    'soft_abs_area_estimation_error',\n",
    "    'hard_abs_area_estimation_error',\n",
    "    'soft_RAVE',\n",
    "    'hard_RAVE',\n",
    "    'log_soft_RAVE',\n",
    "    'log_hard_RAVE',\n",
    "    'Dice',\n",
    "    'dataset',\n",
    "    'loss_func_class',\n",
    "    'threshold',\n",
    "    'temperature',\n",
    "    'hard_volume',\n",
    "    'soft_volume',\n",
    "    'gt_volume',\n",
    "    'data_id',\n",
    "    'split'\n",
    "]\n",
    "# Filter out the columns we want to keep\n",
    "exp_df = inference_df[cols_to_keep].drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################################################\n",
    "# This cell is quite important, it allows us to see the base soft volume for each data_id and loss_func_class\n",
    "##############################################################################################################\n",
    "# We want to add a base soft volume column to let us so what the uncalibrated volume is.\n",
    "bsv = exp_df[exp_df['temperature'] == 1.01][['data_id', 'loss_func_class', 'soft_volume']].drop_duplicates().reset_index(drop=True)\n",
    "# Make a new column that is the combination of data_id and loss_func_class\n",
    "bsv['data_id_experiment_model_dir'] = bsv['data_id'] + '_' + bsv['loss_func_class']\n",
    "exp_df['data_id_experiment_model_dir'] = exp_df['data_id'] + '_' + exp_df['loss_func_class']\n",
    "# Drop the columns data_id and loss_func_class\n",
    "bsv = bsv.drop(columns=['data_id', 'loss_func_class'])\n",
    "# Convert this to a dictionary mapping from data_id to base soft volume\n",
    "bsv_dict = dict(zip(bsv['data_id_experiment_model_dir'], bsv['soft_volume']))\n",
    "# Make a new column of exp_df, called base_soft_volume, where the value is the corresponding value for the data_id of that row in the bsv_dict\n",
    "exp_df['base_soft_volume'] = exp_df['data_id_experiment_model_dir'].map(bsv_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to make sure that the cal split goes first.\n",
    "exp_df = exp_df.sort_values('split', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30, 20))\n",
    "# We want to plot the mean error vs temperature\n",
    "g = sns.relplot(\n",
    "    data=exp_df,\n",
    "    x=x_key,\n",
    "    y=y_key,\n",
    "    hue='loss_func_class',\n",
    "    row='split',\n",
    "    kind='line',\n",
    "    height=10,\n",
    "    aspect=aspect,\n",
    "    # legend=(x_key == 'temperature')\n",
    ")\n",
    "# If the x_key is temperature, place a dashed red vertical line at 1.01\n",
    "if x_key == 'temperature':\n",
    "    for ax in g.axes.flat:\n",
    "        ax.axvline(x=1.01, color='r', linestyle='--')\n",
    "else:\n",
    "    for ax in g.axes.flat:\n",
    "        ax.axvline(x=0.5, color='r', linestyle='--')\n",
    "\n",
    "g.set(xticks=xtick_range, xlim=x_lims, ylim=y_lims)\n",
    "# Make a global title using suptitle with some spacing\n",
    "plt.suptitle(f'{exp_df[\"dataset\"].unique()[0]}: {y_key} vs {x_key}', fontsize=30)\n",
    "# Add spacing between the title and the plot\n",
    "plt.subplots_adjust(top=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30, 20))\n",
    "# We want to plot the mean error vs temperature\n",
    "g = sns.relplot(\n",
    "    data=exp_df,\n",
    "    x=x_key,\n",
    "    y='Dice',\n",
    "    hue='loss_func_class',\n",
    "    row='split',\n",
    "    kind='line',\n",
    "    height=10,\n",
    "    aspect=aspect,\n",
    "    # legend=(x_key == 'temperature')\n",
    ")\n",
    "# If the x_key is temperature, place a dashed red vertical line at 1.01\n",
    "if x_key == 'temperature':\n",
    "    for ax in g.axes.flat:\n",
    "        ax.axvline(x=1.01, color='r', linestyle='--')\n",
    "else:\n",
    "    for ax in g.axes.flat:\n",
    "        ax.axvline(x=0.5, color='r', linestyle='--')\n",
    "\n",
    "g.set(xticks=xtick_range, xlim=x_lims, ylim=[0, 1])\n",
    "# Make a global title using suptitle with some spacing\n",
    "plt.suptitle(f'{exp_df[\"dataset\"].unique()[0]}: Dice vs {x_key}', fontsize=30)\n",
    "# Add spacing between the title and the plot\n",
    "plt.subplots_adjust(top=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_global_optimal_parameter(\n",
    "#     exp_df, \n",
    "#     sweep_key=x_key, \n",
    "#     y_key=y_key,\n",
    "#     group_keys=['split', 'loss_func_class']\n",
    "# ).sort_values(y_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to plot the mean error vs temperature\n",
    "g = sns.relplot(\n",
    "    data=exp_df,\n",
    "    x=x_key,\n",
    "    y=y_key,\n",
    "    hue='data_id',\n",
    "    col='loss_func_class',\n",
    "    row='split',\n",
    "    # col='split',\n",
    "    kind='line',\n",
    "    height=8,\n",
    "    aspect=aspect,\n",
    "    legend=False,\n",
    "    palette=get_prop_color_palette(\n",
    "                exp_df, \n",
    "                hue_key='data_id', \n",
    "                magnitude_key='gt_volume',\n",
    "                cmap=cmap\n",
    "            )\n",
    ")\n",
    "\n",
    "g.set(xticks=xtick_range, ylim=y_lims, xlim=x_lims)\n",
    "# Make a global title using suptitle with some spacing\n",
    "plt.suptitle(f'{exp_df[\"dataset\"].unique()[0]}: {y_key} vs {x_key}', fontsize=30)\n",
    "# Add spacing between the title and the plot\n",
    "plt.subplots_adjust(top=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_perf_df, opt_temps_per_subj = get_per_subject_optimal_values(\n",
    "    exp_df, \n",
    "    sweep_key=x_key, \n",
    "    y_key=y_key,\n",
    "    group_keys=['split', 'loss_func_class'],\n",
    "    keep_keys=['hard_volume', 'base_soft_volume', 'gt_volume'],\n",
    "    return_optimal_values=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_temps_per_subj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corelations between Features and Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def log_hard_volume(hard_volume):\n",
    "#     return np.log(hard_volume + 1)\n",
    "\n",
    "# def log_base_soft_volume(base_soft_volume):\n",
    "#     return np.log(base_soft_volume + 1)\n",
    "\n",
    "# def log_gt_volume(gt_volume):\n",
    "#     return np.log(gt_volume + 1)\n",
    "\n",
    "# opt_temps_per_subj.augment(log_hard_volume)\n",
    "# opt_temps_per_subj.augment(log_base_soft_volume)\n",
    "# opt_temps_per_subj.augment(log_gt_volume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define a function to compute and annotate the correlation coefficient\n",
    "# def annotate_corr(data, **kws):\n",
    "#     x = data[kws['x_var']]\n",
    "#     y = data['temperature']\n",
    "#     r, _ = stats.pearsonr(x, y)\n",
    "#     ax = plt.gca()\n",
    "#     ax.annotate(f'r = {r:.2f}', xy=(0.05, 0.95), xycoords=ax.transAxes,\n",
    "#                 fontsize=25, verticalalignment='top', color='red')\n",
    "\n",
    "# def plot_feature_vs_temperature(x_feat):\n",
    "#     # Create the plot using sns.lmplot\n",
    "#     g = sns.lmplot(\n",
    "#         data=opt_temps_per_subj,\n",
    "#         x=x_feat,\n",
    "#         y='temperature',\n",
    "#         col='loss_func_class',\n",
    "#         row='split',\n",
    "#         height=8,\n",
    "#         aspect=aspect,\n",
    "#         scatter_kws={'s': 150},\n",
    "#         line_kws={'color': 'red'}\n",
    "#     )\n",
    "\n",
    "#     # Apply the annotation function to each subplot\n",
    "#     g.map_dataframe(annotate_corr, x_var=x_feat)\n",
    "\n",
    "#     # Adjust titles and layout\n",
    "#     g.set_titles(col_template=\"{col_name}\", row_template=\"{row_name}\")\n",
    "#     plt.subplots_adjust(top=0.9)\n",
    "#     plt.suptitle(f'{exp_df[\"dataset\"].unique()[0]}: {x_feat} vs {x_key}', fontsize=30)\n",
    "#     plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
