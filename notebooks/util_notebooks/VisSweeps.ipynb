{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/vbutoi/envs/UniverSegTF/lib/python3.9/site-packages/pydantic/_internal/_fields.py:149: UserWarning: Field \"model_dir\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/storage/vbutoi/projects')\n",
    "sys.path.append('/storage/vbutoi/libraries')\n",
    "sys.path.append('/storage/vbutoi/projects/ESE')\n",
    "sys.path.append('/storage/vbutoi/projects/UniverSeg')\n",
    "\n",
    "import os \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "# Ionpy imports\n",
    "from ionpy.analysis import ResultsLoader\n",
    "# Local imports\n",
    "from ese.analysis.analyze_inf import load_cal_inference_stats\n",
    "from ese.analysis.analysis_utils.plot_utils import get_prop_color_palette\n",
    "from ese.analysis.analysis_utils.parse_sweep import get_global_optimal_parameter, get_per_subject_optimal_values\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.set_context(\"talk\")\n",
    "os.environ['DATAPATH'] = ':'.join((\n",
    "       '/storage/vbutoi/datasets',\n",
    "))\n",
    "root = Path(\"/storage/vbutoi/scratch/ESE\")\n",
    "pd.set_option('display.max_rows', 50)\n",
    "rs = ResultsLoader()\n",
    "\n",
    "# For using code without restarting.\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# For using yaml configs.\n",
    "%load_ext yamlmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            require(\n                [\n                    \"notebook/js/codecell\",\n                    \"codemirror/mode/yaml/yaml\"\n                ],\n                function(cc){\n                    cc.CodeCell.options_default.highlight_modes.magic_yaml = {\n                        reg: [\"^%%yaml\"]\n                    }\n                }\n            );\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%yaml results_cfg \n",
    "\n",
    "log:\n",
    "    root: '/storage/vbutoi/scratch/ESE/inference/10_26_24_OCTA_Benchmark'\n",
    "    # root: '/storage/vbutoi/scratch/ESE/inference/10_29_24_OCTA_FULLRES_Updated_Benchmark'\n",
    "    # root: '/storage/vbutoi/scratch/ESE/inference/10_26_24_ISLES_Benchmark'\n",
    "    # root: '/storage/vbutoi/scratch/ESE/inference/10_26_24_Roads_FULLRES_Benchmark'\n",
    "    # root: '/storage/vbutoi/scratch/ESE/inference/10_28_24_WMH_AllHospitals_Benchmark'\n",
    "    inference_group: \n",
    "        # - 'Sweep_Threshold'\n",
    "        - 'Sweep_Temperature'\n",
    "\n",
    "options:\n",
    "    verify_graceful_exit: True\n",
    "    equal_rows_per_cfg_assert: False "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful cell for controlling the plotting functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ######This cells controls what gets plotted in the following cells so we don't have to change each one\n",
    "# x_key = 'threshold'\n",
    "# y_key = 'hard_RAVE'\n",
    "# xtick_range = np.arange(0, 1.1, 0.1)\n",
    "# cmap = 'viridis_r'\n",
    "# aspect = 1\n",
    "# x_lims = (0, 1)\n",
    "# y_lims = (-0.5, 2)\n",
    "\n",
    "x_key = 'threshold'\n",
    "y_key = 'Dice'\n",
    "xtick_range = np.arange(0, 1.1, 0.1)\n",
    "cmap = 'viridis_r'\n",
    "aspect = 1\n",
    "x_lims = (0, 1)\n",
    "y_lims = (-0.5, 2)\n",
    "\n",
    "# x_key = 'temperature'\n",
    "# y_key = 'soft_RAVE'\n",
    "# xtick_range = np.arange(0, 3.1, 0.1)\n",
    "# cmap = 'magma_r'\n",
    "# aspect = 2\n",
    "# x_lims = (0, 3.0)\n",
    "# y_lims = (-0.5, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting Calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished loading inference stats.\n",
      "Log amounts: log_root                                                                         log_set                                              \n",
      "/storage/vbutoi/scratch/ESE/inference/10_26_24_OCTA_Benchmark/Sweep_Temperature  20241025_124511-74GF-901892f6aa41b4912eb7103342d9a825    3640\n",
      "                                                                                 20241025_124515-3J1A-9889a8ae741cda6f8337909765550dad    3640\n",
      "                                                                                 20241025_124519-QE2B-f746e05815df694058d3cc028fd0e18d    1820\n",
      "                                                                                 20241025_124524-H07R-40be4680d5b49b992dd3c06daef70ae4    1820\n",
      "                                                                                 20241025_124528-3ORX-6c77262a024db07b2ff1232127e6e27d    3640\n",
      "                                                                                 20241025_124532-UT8J-899fd00a28f27488db1964de4121150f    3640\n",
      "                                                                                 20241025_124536-H1LN-80a8cf41e9ce6b42038c8555f2ac01be    1820\n",
      "                                                                                 20241025_124540-HYHB-1d0d7a891afd63c63f2bcffc92d9c145    1820\n",
      "                                                                                 20241025_124656-PV7Q-e9533c2d7325ac43361ef79437a482fa    3640\n",
      "                                                                                 20241025_124700-4ECF-f253f15a712e53e820bdbdd8c1bd3f18    3640\n",
      "                                                                                 20241025_124704-6ET7-ea7eb4b71b4ec3c29fbd24176dca273c    1820\n",
      "                                                                                 20241025_124708-X7DS-b95d1e4cf44f03a1157dacde4f79d17d    1820\n",
      "                                                                                 20241025_124712-7DD1-bd5488e986e349683a8bd157081d0357    3640\n",
      "                                                                                 20241025_124716-USLA-ce2374f84be39bed989d3d16103c4974    3640\n",
      "                                                                                 20241025_124721-OFB0-703d67caee4f2638e49221e6af585462    1820\n",
      "                                                                                 20241025_124725-PK47-abd7863442e7211ec6e12402036afac1    1820\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "inference_df = load_cal_inference_stats(\n",
    "    results_cfg=results_cfg,\n",
    "    load_cached=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for ikey in inference_df.keys():\n",
    "#     print(ikey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only keep the rows where the image_metric is 'Dice'\n",
    "inference_df = inference_df[inference_df['image_metric'] == 'Dice']\n",
    "# Rename the column metric score for this new df to Dice\n",
    "inference_df = inference_df.rename(columns={'metric_score': 'Dice'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['dataset'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 20\u001b[0m\n\u001b[1;32m      1\u001b[0m cols_to_keep \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoft_abs_area_estimation_error\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhard_abs_area_estimation_error\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msplit\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     18\u001b[0m ]\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Filter out the columns we want to keep\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m exp_df \u001b[38;5;241m=\u001b[39m \u001b[43minference_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcols_to_keep\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mdrop_duplicates()\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/envs/UniverSegTF/lib/python3.9/site-packages/pandas/core/frame.py:3813\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3811\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   3812\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 3813\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   3815\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m~/envs/UniverSegTF/lib/python3.9/site-packages/pandas/core/indexes/base.py:6070\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6067\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6068\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6070\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6072\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6073\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6074\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/envs/UniverSegTF/lib/python3.9/site-packages/pandas/core/indexes/base.py:6133\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6130\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6132\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m-> 6133\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['dataset'] not in index\""
     ]
    }
   ],
   "source": [
    "cols_to_keep = [\n",
    "    'soft_abs_area_estimation_error',\n",
    "    'hard_abs_area_estimation_error',\n",
    "    'soft_RAVE',\n",
    "    'hard_RAVE',\n",
    "    'log_soft_RAVE',\n",
    "    'log_hard_RAVE',\n",
    "    'Dice',\n",
    "    'dataset',\n",
    "    'loss_func_class',\n",
    "    'threshold',\n",
    "    'temperature',\n",
    "    'hard_volume',\n",
    "    'soft_volume',\n",
    "    'gt_volume',\n",
    "    'data_id',\n",
    "    'split'\n",
    "]\n",
    "# Filter out the columns we want to keep\n",
    "exp_df = inference_df[cols_to_keep].drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################################################\n",
    "# This cell is quite important, it allows us to see the base soft volume for each data_id and loss_func_class\n",
    "##############################################################################################################\n",
    "# We want to add a base soft volume column to let us so what the uncalibrated volume is.\n",
    "bsv = exp_df[exp_df['temperature'] == 1.01][['data_id', 'loss_func_class', 'soft_volume']].drop_duplicates().reset_index(drop=True)\n",
    "# Make a new column that is the combination of data_id and loss_func_class\n",
    "bsv['data_id_experiment_model_dir'] = bsv['data_id'] + '_' + bsv['loss_func_class']\n",
    "exp_df['data_id_experiment_model_dir'] = exp_df['data_id'] + '_' + exp_df['loss_func_class']\n",
    "# Drop the columns data_id and loss_func_class\n",
    "bsv = bsv.drop(columns=['data_id', 'loss_func_class'])\n",
    "# Convert this to a dictionary mapping from data_id to base soft volume\n",
    "bsv_dict = dict(zip(bsv['data_id_experiment_model_dir'], bsv['soft_volume']))\n",
    "# Make a new column of exp_df, called base_soft_volume, where the value is the corresponding value for the data_id of that row in the bsv_dict\n",
    "exp_df['base_soft_volume'] = exp_df['data_id_experiment_model_dir'].map(bsv_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to make sure that the cal split goes first.\n",
    "exp_df = exp_df.sort_values('split', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30, 20))\n",
    "# We want to plot the mean error vs temperature\n",
    "g = sns.relplot(\n",
    "    data=exp_df,\n",
    "    x=x_key,\n",
    "    y=y_key,\n",
    "    hue='loss_func_class',\n",
    "    row='split',\n",
    "    kind='line',\n",
    "    height=10,\n",
    "    aspect=aspect,\n",
    "    legend=(x_key == 'temperature')\n",
    ")\n",
    "# If the x_key is temperature, place a dashed red vertical line at 1.01\n",
    "if x_key == 'temperature':\n",
    "    for ax in g.axes.flat:\n",
    "        ax.axvline(x=1.01, color='r', linestyle='--')\n",
    "else:\n",
    "    for ax in g.axes.flat:\n",
    "        ax.axvline(x=0.5, color='r', linestyle='--')\n",
    "\n",
    "g.set(xticks=xtick_range, xlim=x_lims, ylim=y_lims)\n",
    "# Make a global title using suptitle with some spacing\n",
    "plt.suptitle(f'{exp_df[\"dataset\"].unique()[0]}: {y_key} vs {x_key}', fontsize=30)\n",
    "# Add spacing between the title and the plot\n",
    "plt.subplots_adjust(top=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_global_optimal_parameter(\n",
    "#     exp_df, \n",
    "#     sweep_key=x_key, \n",
    "#     y_key=y_key,\n",
    "#     group_keys=['split', 'loss_func_class']\n",
    "# ).sort_values(y_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to plot the mean error vs temperature\n",
    "g = sns.relplot(\n",
    "    data=exp_df,\n",
    "    x=x_key,\n",
    "    y=y_key,\n",
    "    hue='data_id',\n",
    "    col='loss_func_class',\n",
    "    row='split',\n",
    "    # col='split',\n",
    "    kind='line',\n",
    "    height=8,\n",
    "    aspect=aspect,\n",
    "    legend=False,\n",
    "    palette=get_prop_color_palette(\n",
    "                exp_df, \n",
    "                hue_key='data_id', \n",
    "                magnitude_key='gt_volume',\n",
    "                cmap=cmap\n",
    "            )\n",
    ")\n",
    "\n",
    "g.set(xticks=xtick_range, ylim=y_lims, xlim=x_lims)\n",
    "# Make a global title using suptitle with some spacing\n",
    "plt.suptitle(f'{exp_df[\"dataset\"].unique()[0]}: {y_key} vs {x_key}', fontsize=30)\n",
    "# Add spacing between the title and the plot\n",
    "plt.subplots_adjust(top=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_perf_df, opt_temps_per_subj = get_per_subject_optimal_values(\n",
    "    exp_df, \n",
    "    sweep_key=x_key, \n",
    "    y_key=y_key,\n",
    "    group_keys=['split', 'loss_func_class'],\n",
    "    keep_keys=['hard_volume', 'base_soft_volume', 'gt_volume'],\n",
    "    return_optimal_values=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_temps_per_subj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corelations between Features and Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def log_hard_volume(hard_volume):\n",
    "#     return np.log(hard_volume + 1)\n",
    "\n",
    "# def log_base_soft_volume(base_soft_volume):\n",
    "#     return np.log(base_soft_volume + 1)\n",
    "\n",
    "# def log_gt_volume(gt_volume):\n",
    "#     return np.log(gt_volume + 1)\n",
    "\n",
    "# opt_temps_per_subj.augment(log_hard_volume)\n",
    "# opt_temps_per_subj.augment(log_base_soft_volume)\n",
    "# opt_temps_per_subj.augment(log_gt_volume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define a function to compute and annotate the correlation coefficient\n",
    "# def annotate_corr(data, **kws):\n",
    "#     x = data[kws['x_var']]\n",
    "#     y = data['temperature']\n",
    "#     r, _ = stats.pearsonr(x, y)\n",
    "#     ax = plt.gca()\n",
    "#     ax.annotate(f'r = {r:.2f}', xy=(0.05, 0.95), xycoords=ax.transAxes,\n",
    "#                 fontsize=25, verticalalignment='top', color='red')\n",
    "\n",
    "# def plot_feature_vs_temperature(x_feat):\n",
    "#     # Create the plot using sns.lmplot\n",
    "#     g = sns.lmplot(\n",
    "#         data=opt_temps_per_subj,\n",
    "#         x=x_feat,\n",
    "#         y='temperature',\n",
    "#         col='loss_func_class',\n",
    "#         row='split',\n",
    "#         height=8,\n",
    "#         aspect=aspect,\n",
    "#         scatter_kws={'s': 150},\n",
    "#         line_kws={'color': 'red'}\n",
    "#     )\n",
    "\n",
    "#     # Apply the annotation function to each subplot\n",
    "#     g.map_dataframe(annotate_corr, x_var=x_feat)\n",
    "\n",
    "#     # Adjust titles and layout\n",
    "#     g.set_titles(col_template=\"{col_name}\", row_template=\"{row_name}\")\n",
    "#     plt.subplots_adjust(top=0.9)\n",
    "#     plt.suptitle(f'{exp_df[\"dataset\"].unique()[0]}: {x_feat} vs {x_key}', fontsize=30)\n",
    "#     plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
