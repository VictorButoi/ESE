{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thunderpack import ThunderReader\n",
    "\n",
    "reader = ThunderReader('/storage/vbutoi/datasets/MSD/old_thunder_files/HepaticVessel/CT/0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(reader.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(reader['_splits'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def data_splits(\n",
    "    values: List[str], \n",
    "    splits: Tuple[float, float, float, float], \n",
    "    seed: int\n",
    ") -> Tuple[List[str], List[str], List[str], List[str]]:\n",
    "\n",
    "    if len(set(values)) != len(values):\n",
    "        raise ValueError(f\"Duplicate entries found in values\")\n",
    "\n",
    "    # Super weird bug, removing for now, add up to 1!\n",
    "    # if (s := sum(splits)) != 1.0:\n",
    "    #     raise ValueError(f\"Splits must add up to 1.0, got {splits}->{s}\")\n",
    "\n",
    "    train_size, cal_size, val_size, test_size = splits\n",
    "    values = sorted(values)\n",
    "    # First get the size of the test splut\n",
    "    traincalval, test = train_test_split(values, test_size=test_size, random_state=seed)\n",
    "    # Next size of the val split\n",
    "    val_ratio = val_size / (train_size + cal_size + val_size)\n",
    "    traincal, val = train_test_split(traincalval, test_size=val_ratio, random_state=seed)\n",
    "    # Next size of the cal split\n",
    "    cal_ratio = cal_size / (train_size + cal_size)\n",
    "    train, cal = train_test_split(traincal, test_size=cal_ratio, random_state=seed)\n",
    "\n",
    "    assert sorted(train + cal + val + test) == values, \"Missing Values\"\n",
    "\n",
    "    return (train, cal, val, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def find_folders_with_mdb_files(root_dir):\n",
    "    matching_folders = []\n",
    "\n",
    "    for dirpath, dirnames, filenames in os.walk(root_dir):\n",
    "        if 'data.mdb' in filenames and 'lock.mdb' in filenames:\n",
    "            matching_folders.append(dirpath)\n",
    "\n",
    "    return matching_folders\n",
    "\n",
    "# # Replace 'old_file_root' with the path to your root directory\n",
    "# old_file_root = '/storage/vbutoi/datasets/MSD/old_thunder_files'\n",
    "# thunder_folders = find_folders_with_mdb_files(old_file_root)\n",
    "\n",
    "# # Print the paths of matching folders\n",
    "# for folder in thunder_folders:\n",
    "#     print(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thunderpack import ThunderDB\n",
    "\n",
    "# Replace 'old_file_root' with the path to your root directory\n",
    "old_file_root = '/storage/vbutoi/datasets/MSD/old_thunder_files'\n",
    "thunder_folders = find_folders_with_mdb_files(old_file_root)\n",
    "\n",
    "old_prefix = \"/storage/vbutoi/datasets/MSD/old_thunder_files\"\n",
    "new_folder_prefix = \"/storage/vbutoi/datasets/MSD/thunder_MSD/v4.2/MSD\"\n",
    "splits_seed = 42\n",
    "splits_ratio = (0.6, 0.2, 0.1, 0.1)\n",
    "\n",
    "for old_thunder_path in thunder_folders:\n",
    "    new_path = old_thunder_path.replace(old_prefix, new_folder_prefix)\n",
    "    old_db_obj = ThunderReader(old_thunder_path)\n",
    "    print(\"Task:\", old_thunder_path, \"Num Examples:\", len(old_db_obj['_subjects']))\n",
    "    # If the new path folder doesn't exist, create it\n",
    "    # if not os.path.exists(new_path):\n",
    "    #     os.makedirs(new_path)\n",
    "    # print(\"Moved:\", old_thunder_path, \"->\", new_path)\n",
    "    # ### Make a new ThunderDB object that is identical to the old one, but with new splits.\n",
    "    # with ThunderDB.open(str(new_path), \"c\") as new_db:\n",
    "    #     for key in old_db_obj.keys():\n",
    "    #         if key != \"_splits\":\n",
    "    #             new_db[key] = old_db_obj[key]\n",
    "    #     # Redo the splits! \n",
    "    #     subjects = sorted(new_db['_subjects'])\n",
    "    #     splits = data_splits(subjects, splits_ratio, splits_seed)\n",
    "    #     # Finally, put the new splits in\n",
    "    #     new_db['_splits'] = dict(zip((\"train\", \"cal\", \"val\", \"test\"), splits))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UniverSegTF",
   "language": "python",
   "name": "universegtf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
