{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/storage/vbutoi/projects')\n",
    "sys.path.append('/storage/vbutoi/libraries')\n",
    "sys.path.append('/storage/vbutoi/projects/ESE')\n",
    "sys.path.append('/storage/vbutoi/projects/UniverSeg')\n",
    "\n",
    "# Standard imports\n",
    "import os \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "# Ionpy imports\n",
    "from ionpy.analysis import ResultsLoader\n",
    "# Local imports\n",
    "from ese.analysis.analyze_inf import load_cal_inference_stats\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.set_context(\"talk\")\n",
    "os.environ['DATAPATH'] = ':'.join((\n",
    "       '/storage/vbutoi/datasets',\n",
    "))\n",
    "root = Path(\"/storage/vbutoi/scratch/ESE\")\n",
    "rs = ResultsLoader()\n",
    "\n",
    "# For using code without restarting.\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# For using yaml configs.\n",
    "%load_ext yamlmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%yaml results_cfg \n",
    "\n",
    "log:\n",
    "    root:\n",
    "        - '/storage/vbutoi/scratch/ESE/inference/10_26_24_OCTA_Benchmark'\n",
    "        - '/storage/vbutoi/scratch/ESE/inference/10_26_24_ISLES_Benchmark'\n",
    "        - '/storage/vbutoi/scratch/ESE/inference/10_26_24_WMH_Benchmark'\n",
    "        - '/storage/vbutoi/scratch/ESE/inference/10_26_24_Roads_FULLRES_Benchmark'\n",
    "    inference_group: \n",
    "        - 'Base'\n",
    "        - 'Optimal_RAVE_Threshold'\n",
    "        - 'Optimal_RAVE_Temperature'\n",
    "\n",
    "options:\n",
    "    verify_graceful_exit: True\n",
    "    equal_rows_per_cfg_assert: False "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting Calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_df = load_cal_inference_stats(\n",
    "    results_cfg=results_cfg,\n",
    "    load_cached=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def method_group(log_root):\n",
    "    suffix = log_root.split('/')[-1]\n",
    "    if \"Base\" in suffix:\n",
    "        return \"Base\"\n",
    "    elif \"Threshold\" in suffix:\n",
    "        return \"Threshold Tuned Hard\"\n",
    "    elif \"Temperature\" in suffix:\n",
    "        return \"Temperature Tuned Soft\"\n",
    "    else:\n",
    "        raise ValueError(\"Unknown method\")\n",
    "\n",
    "def pred_volume(method_group, hard_volume, soft_volume):\n",
    "    if method_group == \"Threshold Tuned Hard\": \n",
    "        return hard_volume\n",
    "    elif method_group == \"Temperature Tuned Soft\":\n",
    "        return soft_volume\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def dataset(experiment_inf_dataset_name):\n",
    "    return experiment_inf_dataset_name\n",
    "\n",
    "inference_df.augment(dataset)\n",
    "inference_df.augment(method_group)\n",
    "inference_df.augment(pred_volume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the rows corresponding to the base methods, and drop them frm the dataframe\n",
    "base_rows = inference_df[inference_df['method_group'] == 'Base']\n",
    "tuned_df = inference_df[inference_df['method_group'] != 'Base'].copy()\n",
    "\n",
    "# Now we duplicate the base_rows.\n",
    "hard_thresh_df = base_rows.copy()\n",
    "hard_thresh_df['pred_volume'] = hard_thresh_df['hard_volume']\n",
    "hard_thresh_df['method_group'] = 'Base Hard'\n",
    "\n",
    "soft_thresh_df = base_rows.copy()\n",
    "soft_thresh_df['pred_volume'] = soft_thresh_df['soft_volume']\n",
    "soft_thresh_df['method_group'] = 'Base Soft'\n",
    "\n",
    "# Concatenate the new rows to the dataframe\n",
    "methods_df = pd.concat([tuned_df, hard_thresh_df, soft_thresh_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assert that there are no NaNs in pred_volume or gt_volume\n",
    "assert not methods_df['pred_volume'].isna().any()\n",
    "assert not methods_df['gt_volume'].isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VE(pred_volume, gt_volume):\n",
    "    return np.abs(pred_volume - gt_volume)\n",
    "\n",
    "def RAVE(pred_volume, gt_volume):\n",
    "    return np.abs(pred_volume - gt_volume) / gt_volume\n",
    "\n",
    "def log_VE(VE):\n",
    "    log_soft_err = np.log(VE)\n",
    "    # if the error is negative infinity, we will return -2.\n",
    "    if log_soft_err == -np.inf:\n",
    "        return -3\n",
    "    else:\n",
    "        return log_soft_err\n",
    "\n",
    "def loss_func(loss_func_class):\n",
    "    if loss_func_class == \"ese.losses.PixelCELoss\":\n",
    "        return \"CrossEntropy\"\n",
    "    elif loss_func_class == \"ese.losses.SoftDiceLoss\":\n",
    "        return \"SoftDice\"\n",
    "    else:\n",
    "        raise ValueError(\"Unknown loss function\")\n",
    "\n",
    "methods_df.augment(loss_func)\n",
    "methods_df.augment(VE)\n",
    "methods_df.augment(RAVE)\n",
    "methods_df.augment(log_VE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bookkeeping to make sure we aren't double counting,\n",
    "for split in methods_df['split'].unique():\n",
    "    print(split, len(methods_df[methods_df['split'] == split]['data_id'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to prune the df to the cols we care about\n",
    "cols_to_keep = [\n",
    "    \"pred_volume\",\n",
    "    \"gt_volume\",\n",
    "    \"VE\",\n",
    "    \"log_VE\",\n",
    "    \"RAVE\",\n",
    "    \"loss_func\",\n",
    "    \"dataset\",\n",
    "    \"split\",\n",
    "    \"data_id\",\n",
    "    \"method_group\"\n",
    "]\n",
    "# Prune the dataframe\n",
    "analyis_df = methods_df[cols_to_keep].drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyis_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look at Method Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_analyis_df = analyis_df[analyis_df['split'] == 'val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.catplot(\n",
    "    val_analyis_df, \n",
    "    x='loss_func', \n",
    "    y='RAVE', \n",
    "    hue='method_group', \n",
    "    kind='box',\n",
    "    col='dataset',\n",
    "    aspect=1.5,\n",
    "    height=6,\n",
    "    showfliers=False,\n",
    "    sharey=False\n",
    ")\n",
    "# We want to make a title for the plot, with some spacing \n",
    "g.fig.subplots_adjust(top=0.8)\n",
    "g.fig.suptitle(f\"Relative Absolute Volumetric Error (RAVE) by Method, Loss Function, and Dataset\", fontsize=23)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
