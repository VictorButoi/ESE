{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/vbutoi/envs/UniverSegTF/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/mnt/hdd/home/vbutoi/envs/UniverSegTF/lib/python3.9/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n",
      "/local/vbutoi/envs/UniverSegTF/lib/python3.9/site-packages/pydantic/_internal/_fields.py:149: UserWarning: Field \"model_dir\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/storage/vbutoi/projects')\n",
    "sys.path.append('/storage/vbutoi/libraries')\n",
    "sys.path.append('/storage/vbutoi/projects/ESE')\n",
    "sys.path.append('/storage/vbutoi/projects/UniverSeg')\n",
    "\n",
    "# Standard imports\n",
    "import os \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "# Ionpy imports\n",
    "from ionpy.analysis import ResultsLoader\n",
    "# Local imports\n",
    "from ese.analysis.analyze_inf import load_cal_inference_stats\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.set_context(\"talk\")\n",
    "os.environ['DATAPATH'] = ':'.join((\n",
    "       '/storage/vbutoi/datasets',\n",
    "))\n",
    "root = Path(\"/storage/vbutoi/scratch/ESE\")\n",
    "rs = ResultsLoader()\n",
    "\n",
    "# For using code without restarting.\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# For using yaml configs.\n",
    "%load_ext yamlmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            require(\n                [\n                    \"notebook/js/codecell\",\n                    \"codemirror/mode/yaml/yaml\"\n                ],\n                function(cc){\n                    cc.CodeCell.options_default.highlight_modes.magic_yaml = {\n                        reg: [\"^%%yaml\"]\n                    }\n                }\n            );\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%yaml results_cfg \n",
    "\n",
    "log:\n",
    "    root:\n",
    "        - '/storage/vbutoi/scratch/ESE/inference/11_05_24_UVS_InContext_CrossEval'\n",
    "    inference_group: \n",
    "        - 'Base'\n",
    "        # - 'Optimal_Dice_Threshold'\n",
    "        - 'Optimal_RAVE_Threshold'\n",
    "\n",
    "options:\n",
    "    verify_graceful_exit: True\n",
    "    equal_rows_per_cfg_assert: False "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting Calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading log configs: 100%|██████████| 30/30 [00:00<00:00, 77.83it/s]\n",
      "Loading image stats: 100%|██████████| 30/30 [00:08<00:00,  3.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: The number of rows in the image_info_df is not the same for all log sets. Got log.root                                                                                       log_set                                              \n",
      "/storage/vbutoi/scratch/ESE/inference/11_05_24_UVS_InContext_CrossEval/Base                    20241105_110332-FGSY-77badd7cd1734748825ac49135b4887f     180\n",
      "                                                                                               20241105_110335-M77Y-ae115739b9a20dea65cb92d15593735d     440\n",
      "                                                                                               20241105_110340-BJ3D-671fba858a9084204bb3c56753544af8     400\n",
      "                                                                                               20241105_110344-CWQB-d638adc2f532357a939ea4ad2b048c72      40\n",
      "                                                                                               20241105_110429-X95K-3971a71503dc3f0b78e7de4003e9ea54      60\n",
      "                                                                                               20241105_110433-DNA8-a9eee47fa99be0ed74ef8dd24f97f945     120\n",
      "                                                                                               20241105_110437-S8PL-816380d5dc74b4a0eaf7670273d94c29      60\n",
      "                                                                                               20241105_110441-JWBV-62d43e8d2f70119dbcb529f55b2ac7a4     120\n",
      "                                                                                               20241105_110522-4UG5-71bca619603b0a8ad20137806d501de8      60\n",
      "                                                                                               20241105_110526-VN74-5cd77acf127b38e8a12b6be0ed94f9c3      80\n",
      "                                                                                               20241105_110530-OION-22c9d8f248372dc2e941003184046499     400\n",
      "                                                                                               20241105_110534-QE0B-61380a37baf67383fd21b542d7f18c22    1200\n",
      "/storage/vbutoi/scratch/ESE/inference/11_05_24_UVS_InContext_CrossEval/Optimal_Dice_Threshold  20241105_115032-ZE6G-1f2b44a9dff4dfdc1809b45b7cfd52b3     180\n",
      "                                                                                               20241105_115036-38KP-0516589bca2adffd25dca7cfea189892     440\n",
      "                                                                                               20241105_115041-EW6G-d2e0565e133771a178fef177fd208c55     400\n",
      "                                                                                               20241105_115045-2PB8-79a366e934c767f5dd748af682131d4f      40\n",
      "                                                                                               20241105_115123-4ZCA-283604eca4aa323f31ac51d18eb473b0      60\n",
      "                                                                                               20241105_115127-4BE0-fe23d573f7a68441997f74ebe7bd5464     120\n",
      "                                                                                               20241105_115131-28HW-9270503e81251ce399750af452357d7b      60\n",
      "                                                                                               20241105_115135-H0CB-3818e1906c8e9301b3b2da57a65167b3     120\n",
      "                                                                                               20241105_115159-GMZ0-eea340438ecca6d67b91db27f3fcf543      60\n",
      "                                                                                               20241105_115204-HVE6-0d326555afb3b16404aec3d7e08695bb      80\n",
      "                                                                                               20241105_115208-Z2RZ-b7df18ad46690765d768bf9e8144bc82     400\n",
      "                                                                                               20241105_115212-03UR-b51ce5d46abe99276f1379c2b0bcc026    1200\n",
      "dtype: int64.\n",
      "Finished loading inference stats.\n"
     ]
    }
   ],
   "source": [
    "inference_df = load_cal_inference_stats(\n",
    "    results_cfg=results_cfg,\n",
    "    load_cached=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for ikey in inference_df.keys():\n",
    "#     print(ikey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['PanDental/v1/XRay/0', 'SCD/VIS_human/MRI/2', 'WBC/CV/EM/0',\n",
       "       'SCD/LAF_Pre/MRI/2', 'SpineWeb/Dataset7/MR/0',\n",
       "       'PanDental/v2/XRay/0', 'SCD/LAS/MRI/2', 'SCD/VIS_pig/MRI/2',\n",
       "       'SCD/LAF_Post/MRI/2', 'WBC/JTSC/EM/0',\n",
       "       'STARE/retrieved_2021_12_06/Retinal/0', 'ACDC/Challenge2017/MRI/2'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference_df['inference_data_task'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def method_group(log_root):\n",
    "    suffix = log_root.split('/')[-1]\n",
    "    if \"Base\" in suffix:\n",
    "        return \"Base\"\n",
    "    elif \"Threshold\" in suffix:\n",
    "        return \"Threshold Tuned Hard\"\n",
    "    elif \"Temperature\" in suffix:\n",
    "        return \"Temperature Tuned Soft\"\n",
    "    else:\n",
    "        raise ValueError(\"Unknown method\")\n",
    "\n",
    "def pred_volume(method_group, hard_volume, soft_volume):\n",
    "    if method_group == \"Threshold Tuned Hard\": \n",
    "        return hard_volume\n",
    "    elif method_group == \"Temperature Tuned Soft\":\n",
    "        return soft_volume\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def dataset(inference_data_class):\n",
    "    return inference_data_class.split('.')[-1]\n",
    "\n",
    "inference_df.augment(dataset)\n",
    "inference_df.augment(pred_volume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the rows corresponding to the base methods, and drop them frm the dataframe\n",
    "base_rows = inference_df[inference_df['method_group'] == 'Base']\n",
    "tuned_df = inference_df[inference_df['method_group'] != 'Base'].copy()\n",
    "\n",
    "# Now we duplicate the base_rows.\n",
    "hard_thresh_df = base_rows.copy()\n",
    "hard_thresh_df['pred_volume'] = hard_thresh_df['hard_volume']\n",
    "hard_thresh_df['method_group'] = 'Base Hard'\n",
    "\n",
    "soft_thresh_df = base_rows.copy()\n",
    "soft_thresh_df['pred_volume'] = soft_thresh_df['soft_volume']\n",
    "soft_thresh_df['method_group'] = 'Base Soft'\n",
    "\n",
    "# Concatenate the new rows to the dataframe\n",
    "methods_df = pd.concat([tuned_df, hard_thresh_df, soft_thresh_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assert that there are no NaNs in pred_volume or gt_volume\n",
    "assert not methods_df['pred_volume'].isna().any()\n",
    "assert not methods_df['gt_volume'].isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VE(pred_volume, gt_volume):\n",
    "\n",
    "def RVE(pred_volume, gt_volume):\n",
    "    return (pred_volume - gt_volume) / gt_volume\n",
    "\n",
    "def RAVE(pred_volume, gt_volume):\n",
    "    return np.abs(pred_volume - gt_volume) / gt_volume\n",
    "\n",
    "def log_VE(VE):\n",
    "    log_soft_err = np.log(VE + 1)\n",
    "    # if the error is negative infinity, we will return -2.\n",
    "    if log_soft_err == -np.inf:\n",
    "        return -3\n",
    "    else:\n",
    "        return log_soft_err\n",
    "\n",
    "def loss_func(loss_func_class):\n",
    "    if loss_func_class == \"ese.losses.PixelCELoss\":\n",
    "        return \"CrossEntropy\"\n",
    "    elif loss_func_class == \"ese.losses.SoftDiceLoss\":\n",
    "        return \"SoftDice\"\n",
    "    else:\n",
    "        raise ValueError(\"Unknown loss function\")\n",
    "\n",
    "methods_df.augment(loss_func)\n",
    "methods_df.augment(VE)\n",
    "methods_df.augment(RVE)\n",
    "methods_df.augment(RAVE)\n",
    "methods_df.augment(log_VE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only keep the rows where the image_metric is 'Dice'\n",
    "methods_df = methods_df[methods_df['image_metric'] == 'Dice']\n",
    "# Rename the column metric score for this new df to Dice\n",
    "methods_df = methods_df.rename(columns={'metric_score': 'Dice'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to prune the df to the cols we care about\n",
    "cols_to_keep = [\n",
    "    \"pred_volume\",\n",
    "    \"gt_volume\",\n",
    "    \"Dice\",\n",
    "    \"VE\",\n",
    "    \"RVE\",\n",
    "    \"log_VE\",\n",
    "    \"RAVE\",\n",
    "    \"loss_func\",\n",
    "    \"dataset\",\n",
    "    \"split\",\n",
    "    \"data_id\",\n",
    "    \"method_group\"\n",
    "]\n",
    "# Prune the dataframe\n",
    "analyis_df = methods_df[cols_to_keep].drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyis_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look at Method Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_analyis_df = analyis_df[analyis_df['split'] == 'val'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the unique values of the estimator column.\n",
    "val_analyis_df['method_group'] = val_analyis_df['method_group'].astype('category')\n",
    "val_analyis_df['method_group'] = val_analyis_df['method_group'].cat.reorder_categories([\n",
    "    'Base Hard',\n",
    "    'Base Soft',\n",
    "    'Threshold Tuned Hard',\n",
    "    'Temperature Tuned Soft'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.catplot(\n",
    "    val_analyis_df, \n",
    "    x='loss_func', \n",
    "    y='RAVE', \n",
    "    hue='method_group', \n",
    "    kind='box',\n",
    "    col='dataset',\n",
    "    aspect=1.5,\n",
    "    height=6,\n",
    "    showfliers=False,\n",
    "    sharey=False\n",
    ")\n",
    "# We want to make a title for the plot, with some spacing \n",
    "g.fig.subplots_adjust(top=0.8)\n",
    "g.fig.suptitle(f\"Relative Absolute Volumetric Error (RAVE) by Method, Loss Function, and Dataset\", fontsize=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.relplot(\n",
    "    val_analyis_df,\n",
    "    x='data_id', \n",
    "    y='RAVE', \n",
    "    hue='method_group', \n",
    "    kind='line',\n",
    "    col='dataset',\n",
    "    row='loss_func',\n",
    "    aspect=1.5,\n",
    "    height=6,\n",
    "    facet_kws={'sharex': False, 'sharey': False}\n",
    ")\n",
    "# Disable x tick labels\n",
    "g.set(xticklabels=[])\n",
    "g.set_axis_labels(\"Data-Id Ordered by Dice Score (Increasing)\", \"RAVE\")\n",
    "# We want to make a title for the plot, with some spacing \n",
    "g.fig.subplots_adjust(top=0.8)\n",
    "g.fig.suptitle(f\"Unsorted Relative Absolute Volumetric Error (RAVE) by Dataset (col) and Loss Function (row)\", fontsize=23)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by Dice Score\n",
    "vad_sortby_dice = val_analyis_df.sort_values(by='Dice', ascending=True)\n",
    "\n",
    "g = sns.relplot(\n",
    "    vad_sortby_dice,\n",
    "    x='data_id', \n",
    "    y='RAVE', \n",
    "    hue='method_group', \n",
    "    kind='line',\n",
    "    col='dataset',\n",
    "    row='loss_func',\n",
    "    aspect=1.5,\n",
    "    height=6,\n",
    "    facet_kws={'sharex': False, 'sharey': False}\n",
    ")\n",
    "# Disable x tick labels\n",
    "g.set(xticklabels=[])\n",
    "g.set_axis_labels(\"Data-Id Ordered by Dice Score (Increasing)\", \"RAVE\")\n",
    "# We want to make a title for the plot, with some spacing \n",
    "g.fig.subplots_adjust(top=0.8)\n",
    "g.fig.suptitle(f\"Sort by Dice Relative Absolute Volumetric Error (RAVE) by Dataset (col) and Loss Function (row)\", fontsize=23)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by Dice Score\n",
    "vad_sortby_gtvol = val_analyis_df.sort_values(by='gt_volume', ascending=True)\n",
    "\n",
    "g = sns.relplot(\n",
    "    vad_sortby_gtvol,\n",
    "    x='data_id', \n",
    "    y='RAVE', \n",
    "    hue='method_group', \n",
    "    kind='line',\n",
    "    col='dataset',\n",
    "    row='loss_func',\n",
    "    aspect=1.5,\n",
    "    height=6,\n",
    "    facet_kws={'sharex': False, 'sharey': False}\n",
    ")\n",
    "# Disable x tick labels\n",
    "g.set(xticklabels=[])\n",
    "g.set_axis_labels(\"Data-Id Ordered by Dice Score (Increasing)\", \"RAVE\")\n",
    "# We want to make a title for the plot, with some spacing \n",
    "g.fig.subplots_adjust(top=0.8)\n",
    "g.fig.suptitle(f\"Sort by GT Size Relative Absolute Volumetric Error (RAVE) by Dataset (col) and Loss Function (row)\", fontsize=23)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by Dice Score\n",
    "vad_sortby_gtvol = val_analyis_df.sort_values(by='gt_volume', ascending=True)\n",
    "\n",
    "g = sns.relplot(\n",
    "    vad_sortby_gtvol,\n",
    "    x='data_id', \n",
    "    y='RVE', \n",
    "    hue='method_group', \n",
    "    kind='line',\n",
    "    col='dataset',\n",
    "    row='loss_func',\n",
    "    aspect=1.5,\n",
    "    height=6,\n",
    "    facet_kws={'sharex': False, 'sharey': False}\n",
    ")\n",
    "# Disable x tick labels\n",
    "g.set(xticklabels=[])\n",
    "g.set_axis_labels(\"Data-Id Ordered by GT Amount (Increasing)\", \"RAVE\")\n",
    "# We want to make a title for the plot, with some spacing \n",
    "g.fig.subplots_adjust(top=0.8)\n",
    "g.fig.suptitle(f\"Sort by GT Size Relative Volumetric Error (RVE) by Dataset (col) and Loss Function (row)\", fontsize=23)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigating what's so bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vad_sortby_gtvol[vad_sortby_gtvol['loss_func'] == 'SoftDice'].head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vad_sortby_gtvol[vad_sortby_gtvol['loss_func'] == 'CrossEntropy'].head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the mean gt_volume by dataset\n",
    "gt_volume_means = val_analyis_df.groupby('dataset')['gt_volume'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_volume_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set per row the 'mean gt_volume' for that row's dataset\n",
    "val_analyis_df['mean_gt_volume'] = val_analyis_df['dataset'].map(gt_volume_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to visualize the distribution of ground truth volumes by dataset, noramlized by the mean\n",
    "def norm_gt_volume(gt_volume, mean_gt_volume):\n",
    "    return gt_volume / mean_gt_volume\n",
    "\n",
    "val_analyis_df.augment(norm_gt_volume)\n",
    "\n",
    "# Visualize using KDE plos in a facet grid\n",
    "g = sns.FacetGrid(\n",
    "    val_analyis_df, \n",
    "    col='dataset', \n",
    "    aspect=1.5, \n",
    "    height=6, \n",
    "    sharey=False\n",
    ")\n",
    "g.map(sns.kdeplot, 'norm_gt_volume', fill=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
