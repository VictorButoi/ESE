{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/storage/vbutoi/projects')\n",
    "sys.path.append('/storage/vbutoi/libraries')\n",
    "sys.path.append('/storage/vbutoi/projects/ESE')\n",
    "sys.path.append('/storage/vbutoi/projects/UniverSeg')\n",
    "\n",
    "# Standard imports\n",
    "import os \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "# Ionpy imports\n",
    "from ionpy.analysis import ResultsLoader\n",
    "# Local imports\n",
    "from ese.analysis.analyze_inf import load_cal_inference_stats\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.set_context(\"talk\")\n",
    "os.environ['DATAPATH'] = ':'.join((\n",
    "       '/storage/vbutoi/datasets',\n",
    "))\n",
    "root = Path(\"/storage/vbutoi/scratch/ESE\")\n",
    "rs = ResultsLoader()\n",
    "\n",
    "# For using code without restarting.\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# For using yaml configs.\n",
    "%load_ext yamlmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%yaml results_cfg \n",
    "\n",
    "log:\n",
    "    root:\n",
    "        - '/storage/vbutoi/scratch/ESE/inference/10_29_24_OCTA_FULLRES_Updated_Benchmark'\n",
    "        - '/storage/vbutoi/scratch/ESE/inference/10_26_24_ISLES_Benchmark'\n",
    "        - '/storage/vbutoi/scratch/ESE/inference/10_28_24_WMH_AllHospitals_Benchmark'\n",
    "    inference_group: \n",
    "        - 'Base'\n",
    "        - 'Optimal_RAVE_Threshold'\n",
    "        - 'Optimal_RAVE_Temperature'\n",
    "\n",
    "options:\n",
    "    verify_graceful_exit: True\n",
    "    equal_rows_per_cfg_assert: False "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting Calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_df = load_cal_inference_stats(\n",
    "    results_cfg=results_cfg,\n",
    "    load_cached=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for ikey in inference_df.keys():\n",
    "#     print(ikey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_df['inference_data_class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def method_group(log_root):\n",
    "    suffix = log_root.split('/')[-1]\n",
    "    if \"Base\" in suffix:\n",
    "        return \"Base\"\n",
    "    elif \"Threshold\" in suffix:\n",
    "        return \"Threshold Tuned Hard\"\n",
    "    elif \"Temperature\" in suffix:\n",
    "        return \"Temperature Tuned Soft\"\n",
    "    else:\n",
    "        raise ValueError(\"Unknown method\")\n",
    "\n",
    "def pred_volume(method_group, hard_volume, soft_volume):\n",
    "    if method_group == \"Threshold Tuned Hard\": \n",
    "        return hard_volume\n",
    "    elif method_group == \"Temperature Tuned Soft\":\n",
    "        return soft_volume\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def dataset(inference_data_class):\n",
    "    return inference_data_class.split('.')[-1]\n",
    "\n",
    "inference_df.augment(dataset)\n",
    "inference_df.augment(method_group)\n",
    "inference_df.augment(pred_volume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the rows corresponding to the base methods, and drop them frm the dataframe\n",
    "base_rows = inference_df[inference_df['method_group'] == 'Base']\n",
    "tuned_df = inference_df[inference_df['method_group'] != 'Base'].copy()\n",
    "\n",
    "# Now we duplicate the base_rows.\n",
    "hard_thresh_df = base_rows.copy()\n",
    "hard_thresh_df['pred_volume'] = hard_thresh_df['hard_volume']\n",
    "hard_thresh_df['method_group'] = 'Base Hard'\n",
    "\n",
    "soft_thresh_df = base_rows.copy()\n",
    "soft_thresh_df['pred_volume'] = soft_thresh_df['soft_volume']\n",
    "soft_thresh_df['method_group'] = 'Base Soft'\n",
    "\n",
    "# Concatenate the new rows to the dataframe\n",
    "methods_df = pd.concat([tuned_df, hard_thresh_df, soft_thresh_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assert that there are no NaNs in pred_volume or gt_volume\n",
    "assert not methods_df['pred_volume'].isna().any()\n",
    "assert not methods_df['gt_volume'].isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VE(pred_volume, gt_volume):\n",
    "    return np.abs(pred_volume - gt_volume)\n",
    "\n",
    "def RVE(pred_volume, gt_volume):\n",
    "    return (pred_volume - gt_volume) / gt_volume\n",
    "\n",
    "def RAVE(pred_volume, gt_volume):\n",
    "    return np.abs(pred_volume - gt_volume) / gt_volume\n",
    "\n",
    "def log_VE(VE):\n",
    "    log_soft_err = np.log(VE + 1)\n",
    "    # if the error is negative infinity, we will return -2.\n",
    "    if log_soft_err == -np.inf:\n",
    "        return -3\n",
    "    else:\n",
    "        return log_soft_err\n",
    "\n",
    "def loss_func(loss_func_class):\n",
    "    if loss_func_class == \"ese.losses.PixelCELoss\":\n",
    "        return \"CrossEntropy\"\n",
    "    elif loss_func_class == \"ese.losses.SoftDiceLoss\":\n",
    "        return \"SoftDice\"\n",
    "    else:\n",
    "        raise ValueError(\"Unknown loss function\")\n",
    "\n",
    "methods_df.augment(loss_func)\n",
    "methods_df.augment(VE)\n",
    "methods_df.augment(RVE)\n",
    "methods_df.augment(RAVE)\n",
    "methods_df.augment(log_VE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only keep the rows where the image_metric is 'Dice'\n",
    "methods_df = methods_df[methods_df['image_metric'] == 'Dice']\n",
    "# Rename the column metric score for this new df to Dice\n",
    "methods_df = methods_df.rename(columns={'metric_score': 'Dice'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to prune the df to the cols we care about\n",
    "cols_to_keep = [\n",
    "    \"pred_volume\",\n",
    "    \"gt_volume\",\n",
    "    \"Dice\",\n",
    "    \"VE\",\n",
    "    \"RVE\",\n",
    "    \"log_VE\",\n",
    "    \"RAVE\",\n",
    "    \"loss_func\",\n",
    "    \"dataset\",\n",
    "    \"split\",\n",
    "    \"data_id\",\n",
    "    \"method_group\"\n",
    "]\n",
    "# Prune the dataframe\n",
    "analyis_df = methods_df[cols_to_keep].drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyis_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look at Method Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_analyis_df = analyis_df[analyis_df['split'] == 'val'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the unique values of the estimator column.\n",
    "val_analyis_df['method_group'] = val_analyis_df['method_group'].astype('category')\n",
    "val_analyis_df['method_group'] = val_analyis_df['method_group'].cat.reorder_categories([\n",
    "    'Base Hard',\n",
    "    'Base Soft',\n",
    "    'Threshold Tuned Hard',\n",
    "    'Temperature Tuned Soft'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.catplot(\n",
    "    val_analyis_df, \n",
    "    x='loss_func', \n",
    "    y='RAVE', \n",
    "    hue='method_group', \n",
    "    kind='box',\n",
    "    col='dataset',\n",
    "    aspect=1.5,\n",
    "    height=6,\n",
    "    showfliers=False,\n",
    "    sharey=False\n",
    ")\n",
    "# We want to make a title for the plot, with some spacing \n",
    "g.fig.subplots_adjust(top=0.8)\n",
    "g.fig.suptitle(f\"Relative Absolute Volumetric Error (RAVE) by Method, Loss Function, and Dataset\", fontsize=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.relplot(\n",
    "    val_analyis_df,\n",
    "    x='data_id', \n",
    "    y='RAVE', \n",
    "    hue='method_group', \n",
    "    kind='line',\n",
    "    col='dataset',\n",
    "    row='loss_func',\n",
    "    aspect=1.5,\n",
    "    height=6,\n",
    "    facet_kws={'sharex': False, 'sharey': False}\n",
    ")\n",
    "# Disable x tick labels\n",
    "g.set(xticklabels=[])\n",
    "g.set_axis_labels(\"Data-Id Ordered by Dice Score (Increasing)\", \"RAVE\")\n",
    "# We want to make a title for the plot, with some spacing \n",
    "g.fig.subplots_adjust(top=0.8)\n",
    "g.fig.suptitle(f\"Unsorted Relative Absolute Volumetric Error (RAVE) by Dataset (col) and Loss Function (row)\", fontsize=23)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by Dice Score\n",
    "vad_sortby_dice = val_analyis_df.sort_values(by='Dice', ascending=True)\n",
    "\n",
    "g = sns.relplot(\n",
    "    vad_sortby_dice,\n",
    "    x='data_id', \n",
    "    y='RAVE', \n",
    "    hue='method_group', \n",
    "    kind='line',\n",
    "    col='dataset',\n",
    "    row='loss_func',\n",
    "    aspect=1.5,\n",
    "    height=6,\n",
    "    facet_kws={'sharex': False, 'sharey': False}\n",
    ")\n",
    "# Disable x tick labels\n",
    "g.set(xticklabels=[])\n",
    "g.set_axis_labels(\"Data-Id Ordered by Dice Score (Increasing)\", \"RAVE\")\n",
    "# We want to make a title for the plot, with some spacing \n",
    "g.fig.subplots_adjust(top=0.8)\n",
    "g.fig.suptitle(f\"Sort by Dice Relative Absolute Volumetric Error (RAVE) by Dataset (col) and Loss Function (row)\", fontsize=23)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by Dice Score\n",
    "vad_sortby_gtvol = val_analyis_df.sort_values(by='gt_volume', ascending=True)\n",
    "\n",
    "g = sns.relplot(\n",
    "    vad_sortby_gtvol,\n",
    "    x='data_id', \n",
    "    y='RAVE', \n",
    "    hue='method_group', \n",
    "    kind='line',\n",
    "    col='dataset',\n",
    "    row='loss_func',\n",
    "    aspect=1.5,\n",
    "    height=6,\n",
    "    facet_kws={'sharex': False, 'sharey': False}\n",
    ")\n",
    "# Disable x tick labels\n",
    "g.set(xticklabels=[])\n",
    "g.set_axis_labels(\"Data-Id Ordered by Dice Score (Increasing)\", \"RAVE\")\n",
    "# We want to make a title for the plot, with some spacing \n",
    "g.fig.subplots_adjust(top=0.8)\n",
    "g.fig.suptitle(f\"Sort by GT Size Relative Absolute Volumetric Error (RAVE) by Dataset (col) and Loss Function (row)\", fontsize=23)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by Dice Score\n",
    "vad_sortby_gtvol = val_analyis_df.sort_values(by='gt_volume', ascending=True)\n",
    "\n",
    "g = sns.relplot(\n",
    "    vad_sortby_gtvol,\n",
    "    x='data_id', \n",
    "    y='RVE', \n",
    "    hue='method_group', \n",
    "    kind='line',\n",
    "    col='dataset',\n",
    "    row='loss_func',\n",
    "    aspect=1.5,\n",
    "    height=6,\n",
    "    facet_kws={'sharex': False, 'sharey': False}\n",
    ")\n",
    "# Disable x tick labels\n",
    "g.set(xticklabels=[])\n",
    "g.set_axis_labels(\"Data-Id Ordered by GT Amount (Increasing)\", \"RAVE\")\n",
    "# We want to make a title for the plot, with some spacing \n",
    "g.fig.subplots_adjust(top=0.8)\n",
    "g.fig.suptitle(f\"Sort by GT Size Relative Volumetric Error (RVE) by Dataset (col) and Loss Function (row)\", fontsize=23)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigating what's so bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vad_sortby_gtvol[vad_sortby_gtvol['loss_func'] == 'SoftDice'].head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vad_sortby_gtvol[vad_sortby_gtvol['loss_func'] == 'CrossEntropy'].head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the mean gt_volume by dataset\n",
    "gt_volume_means = val_analyis_df.groupby('dataset')['gt_volume'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_volume_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set per row the 'mean gt_volume' for that row's dataset\n",
    "val_analyis_df['mean_gt_volume'] = val_analyis_df['dataset'].map(gt_volume_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to visualize the distribution of ground truth volumes by dataset, noramlized by the mean\n",
    "def norm_gt_volume(gt_volume, mean_gt_volume):\n",
    "    return gt_volume / mean_gt_volume\n",
    "\n",
    "val_analyis_df.augment(norm_gt_volume)\n",
    "\n",
    "# Visualize using KDE plos in a facet grid\n",
    "g = sns.FacetGrid(\n",
    "    val_analyis_df, \n",
    "    col='dataset', \n",
    "    aspect=1.5, \n",
    "    height=6, \n",
    "    sharey=False\n",
    ")\n",
    "g.map(sns.kdeplot, 'norm_gt_volume', fill=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
