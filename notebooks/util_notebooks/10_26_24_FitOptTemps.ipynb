{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/storage/vbutoi/projects')\n",
    "sys.path.append('/storage/vbutoi/libraries')\n",
    "sys.path.append('/storage/vbutoi/projects/ESE')\n",
    "sys.path.append('/storage/vbutoi/projects/UniverSeg')\n",
    "\n",
    "import os \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "# Ionpy imports\n",
    "from ionpy.analysis import ResultsLoader\n",
    "# Local imports\n",
    "from ese.analysis.analyze_inf import load_cal_inference_stats\n",
    "from ese.analysis.analysis_utils.plot_utils import get_prop_color_palette\n",
    "from ese.analysis.analysis_utils.parse_sweep import get_global_optimal_parameter, get_per_subject_optimal_values\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.set_context(\"talk\")\n",
    "os.environ['DATAPATH'] = ':'.join((\n",
    "       '/storage/vbutoi/datasets',\n",
    "))\n",
    "root = Path(\"/storage/vbutoi/scratch/ESE\")\n",
    "rs = ResultsLoader()\n",
    "\n",
    "# For using code without restarting.\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# For using yaml configs.\n",
    "%load_ext yamlmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%yaml results_cfg \n",
    "\n",
    "log:\n",
    "    # root: '/storage/vbutoi/scratch/ESE/inference/10_26_24_OCTA_Benchmark'\n",
    "    # root: '/storage/vbutoi/scratch/ESE/inference/10_26_24_ISLES_Benchmark'\n",
    "    # root: '/storage/vbutoi/scratch/ESE/inference/10_26_24_Roads_FULLRES_Benchmark'\n",
    "    root: '/storage/vbutoi/scratch/ESE/inference/10_26_24_WMH_Benchmark'\n",
    "    inference_group: 'Sweep_Temperature'\n",
    "\n",
    "options:\n",
    "    verify_graceful_exit: True\n",
    "    equal_rows_per_cfg_assert: False "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful cell for controlling the plotting functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_key = 'temperature'\n",
    "y_key = 'soft_RAVE'\n",
    "xtick_range = np.arange(0, 3.1, 0.1)\n",
    "cmap = 'magma_r'\n",
    "aspect = 2\n",
    "y_lims = (-0.5, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting Calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_df = load_cal_inference_stats(\n",
    "    results_cfg=results_cfg,\n",
    "    load_cached=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset(inference_data_class):\n",
    "    return inference_data_class.split('.')[-1]\n",
    "\n",
    "inference_df.augment(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for ikey in inference_df.keys():\n",
    "#     print(ikey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_keep = [\n",
    "    'soft_abs_area_estimation_error',\n",
    "    'soft_log_abs_area_estimation_error',\n",
    "    'hard_abs_area_estimation_error',\n",
    "    'hard_log_abs_area_estimation_error',\n",
    "    'soft_RAVE',\n",
    "    'hard_RAVE',\n",
    "    'dataset',\n",
    "    'loss_func_class',\n",
    "    'temperature',\n",
    "    'hard_volume',\n",
    "    'soft_volume',\n",
    "    'gt_volume',\n",
    "    'data_id',\n",
    "    'split'\n",
    "]\n",
    "# Filter out the columns we want to keep\n",
    "exp_df = inference_df[cols_to_keep].drop_duplicates().reset_index(drop=True)\n",
    "# We need to make sure that the cal split goes first.\n",
    "exp_df = exp_df.sort_values('split', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################################################\n",
    "# This cell is quite important, it allows us to see the base soft volume for each data_id and loss_func_class\n",
    "##############################################################################################################\n",
    "# We want to add a base soft volume column to let us so what the uncalibrated volume is.\n",
    "bsv = exp_df[exp_df['temperature'] == 1.01][['data_id', 'loss_func_class', 'soft_volume']].drop_duplicates().reset_index(drop=True)\n",
    "# Make a new column that is the combination of data_id and loss_func_class\n",
    "bsv['data_id_loss_func'] = bsv['data_id'] + '_' + bsv['loss_func_class']\n",
    "exp_df['data_id_loss_func'] = exp_df['data_id'] + '_' + exp_df['loss_func_class']\n",
    "# Drop the columns data_id and loss_func_class\n",
    "bsv = bsv.drop(columns=['data_id', 'loss_func_class'])\n",
    "# Convert this to a dictionary mapping from data_id to base soft volume\n",
    "bsv_dict = dict(zip(bsv['data_id_loss_func'], bsv['soft_volume']))\n",
    "# Make a new column of exp_df, called base_soft_volume, where the value is the corresponding value for the data_id of that row in the bsv_dict\n",
    "exp_df['base_soft_volume'] = exp_df['data_id_loss_func'].map(bsv_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30, 20))\n",
    "# We want to plot the mean error vs temperature\n",
    "g = sns.relplot(\n",
    "    data=exp_df,\n",
    "    x=x_key,\n",
    "    y=y_key,\n",
    "    hue='loss_func_class',\n",
    "    row='split',\n",
    "    kind='line',\n",
    "    height=10,\n",
    "    aspect=aspect,\n",
    "    legend=(x_key == 'temperature')\n",
    ")\n",
    "\n",
    "g.set(xticks=xtick_range, ylim=y_lims)\n",
    "# Make a global title using suptitle with some spacing\n",
    "plt.suptitle(f'{exp_df[\"dataset\"].unique()[0]}: {y_key} vs {x_key}', fontsize=30)\n",
    "# Add spacing between the title and the plot\n",
    "plt.subplots_adjust(top=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_opt_temp_df = get_global_optimal_parameter(\n",
    "    exp_df, \n",
    "    sweep_key=x_key, \n",
    "    y_key=y_key,\n",
    "    group_keys=['split', 'loss_func_class']\n",
    ").sort_values(y_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global_opt_temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to plot the mean error vs temperature\n",
    "g = sns.relplot(\n",
    "    data=exp_df,\n",
    "    x=x_key,\n",
    "    y=y_key,\n",
    "    hue='data_id',\n",
    "    col='loss_func_class',\n",
    "    row='split',\n",
    "    # col='split',\n",
    "    kind='line',\n",
    "    height=8,\n",
    "    aspect=aspect,\n",
    "    legend=False,\n",
    "    palette=get_prop_color_palette(\n",
    "                exp_df, \n",
    "                hue_key='data_id', \n",
    "                magnitude_key='gt_volume',\n",
    "                cmap=cmap\n",
    "            )\n",
    ")\n",
    "\n",
    "g.set(xticks=xtick_range, ylim=y_lims)\n",
    "# Make a global title using suptitle with some spacing\n",
    "plt.suptitle(f'{exp_df[\"dataset\"].unique()[0]}: {y_key} vs {x_key}', fontsize=30)\n",
    "# Add spacing between the title and the plot\n",
    "plt.subplots_adjust(top=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to plot the mean error vs temperature\n",
    "g = sns.relplot(\n",
    "    data=exp_df,\n",
    "    x=x_key,\n",
    "    y=y_key,\n",
    "    hue='data_id',\n",
    "    col='loss_func_class',\n",
    "    row='split',\n",
    "    # col='split',\n",
    "    kind='line',\n",
    "    height=8,\n",
    "    aspect=aspect,\n",
    "    legend=False,\n",
    "    palette=get_prop_color_palette(\n",
    "                exp_df, \n",
    "                hue_key='data_id', \n",
    "                magnitude_key='hard_volume',\n",
    "                cmap=cmap\n",
    "            )\n",
    ")\n",
    "\n",
    "g.set(xticks=xtick_range, ylim=y_lims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to plot the mean error vs temperature\n",
    "g = sns.relplot(\n",
    "    data=exp_df,\n",
    "    x=x_key,\n",
    "    y=y_key,\n",
    "    hue='data_id',\n",
    "    col='loss_func_class',\n",
    "    row='split',\n",
    "    kind='line',\n",
    "    height=8,\n",
    "    aspect=aspect,\n",
    "    legend=False,\n",
    "    palette=get_prop_color_palette(\n",
    "                exp_df, \n",
    "                hue_key='data_id', \n",
    "                magnitude_key='base_soft_volume',\n",
    "                cmap=cmap\n",
    "            )\n",
    ")\n",
    "\n",
    "g.set(xticks=xtick_range, ylim=y_lims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_temps_per_subj, opt_df = get_per_subject_optimal_values(\n",
    "    exp_df, \n",
    "    sweep_key=x_key, \n",
    "    y_key=y_key,\n",
    "    group_keys=['split', 'loss_func_class'],\n",
    "    keep_keys=['hard_volume'],\n",
    "    return_optimal_values=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(opt_df['data_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Models and evaluation\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "# Import additional regression models\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet, HuberRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor, AdaBoostRegressor, ExtraTreesRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_fn = 'ese.losses.SoftDiceLoss'\n",
    "loss_fn = 'ese.losses.PixelCELoss'\n",
    "df = opt_df[opt_df['loss_func_class'] == loss_fn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and validation sets based on 'split' column\n",
    "df_train = df[df['split'] == 'cal']\n",
    "df_val = df[df['split'] == 'val']\n",
    "\n",
    "X_train = df_train[['hard_volume']]\n",
    "X_val = df_val[['hard_volume']]\n",
    "\n",
    "# Prepare the features (X) and target (y)\n",
    "y_train = df_train['temperature']\n",
    "y_val = df_val['temperature']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the models to test, including additional regressors\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Ridge Regression': Ridge(),\n",
    "    'Lasso Regression': Lasso(),\n",
    "    'ElasticNet Regression': ElasticNet(),\n",
    "    'Kernel Ridge Regression': KernelRidge(),\n",
    "    'Huber Regressor': HuberRegressor(),\n",
    "    'Polynomial Regression (degree=2)': make_pipeline(PolynomialFeatures(degree=2), LinearRegression()),\n",
    "    'Polynomial Regression (degree=3)': make_pipeline(PolynomialFeatures(degree=3), LinearRegression()),\n",
    "    'K-Nearest Neighbors': KNeighborsRegressor(),\n",
    "    'Decision Tree': DecisionTreeRegressor(random_state=42),\n",
    "    'Random Forest': RandomForestRegressor(random_state=42),\n",
    "    'Extra Trees Regressor': ExtraTreesRegressor(random_state=42),\n",
    "    'Gradient Boosting Regressor': GradientBoostingRegressor(random_state=42),\n",
    "    'AdaBoost Regressor': AdaBoostRegressor(random_state=42),\n",
    "    'Support Vector Regression': SVR(),\n",
    "    'MLP Regressor': MLPRegressor(random_state=42, max_iter=1000),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store the results\n",
    "results = {}\n",
    "\n",
    "# Train and evaluate each model\n",
    "for name, model in models.items():\n",
    "    # Fit the model\n",
    "    model.fit(X_train, y_train)\n",
    "    # Predict on validation set\n",
    "    y_pred = model.predict(X_val)\n",
    "    # Evaluate\n",
    "    mse = mean_squared_error(y_val, y_pred)\n",
    "    r2 = r2_score(y_val, y_pred)\n",
    "    # Store the results\n",
    "    results[name] = {'MSE': mse, 'R2 Score': r2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We also want to add our baseline of predicting a global optimal temperature\n",
    "loss_fn_global_temp = global_opt_temp_df[global_opt_temp_df['loss_func_class'] == loss_fn]\n",
    "cal_estimate_global_temp = float(loss_fn_global_temp[loss_fn_global_temp['split'] == 'cal']['temperature'])\n",
    "# Make the y_pred by repeating the global temperature for each validation sample\n",
    "y_pred_global_temp = np.repeat(cal_estimate_global_temp, len(y_val))\n",
    "# Evaluate\n",
    "mse = mean_squared_error(y_val, y_pred_global_temp)\n",
    "r2 = r2_score(y_val, y_pred_global_temp)\n",
    "# Store the results\n",
    "results['Global Optimal Temperature'] = {'MSE': mse, 'R2 Score': r2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert results to a DataFrame for better visualization\n",
    "results_df = pd.DataFrame(results).T  # Transpose for better format\n",
    "# We want to srt by the best MSE\n",
    "results_df = results_df.sort_values('MSE')\n",
    "print(\"Model Performance:\")\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the predictions vs actual values for each model in subplots\n",
    "import math\n",
    "\n",
    "# Determine the layout of the subplot grid\n",
    "num_models = len(models)\n",
    "cols = 2  # Reduce the number of columns for larger subplots\n",
    "rows = math.ceil(num_models / cols)  # Calculate the number of rows needed\n",
    "\n",
    "# Increase the figure size for larger subplots\n",
    "fig, axs = plt.subplots(rows, cols, figsize=(cols * 8, rows * 6))\n",
    "axs = axs.flatten()  # Flatten the array of axes for easy iteration\n",
    "\n",
    "# Plot each model's predictions in a subplot\n",
    "for idx, (name, model) in enumerate(models.items()):\n",
    "    y_pred = model.predict(X_val)\n",
    "    axs[idx].scatter(X_val, y_val, color='black', label='Actual Validation Data')\n",
    "    axs[idx].scatter(X_val, y_pred, color='blue', label='Predicted Data')\n",
    "    axs[idx].set_title(f\"{name}\")\n",
    "    axs[idx].set_xlabel('Hard Volume')\n",
    "    axs[idx].set_ylabel('Temperature')\n",
    "    axs[idx].legend()\n",
    "\n",
    "# Hide any unused subplots if the grid is larger than the number of models\n",
    "for idx in range(num_models, len(axs)):\n",
    "    fig.delaxes(axs[idx])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
