{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "\n",
    "%load_ext yamlmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%yaml results_cfg \n",
    "\n",
    "log:\n",
    "    root: \n",
    "        - '/storage/vbutoi/scratch/ESE/inference/10_26_24_OCTA_Benchmark'\n",
    "        - '/storage/vbutoi/scratch/ESE/inference/10_26_24_ISLES_Benchmark'\n",
    "        - '/storage/vbutoi/scratch/ESE/inference/10_26_24_Roads_FULLRES_Benchmark'\n",
    "        - '/storage/vbutoi/scratch/ESE/inference/10_26_24_WMH_Benchmark'\n",
    "    inference_group: 'Sweep_Temperature'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a dictionary to store the inference info.\n",
    "log_cfg = results_cfg[\"log\"] \n",
    "\n",
    "# Skip over metadata folders\n",
    "skip_log_folders = [\n",
    "    \"debug\",\n",
    "    \"wandb\", \n",
    "    \"submitit\", \n",
    "]\n",
    "# We need to get the roots and inference groups from the log_cfg.\n",
    "log_roots = log_cfg[\"root\"]\n",
    "log_inference_groups = log_cfg[\"inference_group\"]\n",
    "\n",
    "if isinstance(log_roots, str):\n",
    "    log_roots = [log_roots]\n",
    "if isinstance(log_inference_groups, str):\n",
    "    log_inference_groups = [log_inference_groups]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the log dir folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Gather inference log paths.\n",
    "all_inference_log_paths = []\n",
    "for root in log_roots:\n",
    "    for inf_group in log_inference_groups:\n",
    "        inf_group_dir = root + \"/\" + inf_group\n",
    "        group_folders = os.listdir(inf_group_dir)\n",
    "        # If 'submitit' is in the highest dir, then we don't have subdirs (new folder structure).\n",
    "        if \"submitit\" in group_folders:\n",
    "            # Check to make sure that this log wasn't the result of a crash.\n",
    "            all_inference_log_paths.append(Path(inf_group_dir))\n",
    "        # Otherwise, we had separated our runs in 'log sets', which isn't a good level of abstraction.\n",
    "        # but it's what we had done before.\n",
    "        else:\n",
    "            for sub_exp in group_folders:\n",
    "                sub_exp_log_path = inf_group_dir + \"/\" + sub_exp\n",
    "                # TODO: FIX THIS, I HATE THE SKIP_LOG_FOLDER PARADIGM.\n",
    "                # Verify that it is a folder and also that it is not in the skip_log_folders.\n",
    "                if os.path.isdir(sub_exp_log_path) and sub_exp not in skip_log_folders:\n",
    "                    sub_exp_group_folders = os.listdir(sub_exp_log_path)\n",
    "                    # If 'submitit' is in the highest dir, then we don't have subdirs (new folder structure).\n",
    "                    if \"submitit\" in sub_exp_group_folders:\n",
    "                        # Check to make sure that this log wasn't the result of a crash.\n",
    "                        all_inference_log_paths.append(Path(sub_exp_log_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_inference_log_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the actual config files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_files = []\n",
    "\n",
    "for log_dir in all_inference_log_paths:\n",
    "    for log_set in log_dir.iterdir():\n",
    "        # TODO: FIX THIS, I HATE THE SKIP_LOG_FOLDER PARADIGM.\n",
    "        # Verify that log_set is a directory and that it's not in the skip_log_folders.\n",
    "        if log_set.is_dir() and log_set.name not in skip_log_folders:\n",
    "            # Load the metadata file (json) and add it to the metadata dataframe.\n",
    "            logset_config_dir = log_set / \"config.yml\"\n",
    "            config_files.append(logset_config_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the file config path and print the contents.\n",
    "first_config = config_files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_yml(file_path):\n",
    "    # Step 1: Load the .yml file into a dictionary\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = yaml.safe_load(file)\n",
    "    \n",
    "    # We want to modify the exp_root\n",
    "    old_exp_root = data['experiment']['exp_root']\n",
    "    new_root = old_exp_root.replace(\"10_25_24\", \"10_26_24\")\n",
    "\n",
    "    # Place it in\n",
    "    data['experiment']['exp_root'] = new_root\n",
    "    data['log']['root'] = new_root\n",
    "\n",
    "    backup_path = Path(str(file_path).replace(\"config.yml\", \"backup_config.yml\"))\n",
    "\n",
    "    # Step 3: Backup the old .yml file\n",
    "    shutil.move(file_path, backup_path)\n",
    "    \n",
    "    # Step 4: Write the new .yml file\n",
    "    with open(file_path, 'w') as file:\n",
    "        yaml.dump(data, file)\n",
    "\n",
    "    print(\"Moved {} -> {}\".format(file_path, backup_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cfg_path in config_files:\n",
    "    modify_yml(cfg_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
