{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/storage/vbutoi/projects')\n",
    "sys.path.append('/storage/vbutoi/libraries')\n",
    "sys.path.append('/storage/vbutoi/projects/ESE')\n",
    "sys.path.append('/storage/vbutoi/projects/UniverSeg')\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "import os \n",
    "os.environ['DATAPATH'] = ':'.join((\n",
    "       '/storage/vbutoi/datasets',\n",
    "))\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0,1,2,3' \n",
    "\n",
    "%load_ext yamlmagic\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            require(\n                [\n                    \"notebook/js/codecell\",\n                    \"codemirror/mode/yaml/yaml\"\n                ],\n                function(cc){\n                    cc.CodeCell.options_default.highlight_modes.magic_yaml = {\n                        reg: [\"^%%yaml\"]\n                    }\n                }\n            );\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%yaml wmh_inference_config\n",
    "\n",
    "model:\n",
    "    exp_name: WMH_aug_runs\n",
    "    metric: val-dice_score # for comparison amongst runs of an experiment.\n",
    "    checkpoint: max-val-dice_score\n",
    "\n",
    "dataset:\n",
    "    _class: ese.experiment.datasets.WMH\n",
    "    annotator: observer_o12\n",
    "    axis: 0\n",
    "    data_type: volume\n",
    "    split: '?'\n",
    "    slicing: full \n",
    "    task: '?'\n",
    "    version: 0.2\n",
    "\n",
    "calibration:\n",
    "    class_type: Binary\n",
    "    include_background: True\n",
    "    num_bins: 10\n",
    "    bin_weightings:\n",
    "        - proportional\n",
    "    metrics: \n",
    "        - ACE\n",
    "        - ECE \n",
    "        - ReCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            require(\n                [\n                    \"notebook/js/codecell\",\n                    \"codemirror/mode/yaml/yaml\"\n                ],\n                function(cc){\n                    cc.CodeCell.options_default.highlight_modes.magic_yaml = {\n                        reg: [\"^%%yaml\"]\n                    }\n                }\n            );\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%yaml binarypets_inference_config\n",
    "\n",
    "model:\n",
    "    exp_name: 09_18_23_BinaryPetsPilot\n",
    "    metric: val-dice_score # for comparison amongst runs of an experiment.\n",
    "    checkpoint: max-val-dice_score\n",
    "\n",
    "dataset:\n",
    "    _class: ese.experiment.datasets.BinaryPets\n",
    "    data_type: image\n",
    "    split: '?' \n",
    "    preload: True\n",
    "    version: 0.1\n",
    "\n",
    "calibration:\n",
    "    class_type: Multi-class \n",
    "    include_background: True\n",
    "    num_bins: 10\n",
    "    bin_weightings:\n",
    "        - proportional\n",
    "    metrics: \n",
    "        - ACE\n",
    "        - ECE \n",
    "        - ReCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ionpy.util import dict_product, Config\n",
    "\n",
    "# Get the options for WMH\n",
    "##################################################\n",
    "wmh_dataset_options = {\n",
    "    'dataset.split': ['train', 'val', 'cal'],\n",
    "    'dataset.task': ['Singapore', 'Amsterdam']\n",
    "}\n",
    "\n",
    "base_wmh_cfg = Config(wmh_inference_config)\n",
    "\n",
    "wmh_cfgs = []\n",
    "for cfg_update in dict_product(wmh_dataset_options):\n",
    "    new_wmh_cfg = base_wmh_cfg.update(cfg_update)\n",
    "    wmh_cfgs.append(new_wmh_cfg)\n",
    "\n",
    "\n",
    "# Get the options for BinaryPets \n",
    "##################################################\n",
    "binarypets_dataset_options = {\n",
    "    'dataset.split': ['train', 'val', 'cal'],\n",
    "}\n",
    "\n",
    "base_binarypets_cfg = Config(binarypets_inference_config)\n",
    "\n",
    "bp_cfgs = []\n",
    "for cfg_update in dict_product(binarypets_dataset_options):\n",
    "    new_bp_cfg = base_binarypets_cfg.update(cfg_update)\n",
    "    bp_cfgs.append(new_bp_cfg)\n",
    "\n",
    "\n",
    "# Combine the options\n",
    "# cfgs = wmh_cfgs + bp_cfgs\n",
    "cfgs = bp_cfgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cfgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Config({'model': {'exp_name': '09_18_23_BinaryPetsPilot', 'metric': 'val-dice_score', 'checkpoint': 'max-val-dice_score'}, 'dataset': {'_class': 'ese.experiment.datasets.BinaryPets', 'data_type': 'image', 'split': 'train', 'preload': True, 'version': 0.1}, 'calibration': {'class_type': 'Multi-class', 'include_background': True, 'num_bins': 10, 'bin_weightings': ['proportional'], 'metrics': ['ACE', 'ECE', 'ReCE']}})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfgs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f7589166fe24bdbb2b1014cc785b4cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12f3da5cf6e946ab9068c804800e00ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing BinaryPets, train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Data Loop:   0%|          | 11/4416 [00:58<6:32:16,  5.34s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/storage/vbutoi/projects/ESE/notebooks/run_inference.ipynb Cell 7\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Btwix/storage/vbutoi/projects/ESE/notebooks/run_inference.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mese\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexperiment\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39manalysis\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39minference\u001b[39;00m \u001b[39mimport\u001b[39;00m get_dice_breakdown\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Btwix/storage/vbutoi/projects/ESE/notebooks/run_inference.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m get_dice_breakdown(cfgs[\u001b[39m0\u001b[39;49m])\n",
      "File \u001b[0;32m~/envs/UniverSegTF/lib/python3.9/site-packages/pydantic/decorator.py:40\u001b[0m, in \u001b[0;36mpydantic.decorator.validate_arguments.validate.wrapper_function\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/envs/UniverSegTF/lib/python3.9/site-packages/pydantic/decorator.py:134\u001b[0m, in \u001b[0;36mpydantic.decorator.ValidatedFunction.call\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/envs/UniverSegTF/lib/python3.9/site-packages/pydantic/decorator.py:206\u001b[0m, in \u001b[0;36mpydantic.decorator.ValidatedFunction.execute\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/storage/vbutoi/projects/ESE/ese/experiment/analysis/inference.py:85\u001b[0m, in \u001b[0;36mget_dice_breakdown\u001b[0;34m(cfg, root)\u001b[0m\n\u001b[1;32m     83\u001b[0m     volume_forward_loop(batch, batch_idx, cfg, exp, data_records)\n\u001b[1;32m     84\u001b[0m \u001b[39melif\u001b[39;00m data_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mimage\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m---> 85\u001b[0m     image_forward_loop(batch, batch_idx, cfg, exp, data_records)\n\u001b[1;32m     86\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     87\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mData type \u001b[39m\u001b[39m{\u001b[39;00mdata_type\u001b[39m}\u001b[39;00m\u001b[39m not supported.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/envs/UniverSegTF/lib/python3.9/site-packages/pydantic/decorator.py:40\u001b[0m, in \u001b[0;36mpydantic.decorator.validate_arguments.validate.wrapper_function\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/envs/UniverSegTF/lib/python3.9/site-packages/pydantic/decorator.py:134\u001b[0m, in \u001b[0;36mpydantic.decorator.ValidatedFunction.call\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/envs/UniverSegTF/lib/python3.9/site-packages/pydantic/decorator.py:206\u001b[0m, in \u001b[0;36mpydantic.decorator.ValidatedFunction.execute\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/storage/vbutoi/projects/ESE/ese/experiment/analysis/inference.py:146\u001b[0m, in \u001b[0;36mimage_forward_loop\u001b[0;34m(batch, batch_idx, cfg, exp, data_records)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[39m# Get the prediction\u001b[39;00m\n\u001b[1;32m    144\u001b[0m pred_map, conf_map \u001b[39m=\u001b[39m exp\u001b[39m.\u001b[39mpredict(image, include_probs\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m--> 146\u001b[0m get_calibration_item_info(\n\u001b[1;32m    147\u001b[0m     cfg\u001b[39m=\u001b[39;49mcfg,\n\u001b[1;32m    148\u001b[0m     conf_map\u001b[39m=\u001b[39;49mconf_map,\n\u001b[1;32m    149\u001b[0m     pred_map\u001b[39m=\u001b[39;49mpred_map,\n\u001b[1;32m    150\u001b[0m     label\u001b[39m=\u001b[39;49mlabel,\n\u001b[1;32m    151\u001b[0m     data_idx\u001b[39m=\u001b[39;49mbatch_idx,\n\u001b[1;32m    152\u001b[0m     split\u001b[39m=\u001b[39;49mcfg[\u001b[39m'\u001b[39;49m\u001b[39mdataset\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m'\u001b[39;49m\u001b[39msplit\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    153\u001b[0m     data_records\u001b[39m=\u001b[39;49mdata_records\n\u001b[1;32m    154\u001b[0m )\n",
      "File \u001b[0;32m~/envs/UniverSegTF/lib/python3.9/site-packages/pydantic/decorator.py:40\u001b[0m, in \u001b[0;36mpydantic.decorator.validate_arguments.validate.wrapper_function\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/envs/UniverSegTF/lib/python3.9/site-packages/pydantic/decorator.py:134\u001b[0m, in \u001b[0;36mpydantic.decorator.ValidatedFunction.call\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/envs/UniverSegTF/lib/python3.9/site-packages/pydantic/decorator.py:206\u001b[0m, in \u001b[0;36mpydantic.decorator.ValidatedFunction.execute\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/storage/vbutoi/projects/ESE/ese/experiment/analysis/inference.py:187\u001b[0m, in \u001b[0;36mget_calibration_item_info\u001b[0;34m(cfg, conf_map, pred_map, label, data_idx, split, data_records, slice_idx, task)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[39mfor\u001b[39;00m cal_metric \u001b[39min\u001b[39;00m cfg[\u001b[39m\"\u001b[39m\u001b[39mcalibration\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mmetrics\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m    185\u001b[0m     \u001b[39mfor\u001b[39;00m bin_weighting \u001b[39min\u001b[39;00m cfg[\u001b[39m\"\u001b[39m\u001b[39mcalibration\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mbin_weightings\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m    186\u001b[0m         \u001b[39m# Get the calibration metric\u001b[39;00m\n\u001b[0;32m--> 187\u001b[0m         calibration_info \u001b[39m=\u001b[39m metric_dict[cal_metric](\n\u001b[1;32m    188\u001b[0m             num_bins\u001b[39m=\u001b[39;49mcfg[\u001b[39m\"\u001b[39;49m\u001b[39mcalibration\u001b[39;49m\u001b[39m\"\u001b[39;49m][\u001b[39m\"\u001b[39;49m\u001b[39mnum_bins\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m    189\u001b[0m             conf_map\u001b[39m=\u001b[39;49mconf_map,\n\u001b[1;32m    190\u001b[0m             pred_map\u001b[39m=\u001b[39;49mpred_map,\n\u001b[1;32m    191\u001b[0m             label\u001b[39m=\u001b[39;49mlabel,\n\u001b[1;32m    192\u001b[0m             class_type\u001b[39m=\u001b[39;49mcfg[\u001b[39m\"\u001b[39;49m\u001b[39mcalibration\u001b[39;49m\u001b[39m\"\u001b[39;49m][\u001b[39m\"\u001b[39;49m\u001b[39mclass_type\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m    193\u001b[0m             weighting\u001b[39m=\u001b[39;49mbin_weighting,\n\u001b[1;32m    194\u001b[0m             include_background\u001b[39m=\u001b[39;49mcfg[\u001b[39m\"\u001b[39;49m\u001b[39mcalibration\u001b[39;49m\u001b[39m\"\u001b[39;49m][\u001b[39m\"\u001b[39;49m\u001b[39minclude_background\u001b[39;49m\u001b[39m\"\u001b[39;49m]\n\u001b[1;32m    195\u001b[0m         ) \n\u001b[1;32m    196\u001b[0m         \u001b[39m# Wrap it in an item\u001b[39;00m\n\u001b[1;32m    197\u001b[0m         data_records\u001b[39m.\u001b[39mappend({\n\u001b[1;32m    198\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m\"\u001b[39m: acc,\n\u001b[1;32m    199\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mbin_counts\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mtuple\u001b[39m(calibration_info[\u001b[39m\"\u001b[39m\u001b[39mbin_amounts\u001b[39m\u001b[39m\"\u001b[39m]),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mlab_w_accuracy\u001b[39m\u001b[39m\"\u001b[39m: balanced_acc,\n\u001b[1;32m    213\u001b[0m         })\n",
      "File \u001b[0;32m~/envs/UniverSegTF/lib/python3.9/site-packages/pydantic/decorator.py:40\u001b[0m, in \u001b[0;36mpydantic.decorator.validate_arguments.validate.wrapper_function\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/envs/UniverSegTF/lib/python3.9/site-packages/pydantic/decorator.py:134\u001b[0m, in \u001b[0;36mpydantic.decorator.ValidatedFunction.call\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/envs/UniverSegTF/lib/python3.9/site-packages/pydantic/decorator.py:206\u001b[0m, in \u001b[0;36mpydantic.decorator.ValidatedFunction.execute\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/storage/vbutoi/projects/ESE/ese/experiment/metrics/calibration.py:277\u001b[0m, in \u001b[0;36mReCE\u001b[0;34m(num_bins, conf_map, pred_map, label, include_background, class_type, weighting, min_confidence)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[39m# Calculate the average score for the regions in the bin.\u001b[39;00m\n\u001b[1;32m    276\u001b[0m \u001b[39mif\u001b[39;00m class_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mMulti-class\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 277\u001b[0m     region_metrics[isl_idx] \u001b[39m=\u001b[39m pixel_accuracy(region_pred_map, region_label)\n\u001b[1;32m    278\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    279\u001b[0m     region_metrics[isl_idx] \u001b[39m=\u001b[39m pixel_precision(region_pred_map, region_label)\n",
      "File \u001b[0;32m~/envs/UniverSegTF/lib/python3.9/site-packages/pydantic/decorator.py:40\u001b[0m, in \u001b[0;36mpydantic.decorator.validate_arguments.validate.wrapper_function\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/envs/UniverSegTF/lib/python3.9/site-packages/pydantic/decorator.py:134\u001b[0m, in \u001b[0;36mpydantic.decorator.ValidatedFunction.call\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/envs/UniverSegTF/lib/python3.9/site-packages/pydantic/decorator.py:206\u001b[0m, in \u001b[0;36mpydantic.decorator.ValidatedFunction.execute\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/storage/vbutoi/projects/ionpy/metrics/segmentation.py:77\u001b[0m, in \u001b[0;36mpixel_accuracy\u001b[0;34m(y_pred, y_true, mode, from_logits, return_all)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[39m@validate_arguments\u001b[39m(config\u001b[39m=\u001b[39m\u001b[39mdict\u001b[39m(arbitrary_types_allowed\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m))\n\u001b[1;32m     69\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpixel_accuracy\u001b[39m(\n\u001b[1;32m     70\u001b[0m     y_pred: Tensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     74\u001b[0m     return_all: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m     75\u001b[0m ):\n\u001b[0;32m---> 77\u001b[0m     y_pred_long, y_true_long \u001b[39m=\u001b[39m _inputs_as_longlabels(\n\u001b[1;32m     78\u001b[0m         y_pred, y_true, mode, from_logits\u001b[39m=\u001b[39;49mfrom_logits, discretize\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[1;32m     79\u001b[0m     )\n\u001b[1;32m     80\u001b[0m     correct \u001b[39m=\u001b[39m (y_pred_long \u001b[39m==\u001b[39m y_true_long)\u001b[39m.\u001b[39mfloat()\n\u001b[1;32m     82\u001b[0m     \u001b[39mif\u001b[39;00m return_all:\n",
      "File \u001b[0;32m~/envs/UniverSegTF/lib/python3.9/site-packages/pydantic/decorator.py:40\u001b[0m, in \u001b[0;36mpydantic.decorator.validate_arguments.validate.wrapper_function\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/envs/UniverSegTF/lib/python3.9/site-packages/pydantic/decorator.py:134\u001b[0m, in \u001b[0;36mpydantic.decorator.ValidatedFunction.call\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/envs/UniverSegTF/lib/python3.9/site-packages/pydantic/decorator.py:206\u001b[0m, in \u001b[0;36mpydantic.decorator.ValidatedFunction.execute\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/storage/vbutoi/projects/ionpy/metrics/util.py:134\u001b[0m, in \u001b[0;36m_inputs_as_longlabels\u001b[0;34m(y_pred, y_true, mode, from_logits, discretize)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[39mif\u001b[39;00m discretize:\n\u001b[1;32m    133\u001b[0m     \u001b[39mif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 134\u001b[0m         y_pred \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mround(y_pred)\u001b[39m.\u001b[39;49mclamp_min(\u001b[39m0.0\u001b[39;49m)\u001b[39m.\u001b[39mclamp_max(\u001b[39m1.0\u001b[39m)\n\u001b[1;32m    135\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    136\u001b[0m         y_pred \u001b[39m=\u001b[39m hard_max(y_pred)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from ese.experiment.analysis.inference import get_dice_breakdown\n",
    "\n",
    "get_dice_breakdown(cfgs[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UniverSegTF",
   "language": "python",
   "name": "universegtf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
