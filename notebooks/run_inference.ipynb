{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/storage/vbutoi/projects')\n",
    "sys.path.append('/storage/vbutoi/libraries')\n",
    "sys.path.append('/storage/vbutoi/projects/ESE')\n",
    "sys.path.append('/storage/vbutoi/projects/UniverSeg')\n",
    "import torch\n",
    "torch.set_printoptions(linewidth=200)\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "import os \n",
    "os.environ['DATAPATH'] = ':'.join((\n",
    "       '/storage/vbutoi/datasets',\n",
    "))\n",
    "\n",
    "# Results loader object does everything\n",
    "from ionpy.analysis import ResultsLoader\n",
    "from pathlib import Path\n",
    "root = Path(\"/storage/vbutoi/scratch/ESE\")\n",
    "code_root = Path(\"/storage/vbutoi/projects/ESE\")\n",
    "rs = ResultsLoader()\n",
    "\n",
    "\n",
    "# For using code without restarting.\n",
    "%load_ext autoreload\n",
    "%autoreload \n",
    "# For using yaml configs.\n",
    "%load_ext yamlmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%yaml inference_config\n",
    "\n",
    "experiment:\n",
    "    exp_root: '?'\n",
    "    seed: 42\n",
    "\n",
    "data:\n",
    "    splits: ('val', 'cal')\n",
    "    preload: '?' \n",
    "\n",
    "dataloader:\n",
    "    batch_size: 1 \n",
    "    num_workers: 0\n",
    "    pin_memory: True \n",
    "\n",
    "log:\n",
    "    root: '?'\n",
    "    log_interval: 10 \n",
    "    show_examples: '?' \n",
    "    log_image_stats: '?' \n",
    "    log_pixel_stats: '?' \n",
    "    min_fg_pixels: '?'\n",
    "    track_ensemble_member_scores: True\n",
    "    summary_compute_global_metrics: True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%yaml model_cfg\n",
    "\n",
    "model:\n",
    "    calibrator: '?'\n",
    "    checkpoint: '?' \n",
    "    normalize: '?' \n",
    "    ensemble: '?' \n",
    "    ensemble_cfg: '?'\n",
    "    ensemble_w_metric: '?'\n",
    "    pretrained_exp_root : '?' \n",
    "    pretrained_select_metric: \"val-dice_score\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "from ese.scripts.utils import gather_exp_paths\n",
    "\n",
    "\n",
    "def get_ese_inference_configs(\n",
    "    group_dict: dict,\n",
    "    calibrators_list: List[str], \n",
    "    do_ensemble: bool = False, \n",
    "    log_image_stats: bool = True,\n",
    "    log_pixel_stats: bool = True,\n",
    "    show_examples: bool = False,\n",
    "    ensemble_upper_bound: bool = False,\n",
    "    normalize_opts: List[bool] = None,\n",
    "    additional_args: Optional[dict] = None,\n",
    "    ens_cfg_options: Optional[List[tuple]] = None,\n",
    "    ens_w_metric_list: Optional[List[str]] = ['None'],\n",
    "):\n",
    "    if not do_ensemble:\n",
    "        assert ens_w_metric_list == ['None'], \"No weighting can be provided if no ensemble.\"\n",
    "        assert ens_cfg_options == None, \"No ensemble config can be provided if no ensemble.\"\n",
    "        assert not ensemble_upper_bound, \"No ensemble upper bound can be provided if no ensemble.\"\n",
    "\n",
    "    if ens_cfg_options is None:\n",
    "        ens_cfg_options = [None]\n",
    "\n",
    "    calibrator_option_list = []\n",
    "    for calibrator in calibrators_list:\n",
    "        for ensemble_w_metric in ens_w_metric_list:\n",
    "            if \"Binning\" in calibrator:\n",
    "                iter_norm_opts = normalize_opts\n",
    "            else:\n",
    "                iter_norm_opts = [False]\n",
    "            # Iterate over the different normalization options, only really used if doing a binning calibrator.\n",
    "            for norm in iter_norm_opts:\n",
    "                # Define the paths for the uncailbrated networks.\n",
    "                ##################################################\n",
    "                if (calibrator == \"Uncalibrated\") or (\"Binning\" in calibrator):\n",
    "                    ensemble_root = f\"/storage/vbutoi/scratch/ESE/training/{group_dict['base_models_group']}\"\n",
    "                    checkpoint = \"max-val-dice_score\" \n",
    "                # Define the paths for the calibrated networks.\n",
    "                ##################################################\n",
    "                else:\n",
    "                    ensemble_root = f\"/storage/vbutoi/scratch/ESE/calibration/{group_dict['calibrated_models_group']}/Individual_{calibrator}\"\n",
    "                    checkpoint = \"min-val-ece_loss\"\n",
    "\n",
    "                # Set a few things that will be consistent for all runs.\n",
    "                ##################################################\n",
    "                exp_root = root / \"inference\" / group_dict['exp_group']\n",
    "\n",
    "                # Get the calibrator name\n",
    "                calibrator_class_name_map = {\n",
    "                    \"TempScaling\": \"ese.experiment.models.calibrators.Temperature_Scaling\",\n",
    "                    \"VectorScaling\": \"ese.experiment.models.calibrators.Vector_Scaling\",\n",
    "                    \"DirichletScaling\": \"ese.experiment.models.calibrators.Dirichlet_Scaling\",\n",
    "                    \"LTS\": \"ese.experiment.models.calibrators.LTS\",\n",
    "                    \"NectarScaling\": \"ese.experiment.models.calibrators.NECTAR_Scaling\",\n",
    "                    \"HistogramBinning\": \"ese.experiment.models.calibrators.Histogram_Binning\",\n",
    "                    \"NectarBinning\": \"ese.experiment.models.calibrators.NECTAR_Binning\",\n",
    "                }\n",
    "                if calibrator in calibrator_class_name_map:\n",
    "                    calibrator_cls = calibrator_class_name_map[calibrator]\n",
    "                else:\n",
    "                    calibrator_cls = calibrator\n",
    "\n",
    "                default_config_options = {\n",
    "                    'experiment.exp_root': [str(exp_root)],\n",
    "                    'experiment.dataset_name': [group_dict['dataset']],\n",
    "                    'model.checkpoint': [checkpoint],\n",
    "                    'model.calibrator': [calibrator],\n",
    "                    'model.calibrator_cls': [calibrator_cls],\n",
    "                    'model.normalize': [norm],\n",
    "                    'data.preload': [group_dict['preload']],\n",
    "                    'log.show_examples': [show_examples],\n",
    "                    'log.log_image_stats': [log_image_stats],\n",
    "                    'log.log_pixel_stats': [log_pixel_stats],\n",
    "                }\n",
    "\n",
    "                if additional_args is not None:\n",
    "                    default_config_options.update(additional_args)\n",
    "                # Make presets for the different runnning configurations.\n",
    "                ##################################################\n",
    "                # If you want to run inference on ensembles, use this.\n",
    "                if do_ensemble:\n",
    "                    if ensemble_upper_bound:\n",
    "                        log_root = str(exp_root / f\"ensemble_upper_bounds\")\n",
    "                    else:\n",
    "                        log_root = str(exp_root / f\"{group_dict['dataset']}_Ensemble_{calibrator}\")\n",
    "                    advanced_args = {\n",
    "                        'log.root': [log_root],\n",
    "                        'model.pretrained_exp_root': [ensemble_root],\n",
    "                        'model.ensemble': [True],\n",
    "                        'model.ensemble_w_metric': [ensemble_w_metric],\n",
    "                        'model.ensemble_cfg': ens_cfg_options \n",
    "                    }\n",
    "                # If you want to run inference on individual networks, use this.\n",
    "                else:\n",
    "                    advanced_args = {\n",
    "                        'log.root': [str(exp_root / f\"{group_dict['dataset']}_Individual_{calibrator}\")],\n",
    "                        'model.pretrained_exp_root': gather_exp_paths(ensemble_root), # Note this is a list of train exp paths.\n",
    "                        'model.ensemble': [False],\n",
    "                        'model.ensemble_cfg': ens_cfg_options,\n",
    "                        'model.ensemble_w_metric': [None]\n",
    "                    }\n",
    "                \n",
    "                if \"Binning\" in calibrator:\n",
    "                    assert (exp_root / f\"{group_dict['dataset']}_Individual_Uncalibrated\").exists(),\\\n",
    "                        \"Uncalibrated model inference results must exist for binning.\"\n",
    "\n",
    "                # Combine the default and advanced arguments.\n",
    "                default_config_options.update(advanced_args)\n",
    "                # Append these to the list of configs and roots.\n",
    "                calibrator_option_list.append(default_config_options)\n",
    "    # Return the list of different configs.\n",
    "    return calibrator_option_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_name = '02_12_24_WMH_Inference' \n",
    "group_dict = {\n",
    "    \"dataset\": \"WMH\",\n",
    "    \"exp_group\": exp_name,\n",
    "    \"base_models_group\": \"01_08_24_WMH_Ensemble\",\n",
    "    \"calibrated_models_group\": \"01_19_24_WMH_Foreground_Calibrators\",\n",
    "    \"preload\": False\n",
    "}\n",
    "\n",
    "# exp_name = '02_11_24_CityScapes_Inference' \n",
    "# group_dict = {\n",
    "#     \"dataset\": \"CityScapes\",\n",
    "#     \"exp_group\": exp_name,\n",
    "#     \"base_models_group\": \"01_25_24_CityScapes_Dice\",\n",
    "#     \"calibrated_models_group\": \"01_26_24_CityScapes_Ensemble\",\n",
    "#     \"preload\": False\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard Calibrators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get the configs for the different runs.\n",
    "# dataset_options = get_ese_inference_configs(\n",
    "#     group_dict=group_dict,\n",
    "#     calibrators_list=[\n",
    "#         'Uncalibrated',\n",
    "#         'Vanilla',\n",
    "#         'TempScaling',\n",
    "#         'VectorScaling',\n",
    "#         'DirichletScaling',\n",
    "#         'LTS',\n",
    "#         'NectarScaling',\n",
    "#     ], \n",
    "#     # do_ensemble=True, \n",
    "#     # ens_cfg_options=[\n",
    "#     #     ('mean', 'logits'), \n",
    "#     #     ('mean', 'probs'), \n",
    "#     #     ('product', 'probs')\n",
    "#     # ],\n",
    "#     # ens_w_metric_list=[\n",
    "#     #     'None',\n",
    "#     # ],\n",
    "#     additional_args=None,\n",
    "#     show_examples=False\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binning Calibrators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the configs for the different runs.\n",
    "dataset_options = get_ese_inference_configs(\n",
    "    group_dict=group_dict,\n",
    "    calibrators_list=[\n",
    "        'HistogramBinning',\n",
    "        'NectarBinning',\n",
    "    ], \n",
    "    do_ensemble=True, \n",
    "    ens_cfg_options=[\n",
    "        ('mean', 'logits'), \n",
    "        ('mean', 'probs'), \n",
    "        ('product', 'probs')\n",
    "    ],\n",
    "    ens_w_metric_list=[\n",
    "        'None',\n",
    "    ],\n",
    "    normalize_opts=[\n",
    "        True, \n",
    "        False\n",
    "    ], # Used only for histogram binning variants.\n",
    "    additional_args=None,\n",
    "    show_examples=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upper Bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Get the configs for computing the upepr bounds\n",
    "\n",
    "# dataset_options = get_ese_inference_configs(\n",
    "#     group_dict=group_dict,\n",
    "#     do_ensemble=True, \n",
    "#     ensemble_upper_bound=True,\n",
    "#     calibrators_list=[\n",
    "#         'Uncalibrated',\n",
    "#     ], \n",
    "#     ens_cfg_options=[\n",
    "#         ('upperbound', 'probs')\n",
    "#     ]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ese.scripts.utils import get_option_product\n",
    "from ionpy.util import Config\n",
    "import yaml\n",
    "\n",
    "# Load the inference cfg from local.\n",
    "##################################################\n",
    "cfg_root = code_root / \"ese\" / \"experiment\" / \"configs\" / \"inference\"\n",
    "##################################################\n",
    "with open(cfg_root / f\"{group_dict['dataset']}.yaml\", 'r') as file:\n",
    "    dataset_inference_cfg = yaml.safe_load(file)\n",
    "with open(cfg_root / \"Calibration_Metrics.yaml\", 'r') as file:\n",
    "    cal_metrics_cfg = yaml.safe_load(file)\n",
    "##################################################\n",
    "base_cfg = Config(inference_config).update([model_cfg, cal_metrics_cfg, dataset_inference_cfg])\n",
    "\n",
    "# Get the configs\n",
    "cfgs = get_option_product(exp_name, dataset_options, base_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cfgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ese.experiment.analysis.run_inference import get_cal_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ese.experiment.experiment import run_ese_exp\n",
    "\n",
    "# ###### Run individual jobs\n",
    "# run_ese_exp(\n",
    "#     config=cfgs[0], \n",
    "#     job_func=get_cal_stats,\n",
    "#     run_name='debug',\n",
    "#     gpu='3',\n",
    "# ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ese.experiment.experiment import submit_ese_exps \n",
    "#### Run Batch Jobs\n",
    "submit_ese_exps(\n",
    "    config_list=cfgs,\n",
    "    job_func=get_cal_stats,\n",
    "    available_gpus=['0', '1', '2', '3']\n",
    "    # available_gpus=['4', '5', '6', '7']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here we run upper-bounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ese.experiment.analysis.ensemble_upperbound import get_ensemble_ub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###### Run individual jobs\n",
    "# run_ese_exp(\n",
    "#     config=cfgs[0], \n",
    "#     job_func=get_ensemble_ub,\n",
    "#     run_name='debug',\n",
    "#     gpu='0',\n",
    "# ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###### Run Batch Jobs\n",
    "# submit_ese_exps(\n",
    "#     config_list=cfgs,\n",
    "#     job_func=get_ensemble_ub,\n",
    "#     available_gpus=['1']\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UniverSegTF",
   "language": "python",
   "name": "universegtf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
