{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/storage/vbutoi/projects')\n",
    "sys.path.append('/storage/vbutoi/libraries')\n",
    "sys.path.append('/storage/vbutoi/projects/ESE')\n",
    "sys.path.append('/storage/vbutoi/projects/UniverSeg')\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "import os \n",
    "os.environ['DATAPATH'] = ':'.join((\n",
    "       '/storage/vbutoi/datasets',\n",
    "))\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0,1,2,3' \n",
    "\n",
    "%load_ext yamlmagic\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            require(\n                [\n                    \"notebook/js/codecell\",\n                    \"codemirror/mode/yaml/yaml\"\n                ],\n                function(cc){\n                    cc.CodeCell.options_default.highlight_modes.magic_yaml = {\n                        reg: [\"^%%yaml\"]\n                    }\n                }\n            );\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%yaml wmh_inference_config\n",
    "\n",
    "log:\n",
    "    root: /storage/vbutoi/scratch/ESE\n",
    "    log_interval: 50\n",
    "\n",
    "model:\n",
    "    exp_name: WMH_aug_runs\n",
    "    metric: val-dice_score # for comparison amongst runs of an experiment.\n",
    "    checkpoint: max-val-dice_score\n",
    "    num_workers: 0  \n",
    "\n",
    "dataset:\n",
    "    _class: ese.experiment.datasets.WMH\n",
    "    annotator: observer_o12\n",
    "    axis: 0\n",
    "    data_type: volume\n",
    "    split: '?'\n",
    "    slicing: full \n",
    "    task: '?'\n",
    "    version: 0.2\n",
    "\n",
    "calibration:\n",
    "    class_type: Binary\n",
    "    include_background: True\n",
    "    num_bins: 10\n",
    "    bin_weightings:\n",
    "        - proportional\n",
    "    metrics: \n",
    "        - ACE\n",
    "        - ECE \n",
    "        - ReCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            require(\n                [\n                    \"notebook/js/codecell\",\n                    \"codemirror/mode/yaml/yaml\"\n                ],\n                function(cc){\n                    cc.CodeCell.options_default.highlight_modes.magic_yaml = {\n                        reg: [\"^%%yaml\"]\n                    }\n                }\n            );\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%yaml binarypets_inference_config\n",
    "\n",
    "log:\n",
    "    root: /storage/vbutoi/scratch/ESE\n",
    "    log_interval : 50\n",
    "\n",
    "model:\n",
    "    exp_name: 09_18_23_BinaryPetsPilot\n",
    "    metric: val-dice_score # for comparison amongst runs of an experiment.\n",
    "    checkpoint: max-val-dice_score\n",
    "    num_workers: 0  \n",
    "\n",
    "dataset:\n",
    "    _class: ese.experiment.datasets.BinaryPets\n",
    "    data_type: image\n",
    "    split: '?' \n",
    "    preload: True\n",
    "    version: 0.1\n",
    "\n",
    "calibration:\n",
    "    class_type: Multi-class \n",
    "    include_background: True\n",
    "    num_bins: 10\n",
    "    bin_weightings:\n",
    "        - proportional\n",
    "    metrics: \n",
    "        - ACE\n",
    "        - ECE \n",
    "        - ReCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ionpy.util import dict_product, Config\n",
    "\n",
    "# Get the options for WMH\n",
    "##################################################\n",
    "wmh_dataset_options = {\n",
    "    'dataset.split': ['train', 'val', 'cal'],\n",
    "    'dataset.task': ['Singapore', 'Amsterdam']\n",
    "}\n",
    "\n",
    "base_wmh_cfg = Config(wmh_inference_config)\n",
    "\n",
    "wmh_cfgs = []\n",
    "for cfg_update in dict_product(wmh_dataset_options):\n",
    "    new_wmh_cfg = base_wmh_cfg.update(cfg_update)\n",
    "    wmh_cfgs.append(new_wmh_cfg)\n",
    "\n",
    "\n",
    "# Get the options for BinaryPets \n",
    "##################################################\n",
    "binarypets_dataset_options = {\n",
    "    'dataset.split': ['train', 'val', 'cal'],\n",
    "}\n",
    "\n",
    "base_binarypets_cfg = Config(binarypets_inference_config)\n",
    "\n",
    "bp_cfgs = []\n",
    "for cfg_update in dict_product(binarypets_dataset_options):\n",
    "    new_bp_cfg = base_binarypets_cfg.update(cfg_update)\n",
    "    bp_cfgs.append(new_bp_cfg)\n",
    "\n",
    "\n",
    "# Combine the options\n",
    "cfgs = wmh_cfgs + bp_cfgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cfgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Config({'log': {'root': '/storage/vbutoi/scratch/ESE', 'log_interval': 50}, 'model': {'exp_name': 'WMH_aug_runs', 'metric': 'val-dice_score', 'checkpoint': 'max-val-dice_score', 'num_workers': 0}, 'dataset': {'_class': 'ese.experiment.datasets.WMH', 'annotator': 'observer_o12', 'axis': 0, 'data_type': 'volume', 'split': 'train', 'slicing': 'full', 'task': 'Singapore', 'version': 0.2}, 'calibration': {'class_type': 'Binary', 'include_background': True, 'num_bins': 10, 'bin_weightings': ['proportional'], 'metrics': ['ACE', 'ECE', 'ReCE']}})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfgs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ese.experiment.analysis.inference import get_cal_stats\n",
    "\n",
    "# get_cal_stats(cfgs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initalized SliteRunner\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted job id: 4030553.\n",
      "Submitted job id: 4030559.\n",
      "Submitted job id: 4030565.\n",
      "Submitted job id: 4030578.\n"
     ]
    }
   ],
   "source": [
    "from ionpy.slite.submit import submit_jobs\n",
    "from ese.experiment.analysis.inference import get_cal_stats\n",
    "\n",
    "submit_jobs(\n",
    "    project=\"ESE\",\n",
    "    exp_name=\"09_28_23_WMH_and_BP_inference\",\n",
    "    config_list=cfgs, \n",
    "    job_func=get_cal_stats\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UniverSegTF",
   "language": "python",
   "name": "universegtf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
