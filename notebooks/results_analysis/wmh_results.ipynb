{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/storage/vbutoi/projects')\n",
    "sys.path.append('/storage/vbutoi/libraries')\n",
    "sys.path.append('/storage/vbutoi/projects/ESE')\n",
    "sys.path.append('/storage/vbutoi/projects/UniverSeg')\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "import os \n",
    "os.environ['DATAPATH'] = ':'.join((\n",
    "       '/storage/vbutoi/datasets',\n",
    "))\n",
    "\n",
    "# Results loader object does everything\n",
    "from ionpy.analysis import ResultsLoader\n",
    "from pathlib import Path\n",
    "root = Path(\"/storage/vbutoi/scratch/ESE\")\n",
    "rs = ResultsLoader()\n",
    "\n",
    "# For using code without restarting.\n",
    "%load_ext autoreload\n",
    "%autoreload \n",
    "# For using yaml configs.\n",
    "%load_ext yamlmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage/vbutoi/projects/ESE/ese/experiment/analysis/inference.py:89: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  cal_info_dict[\"image_info_df\"] = pd.concat([cal_info_dict[\"image_info_df\"], image_stats_df])\n",
      "/storage/vbutoi/projects/ESE/ese/experiment/analysis/inference.py:89: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  cal_info_dict[\"image_info_df\"] = pd.concat([cal_info_dict[\"image_info_df\"], image_stats_df])\n"
     ]
    }
   ],
   "source": [
    "from ese.experiment.analysis.inference import load_cal_inference_stats\n",
    "\n",
    "inference_path = root / \"inference/12_17_23_WMH_GlobalAnalysis\"\n",
    "dataset = \"WMH\"\n",
    "\n",
    "cal_inference_info = load_cal_inference_stats(\n",
    "    log_dir=inference_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['pixel_info_dicts', 'image_info_df', 'metadata'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cal_inference_info.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = cal_inference_info['metadata']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_name = list(cal_inference_info[\"pixel_info_dicts\"].keys())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20240105_161409-DSF0-81238d871613f6a5d3f736c88de15f0d'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Barplot Pixel-level Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ese.experiment.analysis.err_diagrams import viz_accuracy_vs_confidence\n",
    "# from ese.experiment.analysis.utils import select_pixel_dict\n",
    "\n",
    "# for split in [\"cal\"]: \n",
    "#     split_preds_dict = select_pixel_dict(\n",
    "#         pixel_meter_logdict=cal_inference_info[\"pixel_info_dicts\"], \n",
    "#         metadata=cal_inference_info[\"metadata\"],\n",
    "#         kwargs={\"dataset.split\": split}\n",
    "#     ) \n",
    "#     # Plot the accuracy vs confidence for this split.\n",
    "#     viz_accuracy_vs_confidence(\n",
    "#         split_preds_dict,\n",
    "#         title=f\"{dataset} Confidence vs Accuracy per (Bin and Predicted Label, {split} split)\",\n",
    "#         x=\"pred_label\",\n",
    "#         col=\"bin_num\",\n",
    "#         kind=\"bar\",\n",
    "#         facet_kws={'sharey': True, 'sharex': False}\n",
    "#         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ese.experiment.analysis.err_diagrams import viz_accuracy_vs_confidence\n",
    "\n",
    "# # Plot the accuracy vs confidence for this split.\n",
    "# viz_accuracy_vs_confidence(\n",
    "#     cal_inference_info[\"pixel_info_dicts\"][record_name],\n",
    "#     title=f\"{dataset} Confidence vs Accuracy per (Bin and Num Neighbors)\",\n",
    "#     x=\"num_neighbors\",\n",
    "#     col=\"bin_num\",\n",
    "#     relative_props=True,\n",
    "#     facet_kws={'sharey': True, 'sharex': False},\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ese.experiment.analysis.err_diagrams import viz_accuracy_vs_confidence\n",
    "\n",
    "# for label in [0, 1]: \n",
    "#     # Plot the accuracy vs confidence for this split.\n",
    "#     viz_accuracy_vs_confidence(\n",
    "#         cal_inference_info[\"pixel_info_dicts\"][record_name],\n",
    "#         title=f\"{dataset} Confidence vs Accuracy per (Bin and Num Neighbors, label: {label})\",\n",
    "#         x=\"num_neighbors\",\n",
    "#         col=\"bin_num\",\n",
    "#         relative_props=False,\n",
    "#         add_edge_props=True,\n",
    "#         label=label,\n",
    "#         facet_kws={'sharey': True, 'sharex': False},\n",
    "#         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at the metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Exactly one of (y_pred and y_true) or pixel_preds_dict must be defined, but y_pred defined = False, y_true defined = False, pixel_preds_dict defined = False.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mese\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperiment\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mece\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m \n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mece_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpixel_meters_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcal_inference_info\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpixel_info_dicts\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrecord_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(tl_ece_loss(pixel_meters_dict\u001b[38;5;241m=\u001b[39mcal_inference_info[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpixel_info_dicts\u001b[39m\u001b[38;5;124m\"\u001b[39m][record_name]))\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(cw_ece_loss(pixel_meters_dict\u001b[38;5;241m=\u001b[39mcal_inference_info[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpixel_info_dicts\u001b[39m\u001b[38;5;124m\"\u001b[39m][record_name]))\n",
      "File \u001b[0;32m~/envs/UniverSegTF/lib/python3.9/site-packages/pydantic/decorator.py:40\u001b[0m, in \u001b[0;36mpydantic.decorator.validate_arguments.validate.wrapper_function\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/envs/UniverSegTF/lib/python3.9/site-packages/pydantic/decorator.py:134\u001b[0m, in \u001b[0;36mpydantic.decorator.ValidatedFunction.call\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/envs/UniverSegTF/lib/python3.9/site-packages/pydantic/decorator.py:206\u001b[0m, in \u001b[0;36mpydantic.decorator.ValidatedFunction.execute\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/storage/vbutoi/projects/ESE/ese/experiment/metrics/ece.py:62\u001b[0m, in \u001b[0;36mece_loss\u001b[0;34m(y_pred, y_true, pixel_meters_dict, num_bins, neighborhood_width, edge_only, square_diff, from_logits, return_dict, stats_info_dict, conf_interval, ignore_index)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;124;03mCalculates the Expected Semantic Error (ECE) for a predicted label map.\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# Verify input.\u001b[39;00m\n\u001b[0;32m---> 62\u001b[0m use_global \u001b[38;5;241m=\u001b[39m \u001b[43mcal_input_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpixel_meters_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# Get the statistics either from images or pixel meter dict.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_global:\n",
      "File \u001b[0;32m~/envs/UniverSegTF/lib/python3.9/site-packages/pydantic/decorator.py:40\u001b[0m, in \u001b[0;36mpydantic.decorator.validate_arguments.validate.wrapper_function\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/envs/UniverSegTF/lib/python3.9/site-packages/pydantic/decorator.py:134\u001b[0m, in \u001b[0;36mpydantic.decorator.ValidatedFunction.call\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/envs/UniverSegTF/lib/python3.9/site-packages/pydantic/decorator.py:206\u001b[0m, in \u001b[0;36mpydantic.decorator.ValidatedFunction.execute\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/storage/vbutoi/projects/ESE/ese/experiment/metrics/ece.py:36\u001b[0m, in \u001b[0;36mcal_input_check\u001b[0;34m(y_pred, y_true, pixel_preds_dict)\u001b[0m\n\u001b[1;32m     34\u001b[0m use_global_funcs \u001b[38;5;241m=\u001b[39m (pixel_preds_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# xor images_defined pixel_preds_defined\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m use_global_funcs \u001b[38;5;241m^\u001b[39m use_local_funcs,\\\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExactly one of (y_pred and y_true) or pixel_preds_dict must be defined,\u001b[39m\u001b[38;5;124m\"\u001b[39m\\\n\u001b[1;32m     38\u001b[0m          \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m but y_pred defined = \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, y_true defined = \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, pixel_preds_dict defined = \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\\\n\u001b[1;32m     39\u001b[0m         y_pred \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, y_true \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, pixel_preds_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m use_global_funcs\n",
      "\u001b[0;31mAssertionError\u001b[0m: Exactly one of (y_pred and y_true) or pixel_preds_dict must be defined, but y_pred defined = False, y_true defined = False, pixel_preds_dict defined = False."
     ]
    }
   ],
   "source": [
    "from ese.experiment.metrics.ece import * \n",
    "\n",
    "print(ece_loss(pixel_meters_dict=cal_inference_info[\"pixel_info_dicts\"][record_name]))\n",
    "print(tl_ece_loss(pixel_meters_dict=cal_inference_info[\"pixel_info_dicts\"][record_name]))\n",
    "print(cw_ece_loss(pixel_meters_dict=cal_inference_info[\"pixel_info_dicts\"][record_name]))\n",
    "\n",
    "print(edge_ece_loss(pixel_meters_dict=cal_inference_info[\"pixel_info_dicts\"][record_name]))\n",
    "print(etl_ece_loss(pixel_meters_dict=cal_inference_info[\"pixel_info_dicts\"][record_name]))\n",
    "print(ecw_ece_loss(pixel_meters_dict=cal_inference_info[\"pixel_info_dicts\"][record_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ese.experiment.metrics.elm import *\n",
    "\n",
    "print(elm_loss(pixel_meters_dict=cal_inference_info[\"pixel_info_dicts\"][record_name]))\n",
    "print(tl_elm_loss(pixel_meters_dict=cal_inference_info[\"pixel_info_dicts\"][record_name]))\n",
    "print(cw_elm_loss(pixel_meters_dict=cal_inference_info[\"pixel_info_dicts\"][record_name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image-level Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_info_df = cal_inference_info['image_info_df']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ese.experiment.analysis.utils import reorder_splits\n",
    "\n",
    "unique_image_df = reorder_splits(image_info_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ese.experiment.analysis.err_diagrams import viz_quality_metric_distributions\n",
    "\n",
    "viz_quality_metric_distributions(\n",
    "    unique_image_df, \n",
    "    title=f\"{dataset} Quality Metric Distributions\",\n",
    "    col_wrap=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ese.experiment.analysis.err_diagrams import viz_calibration_metric_distributions\n",
    "\n",
    "viz_calibration_metric_distributions(\n",
    "    unique_image_df, \n",
    "    title=f\"{dataset} Calibration Metric Score Distributions\",\n",
    "    col_wrap=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ese.experiment.analysis.err_diagrams import viz_cal_metric_corr\n",
    "\n",
    "viz_cal_metric_corr(\n",
    "    unique_image_df,\n",
    "    title=f\"{dataset} Calibration Metric Score Correlation\",\n",
    "    heatmap_row=\"qual_metric\",\n",
    "    heatmap_col=\"cal_metric\",\n",
    "    col=\"cal_metric_type\",\n",
    "    height=7\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_qm_sorted = unique_image_df.sort_values(by=[\"qual_metric\", \"cal_metric_type\"])\n",
    "g = sns.relplot(\n",
    "    df_qm_sorted, \n",
    "    x=\"cal_m_score\", \n",
    "    y=\"qual_score\", \n",
    "    col=\"cal_metric\", \n",
    "    row=\"qual_metric\", \n",
    "    height=3.5, \n",
    "    aspect=1,\n",
    "    facet_kws={'sharey': False, 'sharex': False}\n",
    "    )\n",
    "# g.set(xlim=(0, 1), ylim=(0, 1))\n",
    "g.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g = sns.relplot(\n",
    "#     df_qm_sorted, \n",
    "#     x=\"log_true_lab_amount\", \n",
    "#     y=\"qual_score\", \n",
    "#     hue=\"qual_metric\", \n",
    "#     col=\"qual_metric\", \n",
    "#     row=\"label\",\n",
    "#     height=4, \n",
    "#     aspect=1,\n",
    "#     facet_kws={'sharey': False, 'sharex': False}\n",
    "#     )\n",
    "# #g.set(ylim=(0, 1))\n",
    "# g.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g = sns.relplot(\n",
    "#     df_qm_sorted, \n",
    "#     x=\"log_true_lab_amount\", \n",
    "#     y=\"cal_m_score\", \n",
    "#     hue=\"cal_metric\", \n",
    "#     col=\"cal_metric\", \n",
    "#     row=\"label\",\n",
    "#     height=4,\n",
    "#     aspect=1,\n",
    "#     facet_kws={'sharey': False, 'sharex': False}\n",
    "#     )\n",
    "# g.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UniverSegTF",
   "language": "python",
   "name": "universegtf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
