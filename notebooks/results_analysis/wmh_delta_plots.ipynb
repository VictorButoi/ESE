{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/storage/vbutoi/projects')\n",
    "sys.path.append('/storage/vbutoi/libraries')\n",
    "sys.path.append('/storage/vbutoi/projects/ESE')\n",
    "sys.path.append('/storage/vbutoi/projects/UniverSeg')\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "import os \n",
    "os.environ['DATAPATH'] = ':'.join((\n",
    "       '/storage/vbutoi/datasets',\n",
    "))\n",
    "\n",
    "# Results loader object does everything\n",
    "from ionpy.analysis import ResultsLoader\n",
    "from pathlib import Path\n",
    "root = Path(\"/storage/vbutoi/scratch/ESE\")\n",
    "rs = ResultsLoader()\n",
    "\n",
    "# For using code without restarting.\n",
    "%load_ext autoreload\n",
    "%autoreload \n",
    "# For using yaml configs.\n",
    "%load_ext yamlmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%yaml results_cfg \n",
    "\n",
    "log:\n",
    "    root: /storage/vbutoi/scratch/ESE/inference\n",
    "    load_pixel_meters: True \n",
    "    remove_shared_columns: True\n",
    "    drop_nan_metric_rows: False\n",
    "    min_fg_pixels: 100\n",
    "    inference_paths:\n",
    "        - \"01_17_24_Ignore_None/WMH_Individual_Uncalibrated\"\n",
    "        - \"01_17_24_Ignore_None/WMH_Individual_TempScaling\"\n",
    "        - \"01_17_24_Ignore_None/WMH_Individual_VectorScaling\"\n",
    "        - \"01_17_24_Ignore_None/WMH_Individual_DirichletScaling\"\n",
    "        - \"01_17_24_Ignore_None/WMH_Individual_LTS\"\n",
    "        - \"01_17_24_Ignore_None/WMH_Ensemble_Uncalibrated\"\n",
    "        - \"01_17_24_Ignore_None/WMH_Ensemble_TempScaling\"\n",
    "        - \"01_17_24_Ignore_None/WMH_Ensemble_VectorScaling\"\n",
    "        - \"01_17_24_Ignore_None/WMH_Ensemble_DirichletScaling\"\n",
    "        - \"01_17_24_Ignore_None/WMH_Ensemble_LTS\"\n",
    "    \n",
    "calibration:\n",
    "    conf_interval:\n",
    "        - 0.5\n",
    "        - 1.\n",
    "    num_bins: 10\n",
    "    square_diff: False \n",
    "    neighborhood_width: 3\n",
    "\n",
    "# cal_metrics:\n",
    "#     - ECE:\n",
    "#         _fn: ese.experiment.metrics.ece.ece_loss\n",
    "#     - CW_ECE:\n",
    "#         _fn: ese.experiment.metrics.ece.cw_ece_loss\n",
    "#     - Edge_ECE:\n",
    "#         _fn: ese.experiment.metrics.ece.edge_ece_loss\n",
    "#     - ELM:\n",
    "#         _fn: ese.experiment.metrics.elm.elm_loss\n",
    "#     - Foreground_ECE:\n",
    "#         _fn: ese.experiment.metrics.ece.ece_loss\n",
    "#         ignore_index: 0\n",
    "#     - Foreground_CW_ECE:\n",
    "#         _fn: ese.experiment.metrics.ece.cw_ece_loss\n",
    "#         ignore_index: 0\n",
    "#     - Foreground_Edge_ECE:\n",
    "#         _fn: ese.experiment.metrics.ece.edge_ece_loss\n",
    "#         ignore_index: 0       \n",
    "#     - Foreground_ELM:\n",
    "#         _fn: ese.experiment.metrics.elm.elm_loss\n",
    "#         ignore_index: 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ese.experiment.analysis.inference import load_cal_inference_stats\n",
    "\n",
    "image_info_df = load_cal_inference_stats(\n",
    "    results_cfg=results_cfg\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's try to see if there is any hope with having better ECE/ELM makes better ensembles. Note that this isn't a conclusive result just because the number of samples per images that are used to calculate ECE/ELM are not sufficient to get actual statistical quantities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First thing we have to do is calculate per slice per model configuration, the delta in performance that each configuration has between that configuration's slice performance and the average un-calibrated UNet performance on that slice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet_info_df = image_info_df[image_info_df['ensemble'] == False].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet_group_keys = [\n",
    "    'data_id',\n",
    "    'slice_idx',\n",
    "    'num_lab_0_pixels',\n",
    "    'num_lab_1_pixels',\n",
    "    'num_bins',\n",
    "    'neighborhood_width',\n",
    "    'square_diff',\n",
    "    'image_metric',\n",
    "    'model._class',\n",
    "    'model.checkpoint',\n",
    "    'model._pretrained_class',\n",
    "    'groupavg_image_metric',\n",
    "    'model_class',\n",
    "    'pretrained_model_class',\n",
    "    'metric_type',\n",
    "    'model_type',\n",
    "    'calibrator'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a check, that when you group by these keys, you get a unique row.\n",
    "# If not, you need to add more keys.\n",
    "num_rows_per_group = unet_info_df.groupby(unet_group_keys).size()\n",
    "# They should have exactly 4, for four seeds.\n",
    "assert (num_rows_per_group.max() == 4) and (num_rows_per_group.min() == 4),\\\n",
    "    f\"Grouping by these keys does not give the required number of rows per seed (4), Got: {num_rows_per_group}.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group everything we need. \n",
    "average_seed_unet = unet_info_df.groupby(unet_group_keys).agg({\n",
    "    'metric_score': 'mean', \n",
    "    'groupavg_metric_score': 'mean'\n",
    "    }).reset_index()\n",
    "# Set some useful variables.\n",
    "average_seed_unet['experiment.pretrained_seed'] = 'Average'\n",
    "average_seed_unet['pretrained_seed'] = 'Average'\n",
    "average_seed_unet['model_type'] = 'group' # Now this is a group of results\n",
    "\n",
    "def method_name(pretrained_model_class, model_class):\n",
    "    if pretrained_model_class == \"None\":\n",
    "        return f\"{model_class.split('.')[-1]} (seed=Average)\"\n",
    "    else:\n",
    "        return f\"{pretrained_model_class.split('.')[-1]} (seed=Average)\"\n",
    "\n",
    "def configuration(method_name, calibrator):\n",
    "    return f\"{method_name}_{calibrator}\"\n",
    "\n",
    "average_seed_unet.augment(method_name)\n",
    "average_seed_unet.augment(configuration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add this unet group back to image info df\n",
    "info_df_w_baselines = pd.concat([image_info_df, average_seed_unet], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we have to add to each row a column that is the difference betweeen the row's metric_score and the metric_score corresponding to the same image metric as mean uncalibrated UNet performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Get the rows corresponding to a unet aveages across multiple seeds with no calibration.\n",
    "average_unet_row = info_df_w_baselines[(info_df_w_baselines['pretrained_seed'] == 'Average') & (info_df_w_baselines['calibrator'] == 'Uncalibrated')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_datapoint_cols = ['data_id', 'slice_idx', 'image_metric', 'groupavg_image_metric']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check that for each datapoint we only have one average unet row.\n",
    "num_avg_unets_per_datapoint = average_unet_row.groupby(unique_datapoint_cols).size()\n",
    "assert num_avg_unets_per_datapoint.max() == 1,\\\n",
    "    f\"There should be only one row for each data_id, slice_idx, image_metric, and groupavg image metric combination, got {num_avg_unets_per_datapoint}.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure there are no NaNs in the average UNet rows.\n",
    "assert average_unet_row['metric_score'].isna().sum() == 0, \"There should be no NaNs in metric_score of UNet rows.\"\n",
    "assert average_unet_row['groupavg_metric_score'].isna().sum() == 0, \"There should be no NaNs in groupavg_metric_score of UNet rows.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Merge based on 'image_metric', 'subject_id', and 'slice_idx'\n",
    "info_df_w_avg_unet_cols = pd.merge(\n",
    "    info_df_w_baselines, \n",
    "    average_unet_row[unique_datapoint_cols + ['metric_score', 'groupavg_metric_score']], \n",
    "    on=unique_datapoint_cols, \n",
    "    how='left', \n",
    "    suffixes=('', '_average_unet')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Calculate the difference\n",
    "info_df_w_avg_unet_cols['metric_delta'] = info_df_w_avg_unet_cols['metric_score'] - info_df_w_avg_unet_cols['metric_score_average_unet'] # Current - Baseline\n",
    "info_df_w_avg_unet_cols['groupavg_metric_delta'] = info_df_w_avg_unet_cols['groupavg_metric_score'] - info_df_w_avg_unet_cols['groupavg_metric_score_average_unet'] # Current - Baseline\n",
    "# Drop those columns\n",
    "info_df_w_delta = info_df_w_avg_unet_cols.drop(columns=['metric_score_average_unet', 'groupavg_metric_score_average_unet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# At this point, we want to drop the rows that correspond to having NaN deltas\n",
    "# This is because we are only interested in the rows that have a baseline.\n",
    "# We will use this to plot the deltas.\n",
    "info_df_w_delta = info_df_w_delta.dropna(subset=['metric_delta', 'groupavg_metric_delta'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we can look at trends! We want to make some scatterplots to look at relationships between calibration scores and their relative improvement over the baseline.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we want only the rows corresponding to group metrics, no longer looking at seeds.\n",
    "grouped_models_df = info_df_w_delta[info_df_w_delta['model_type'] == 'group'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SANITY CHECKS, MAKE SURE THAT FOR CALIBRATORS UNCALIBRATED, TEMPERATURE_SCALING, LTS\n",
    "for calibrator in [\"Uncalibrated\", \"Temperature_Scaling\", \"LTS\"]:\n",
    "    unique_qual_metrics = grouped_models_df[grouped_models_df['metric_type'] == 'quality']['image_metric'].unique()\n",
    "    for quality_metric in unique_qual_metrics:\n",
    "        # Checkign that the delta is 0 for the calibrator and the quality_metric\n",
    "        rows = grouped_models_df[\n",
    "            (grouped_models_df['calibrator'] == calibrator) & \n",
    "            (grouped_models_df['image_metric'] == quality_metric) &\n",
    "            (grouped_models_df['method_name'] == 'UNet (seed=Average)')\n",
    "        ]\n",
    "        assert (rows['metric_delta'] == 0).all(),\\\n",
    "            f\"Delta from base should be 0 for the calibrator {calibrator} and the quality metric {quality_metric}, got {rows['metric_delta']}.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a bunch of new rows where the image_metric is the groupavg_image_metric and the metric_score is the groupavg_metric_score and the metric_delta is the groupavg_metric_delta\n",
    "groupavg_rows = grouped_models_df.copy()\n",
    "groupavg_rows['image_metric'] = groupavg_rows['groupavg_image_metric']\n",
    "groupavg_rows['metric_score'] = groupavg_rows['groupavg_metric_score']\n",
    "groupavg_rows['metric_delta'] = groupavg_rows['groupavg_metric_delta']\n",
    "# Drop the groupavg columns\n",
    "standard_image_rows = grouped_models_df.drop(columns=['groupavg_image_metric', 'groupavg_metric_score', 'groupavg_metric_delta']) \n",
    "groupavg_rows = groupavg_rows.drop(columns=['groupavg_image_metric', 'groupavg_metric_score', 'groupavg_metric_delta'])\n",
    "# Concatenate the two\n",
    "grouped_models_df = pd.concat([standard_image_rows, groupavg_rows], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pivot table with 'metric_type' as columns\n",
    "pivot_grouped_models_df = grouped_models_df.pivot_table(\n",
    "    index=['configuration', 'method_name', 'calibrator', 'data_id', 'slice_idx'],\n",
    "    values=['metric_score', 'metric_delta'], \n",
    "    columns=['metric_type', 'image_metric'], \n",
    "    aggfunc='mean'\n",
    ").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy so that we can modify the column names\n",
    "pivot_perf_per_datpoint = pivot_grouped_models_df.copy()\n",
    "# Make new column names.\n",
    "new_cols = []\n",
    "for col in pivot_grouped_models_df.columns.values:\n",
    "    if col[0] == 'metric_delta':\n",
    "        new_cols.append(f'delta_{col[-1]}')\n",
    "    elif col[-1] == '':\n",
    "        new_cols.append(col[0])\n",
    "    else:\n",
    "        new_cols.append(col[-1])\n",
    "# Set the column names to be the lowest non empty level per column in the multi-index\n",
    "pivot_perf_per_datpoint.columns = new_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_perf_per_datpoint.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to sort the pivot_df so that the order of the method names is\n",
    "# UNet (seed=Average), Ensemble (mean, logits), Ensemble (mean, probs),\n",
    "# and the order of the calibrators is Uncalibrated, Temperature Scaling, LTS, Vector Scaling, Dirichlet Scaling\n",
    "method_order_name = ['UNet (seed=Average)', 'Ensemble (mean, logits)', 'Ensemble (mean, probs)']\n",
    "calibrator_order_name = ['Uncalibrated', 'Temperature_Scaling', 'LTS', 'Vector_Scaling', 'Dirichlet_Scaling']\n",
    "# Sort the methods\n",
    "pivot_perf_per_datpoint['method_name'] = pivot_perf_per_datpoint['method_name'].astype('category')\n",
    "pivot_perf_per_datpoint['method_name'] = pivot_perf_per_datpoint['method_name'].cat.reorder_categories(method_order_name)\n",
    "# Sort the calibrators\n",
    "pivot_perf_per_datpoint['calibrator'] = pivot_perf_per_datpoint['calibrator'].astype('category')\n",
    "pivot_perf_per_datpoint['calibrator'] = pivot_perf_per_datpoint['calibrator'].cat.reorder_categories(calibrator_order_name)\n",
    "# Sort the dataframe\n",
    "sorted_pivot_perf_per_datpoint = pivot_perf_per_datpoint.sort_values(by=['method_name', 'calibrator'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at change in *predicted ensemble* calibration vs change in Dice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ese.experiment.analysis.plot_utils import add_corr_coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.relplot(\n",
    "    data=sorted_pivot_perf_per_datpoint, \n",
    "    x='delta_Image_ECE', \n",
    "    y='delta_Dice',\n",
    "    row='method_name',\n",
    "    col='calibrator',\n",
    "    hue='method_name',\n",
    "    style='calibrator',\n",
    "    kind='scatter',\n",
    "    height=4,\n",
    "    facet_kws=dict(margin_titles=True)\n",
    "    )\n",
    "g.set_titles(\"\")  # Set titles to empty string\n",
    "g.set(xlim=(-0.006, 0.006), ylim=(-0.13, 0.13))\n",
    "# Show the plot\n",
    "g.fig.subplots_adjust(hspace=0.1, wspace=0.15)\n",
    "# Add correlation coefficients\n",
    "add_corr_coefficients(\n",
    "    g, \n",
    "    data=sorted_pivot_perf_per_datpoint, \n",
    "    x='delta_Image_ECE', \n",
    "    y='delta_Dice',\n",
    "    row='method_name',\n",
    "    col='calibrator'\n",
    ")\n",
    "# Add a title to the entire figure, and make it slightly bigger than the default\n",
    "g.fig.suptitle('Relationship Between Total ECE Delta and Dice Score Delta', size=20)\n",
    "g.fig.subplots_adjust(top=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.relplot(\n",
    "    data=sorted_pivot_perf_per_datpoint, \n",
    "    x='delta_Image_Foreground-ECE', \n",
    "    y='delta_Dice',\n",
    "    row='method_name',\n",
    "    col='calibrator',\n",
    "    hue='method_name',\n",
    "    style='calibrator',\n",
    "    height=4,\n",
    "    facet_kws=dict(margin_titles=True)\n",
    "    )\n",
    "g.set_titles(\"\")  # Set titles to empty string\n",
    "g.set(xlim=(-0.15, 0.15), ylim=(-0.12, 0.12))\n",
    "# Show the plot\n",
    "g.fig.subplots_adjust(hspace=0.1, wspace=0.15)\n",
    "# Add correlation coefficients\n",
    "add_corr_coefficients(\n",
    "    g, \n",
    "    data=sorted_pivot_perf_per_datpoint, \n",
    "    x='delta_Image_Foreground-ECE', \n",
    "    y='delta_Dice',\n",
    "    row='method_name',\n",
    "    col='calibrator'\n",
    ")\n",
    "# Add a title to the entire figure, and make it slightly bigger than the default\n",
    "g.fig.suptitle('Relationship Between Foreground ECE Delta and Dice Score Delta', size=20)\n",
    "g.fig.subplots_adjust(top=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.relplot(\n",
    "    data=sorted_pivot_perf_per_datpoint, \n",
    "    x='delta_Image_Edge-ECE', \n",
    "    y='delta_Dice',\n",
    "    row='method_name',\n",
    "    col='calibrator',\n",
    "    hue='method_name',\n",
    "    style='calibrator',\n",
    "    height=4,\n",
    "    facet_kws=dict(margin_titles=True)\n",
    "    )\n",
    "g.set_titles(\"\")  # Set titles to empty string\n",
    "g.set(xlim=(-0.15, 0.15), ylim=(-0.12, 0.12))\n",
    "# Show the plot\n",
    "g.fig.subplots_adjust(hspace=0.1, wspace=0.15)\n",
    "# Add correlation coefficients\n",
    "add_corr_coefficients(\n",
    "    g, \n",
    "    data=sorted_pivot_perf_per_datpoint, \n",
    "    x='delta_Image_Edge-ECE', \n",
    "    y='delta_Dice',\n",
    "    row='method_name',\n",
    "    col='calibrator'\n",
    ")\n",
    "# Add a title to the entire figure, and make it slightly bigger than the default\n",
    "g.fig.suptitle('Relationship Between Total Edge ECE Delta and Dice Score Delta', size=20)\n",
    "g.fig.subplots_adjust(top=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.relplot(\n",
    "    data=sorted_pivot_perf_per_datpoint, \n",
    "    x='delta_Image_Foreground-Edge-ECE', \n",
    "    y='delta_Dice',\n",
    "    row='method_name',\n",
    "    col='calibrator',\n",
    "    hue='method_name',\n",
    "    style='calibrator',\n",
    "    height=4,\n",
    "    facet_kws=dict(margin_titles=True)\n",
    "    )\n",
    "g.set_titles(\"\")  # Set titles to empty string\n",
    "g.set(xlim=(-0.15, 0.15), ylim=(-0.12, 0.12))\n",
    "# Show the plot\n",
    "g.fig.subplots_adjust(hspace=0.1, wspace=0.15)\n",
    "# Add correlation coefficients\n",
    "add_corr_coefficients(\n",
    "    g, \n",
    "    data=sorted_pivot_perf_per_datpoint, \n",
    "    x='delta_Image_Foreground-Edge-ECE', \n",
    "    y='delta_Dice',\n",
    "    row='method_name',\n",
    "    col='calibrator'\n",
    ")\n",
    "# Add a title to the entire figure, and make it slightly bigger than the default\n",
    "g.fig.suptitle('Relationship Between Foreground Edge ECE Delta and Dice Score Delta', size=20)\n",
    "g.fig.subplots_adjust(top=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.relplot(\n",
    "    data=sorted_pivot_perf_per_datpoint, \n",
    "    x='delta_Image_ELM', \n",
    "    y='delta_Dice',\n",
    "    row='method_name',\n",
    "    col='calibrator',\n",
    "    hue='method_name',\n",
    "    style='calibrator',\n",
    "    height=4,\n",
    "    facet_kws=dict(margin_titles=True)\n",
    "    )\n",
    "g.set_titles(\"\")  # Set titles to empty string\n",
    "g.set(xlim=(-0.006, 0.006), ylim=(-0.12, 0.12))\n",
    "# Show the plot\n",
    "g.fig.subplots_adjust(hspace=0.1, wspace=0.15)\n",
    "# Add correlation coefficients\n",
    "add_corr_coefficients(\n",
    "    g, \n",
    "    data=sorted_pivot_perf_per_datpoint, \n",
    "    x='delta_Image_ELM', \n",
    "    y='delta_Dice',\n",
    "    row='method_name',\n",
    "    col='calibrator'\n",
    ")\n",
    "# Add a title to the entire figure, and make it slightly bigger than the default\n",
    "g.fig.suptitle('Relationship Between Total ELM Delta and Dice Score Delta', size=20)\n",
    "g.fig.subplots_adjust(top=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.relplot(\n",
    "    data=sorted_pivot_perf_per_datpoint, \n",
    "    x='delta_Image_Foreground-ELM', \n",
    "    y='delta_Dice',\n",
    "    row='method_name',\n",
    "    col='calibrator',\n",
    "    hue='method_name',\n",
    "    style='calibrator',\n",
    "    height=4,\n",
    "    facet_kws=dict(margin_titles=True)\n",
    "    )\n",
    "g.set_titles(\"\")  # Set titles to empty string\n",
    "g.set(xlim=(-0.15, 0.15), ylim=(-0.12, 0.12))\n",
    "# Show the plot\n",
    "g.fig.subplots_adjust(hspace=0.1, wspace=0.15)\n",
    "# Add correlation coefficients\n",
    "add_corr_coefficients(\n",
    "    g, \n",
    "    data=sorted_pivot_perf_per_datpoint, \n",
    "    x='delta_Image_Foreground-ELM', \n",
    "    y='delta_Dice',\n",
    "    row='method_name',\n",
    "    col='calibrator'\n",
    ")\n",
    "# Add a title to the entire figure, and make it slightly bigger than the default\n",
    "g.fig.suptitle('Relationship Between Foreground ELM Delta and Dice Score Delta', size=20)\n",
    "g.fig.subplots_adjust(top=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we can look at the average ensemble member calibration vs change in dice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.relplot(\n",
    "    data=sorted_pivot_perf_per_datpoint, \n",
    "    x='delta_GroupAvg_Image_ECE', \n",
    "    y='delta_Dice',\n",
    "    row='method_name',\n",
    "    col='calibrator',\n",
    "    hue='method_name',\n",
    "    style='calibrator',\n",
    "    kind='scatter',\n",
    "    height=4,\n",
    "    facet_kws=dict(margin_titles=True)\n",
    "    )\n",
    "g.set_titles(\"\")  # Set titles to empty string\n",
    "g.set(xlim=(-0.006, 0.006), ylim=(-0.13, 0.13))\n",
    "# Show the plot\n",
    "g.fig.subplots_adjust(hspace=0.1, wspace=0.15)\n",
    "# Add correlation coefficients\n",
    "add_corr_coefficients(\n",
    "    g, \n",
    "    data=sorted_pivot_perf_per_datpoint, \n",
    "    x='delta_GroupAvg_Image_ECE', \n",
    "    y='delta_Dice',\n",
    "    row='method_name',\n",
    "    col='calibrator'\n",
    ")\n",
    "# Add a title to the entire figure, and make it slightly bigger than the default\n",
    "g.fig.suptitle('Relationship Between Total Group Avg ECE Delta and Dice Score Delta', size=20)\n",
    "g.fig.subplots_adjust(top=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.relplot(\n",
    "    data=sorted_pivot_perf_per_datpoint, \n",
    "    x='delta_GroupAvg_Image_Foreground-ECE', \n",
    "    y='delta_Dice',\n",
    "    row='method_name',\n",
    "    col='calibrator',\n",
    "    hue='method_name',\n",
    "    style='calibrator',\n",
    "    height=4,\n",
    "    facet_kws=dict(margin_titles=True)\n",
    "    )\n",
    "g.set_titles(\"\")  # Set titles to empty string\n",
    "g.set(xlim=(-0.15, 0.15), ylim=(-0.12, 0.12))\n",
    "# Show the plot\n",
    "g.fig.subplots_adjust(hspace=0.1, wspace=0.15)\n",
    "# Add correlation coefficients\n",
    "add_corr_coefficients(\n",
    "    g, \n",
    "    data=sorted_pivot_perf_per_datpoint, \n",
    "    x='delta_GroupAvg_Image_Foreground-ECE', \n",
    "    y='delta_Dice',\n",
    "    row='method_name',\n",
    "    col='calibrator'\n",
    ")\n",
    "# Add a title to the entire figure, and make it slightly bigger than the default\n",
    "g.fig.suptitle('Relationship Between Foreground Group Avg ECE Delta and Dice Score Delta', size=20)\n",
    "g.fig.subplots_adjust(top=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.relplot(\n",
    "    data=sorted_pivot_perf_per_datpoint, \n",
    "    x='delta_GroupAvg_Image_Edge-ECE', \n",
    "    y='delta_Dice',\n",
    "    row='method_name',\n",
    "    col='calibrator',\n",
    "    hue='method_name',\n",
    "    style='calibrator',\n",
    "    height=4,\n",
    "    facet_kws=dict(margin_titles=True)\n",
    "    )\n",
    "g.set_titles(\"\")  # Set titles to empty string\n",
    "g.set(xlim=(-0.15, 0.15), ylim=(-0.12, 0.12))\n",
    "# Show the plot\n",
    "g.fig.subplots_adjust(hspace=0.1, wspace=0.15)\n",
    "# Add correlation coefficients\n",
    "add_corr_coefficients(\n",
    "    g, \n",
    "    data=sorted_pivot_perf_per_datpoint, \n",
    "    x='delta_GroupAvg_Image_Edge-ECE', \n",
    "    y='delta_Dice',\n",
    "    row='method_name',\n",
    "    col='calibrator'\n",
    ")\n",
    "# Add a title to the entire figure, and make it slightly bigger than the default\n",
    "g.fig.suptitle('Relationship Between Group Avg Edge ECE Delta and Dice Score Delta', size=20)\n",
    "g.fig.subplots_adjust(top=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.relplot(\n",
    "    data=sorted_pivot_perf_per_datpoint, \n",
    "    x='delta_GroupAvg_Image_Foreground-Edge-ECE', \n",
    "    y='delta_Dice',\n",
    "    row='method_name',\n",
    "    col='calibrator',\n",
    "    hue='method_name',\n",
    "    style='calibrator',\n",
    "    height=4,\n",
    "    facet_kws=dict(margin_titles=True)\n",
    "    )\n",
    "g.set_titles(\"\")  # Set titles to empty string\n",
    "g.set(xlim=(-0.15, 0.15), ylim=(-0.12, 0.12))\n",
    "# Show the plot\n",
    "g.fig.subplots_adjust(hspace=0.1, wspace=0.15)\n",
    "# Add correlation coefficients\n",
    "add_corr_coefficients(\n",
    "    g, \n",
    "    data=sorted_pivot_perf_per_datpoint, \n",
    "    x='delta_GroupAvg_Image_Foreground-Edge-ECE', \n",
    "    y='delta_Dice',\n",
    "    row='method_name',\n",
    "    col='calibrator'\n",
    ")\n",
    "# Add a title to the entire figure, and make it slightly bigger than the default\n",
    "g.fig.suptitle('Relationship Between Group Avg Foreground Edge ECE Delta and Dice Score Delta', size=20)\n",
    "g.fig.subplots_adjust(top=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.relplot(\n",
    "    data=sorted_pivot_perf_per_datpoint, \n",
    "    x='delta_GroupAvg_Image_ELM', \n",
    "    y='delta_Dice',\n",
    "    row='method_name',\n",
    "    col='calibrator',\n",
    "    hue='method_name',\n",
    "    style='calibrator',\n",
    "    height=4,\n",
    "    facet_kws=dict(margin_titles=True)\n",
    "    )\n",
    "g.set_titles(\"\")  # Set titles to empty string\n",
    "g.set(xlim=(-0.006, 0.006), ylim=(-0.12, 0.12))\n",
    "# Show the plot\n",
    "g.fig.subplots_adjust(hspace=0.1, wspace=0.15)\n",
    "# Add correlation coefficients\n",
    "add_corr_coefficients(\n",
    "    g, \n",
    "    data=sorted_pivot_perf_per_datpoint, \n",
    "    x='delta_GroupAvg_Image_ELM', \n",
    "    y='delta_Dice',\n",
    "    row='method_name',\n",
    "    col='calibrator'\n",
    ")\n",
    "# Add a title to the entire figure, and make it slightly bigger than the default\n",
    "g.fig.suptitle('Relationship Between Total Group Avg ELM Delta and Dice Score Delta', size=20)\n",
    "g.fig.subplots_adjust(top=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.relplot(\n",
    "    data=sorted_pivot_perf_per_datpoint, \n",
    "    x='delta_GroupAvg_Image_Foreground-ELM', \n",
    "    y='delta_Dice',\n",
    "    row='method_name',\n",
    "    col='calibrator',\n",
    "    hue='method_name',\n",
    "    style='calibrator',\n",
    "    height=4,\n",
    "    facet_kws=dict(margin_titles=True)\n",
    "    )\n",
    "g.set_titles(\"\")  # Set titles to empty string\n",
    "g.set(xlim=(-0.15, 0.15), ylim=(-0.12, 0.12))\n",
    "# Show the plot\n",
    "g.fig.subplots_adjust(hspace=0.1, wspace=0.15)\n",
    "# Add correlation coefficients\n",
    "add_corr_coefficients(\n",
    "    g, \n",
    "    data=sorted_pivot_perf_per_datpoint, \n",
    "    x='delta_GroupAvg_Image_Foreground-ELM', \n",
    "    y='delta_Dice',\n",
    "    row='method_name',\n",
    "    col='calibrator'\n",
    ")\n",
    "# Add a title to the entire figure, and make it slightly bigger than the default\n",
    "g.fig.suptitle('Relationship Between Foreground Group Avg ELM Delta and Dice Score Delta', size=20)\n",
    "g.fig.subplots_adjust(top=0.9)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UniverSegTF",
   "language": "python",
   "name": "universegtf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
