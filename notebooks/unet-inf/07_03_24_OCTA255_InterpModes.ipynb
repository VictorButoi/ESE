{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/storage/vbutoi/projects')\n",
    "sys.path.append('/storage/vbutoi/libraries')\n",
    "sys.path.append('/storage/vbutoi/projects/ESE')\n",
    "sys.path.append('/storage/vbutoi/projects/UniverSeg')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.set_context(\"talk\")\n",
    "\n",
    "import os \n",
    "os.environ['DATAPATH'] = ':'.join((\n",
    "       '/storage/vbutoi/datasets',\n",
    "))\n",
    "\n",
    "from ese.experiment.analysis.analyze_inf import load_cal_inference_stats\n",
    "# Results loader object does everything\n",
    "from ionpy.analysis import ResultsLoader\n",
    "from pathlib import Path\n",
    "root = Path(\"/storage/vbutoi/scratch/ESE\")\n",
    "rs = ResultsLoader()\n",
    "\n",
    "# For using code without restarting.\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# For using yaml configs.\n",
    "%load_ext yamlmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%yaml results_cfg \n",
    "\n",
    "log:\n",
    "    root: /storage/vbutoi/scratch/ESE/inference\n",
    "    inference_groups: \n",
    "        - '07_03_24_OCTA_6M_Lab255_InterpolationSettings'\n",
    "\n",
    "options:\n",
    "    add_dice_loss_rows: True\n",
    "    drop_nan_metric_rows: True \n",
    "    remove_shared_columns: False\n",
    "    equal_rows_per_cfg_assert: True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_df = load_cal_inference_stats(\n",
    "    results_cfg=results_cfg,\n",
    "    load_cached=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'dataset.version' in inference_df.columns:\n",
    "    inference_df['dataset_version'] = inference_df['dataset.version'].map(lambda x: float(x))\n",
    "else:\n",
    "    inference_df['dataset_version'] = 1.0\n",
    "\n",
    "def loss_func(loss_func_class):\n",
    "    if loss_func_class == \"None\":\n",
    "        return 'Combo'\n",
    "    else:\n",
    "        return loss_func_class.split('.')[-1]\n",
    "    \n",
    "def resolution(dataset_version):\n",
    "    if dataset_version == 0.1:\n",
    "        return \"128\"\n",
    "    elif dataset_version == 1.0:\n",
    "        return \"400\" \n",
    "    else:\n",
    "        raise ValueError(f\"Unknown dataset version {dataset_version}\")\n",
    "\n",
    "inference_df.augment(loss_func)\n",
    "inference_df.augment(resolution)\n",
    "\n",
    "# Remove rows corresponding to pretrained seed 42, it crashed.\n",
    "inference_df = inference_df[inference_df['experiment_pretrained_seed'] != 42].reset_index(drop=True)\n",
    "# We want to remove all rows where experiment_resolution_output_mode = nearest and align_corners = True\n",
    "inference_df = inference_df[\n",
    "                    ~((inference_df['experiment_resolution_output_mode'] == 'nearest') & \n",
    "                    (inference_df['experiment_resolution_output_align_corners'] == True))\n",
    "                ].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library Funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_error_df(raw_df, groupby_keys, value_vars, var_name, value_name):\n",
    "    # Make a clone of the proportion df.\n",
    "    input_df = raw_df.copy()\n",
    "    # Melt the dataframe to have a single column for the error.\n",
    "    error_df = pd.melt(\n",
    "        input_df,\n",
    "        id_vars=groupby_keys,\n",
    "        value_vars=value_vars,\n",
    "        var_name=var_name,\n",
    "        value_name=value_name,\n",
    "    )\n",
    "    # Make some columns that are useful for plotting.\n",
    "    error_df[f'absolute {value_name}'] = error_df[value_name].abs()\n",
    "    # Return the melted dataframe.\n",
    "    return error_df\n",
    "\n",
    "\n",
    "def calibrator(model_pretrained_exp_root):\n",
    "    if \"SVLS\" in model_pretrained_exp_root:\n",
    "        return \"SVLS\"\n",
    "    else:\n",
    "        return \"Uncal\"\n",
    "    \n",
    "\n",
    "def upsample_cfg(experiment_resolution_output_mode, experiment_resolution_output_align_corners):\n",
    "    return f\"{experiment_resolution_output_mode} align={experiment_resolution_output_align_corners}\"\n",
    "\n",
    "\n",
    "def process_method_names(input_df, value_name):\n",
    "    # Make a clone of the input_df\n",
    "    df = input_df.copy()\n",
    "    # Drop all the rows where calibrator != Uncalibrated AND the proportion_type is hard_proportion_error.\n",
    "    df = df[~((df['calibrator'] != 'Uncal') & (df['proportion_type'] == f'hard {value_name}'))]\n",
    "    # Then we augment the proportion_type with the calibrator name.\n",
    "    def proportion_type(calibrator, loss_func, proportion_type):\n",
    "        # If the loss function is PixelCELoss, we drop the loss function name.\n",
    "        if loss_func == \"PixelCELoss\":\n",
    "            proc_loss_func = \"CE\"\n",
    "        else:\n",
    "            proc_loss_func = \"Dice\"\n",
    "\n",
    "        # If the proportion_type is hard_proportion_error, we drop the calibrator name.\n",
    "        if proportion_type in [\"new gt error\", \"new gt relative error\"]:\n",
    "            return \"New GT\"\n",
    "        elif calibrator == \"Uncal\":\n",
    "            return \"Uncal \" + proportion_type.split(\" \")[0] + f\" ({proc_loss_func})\"\n",
    "        else:\n",
    "            return calibrator + \" soft\" + f\" ({proc_loss_func})\"\n",
    "    # Finally, sort by data_id\n",
    "    df['proportion type'] = df.apply(lambda x: proportion_type(x['calibrator'], x['loss_func'], x['proportion_type']), axis=1)\n",
    "    df = df.sort_values(by=\"data_id\")\n",
    "    # Drop the duplicate rows and reset the index.\n",
    "    df = df.drop_duplicates().reset_index(drop=True)\n",
    "    # Return the augmented dataframe.\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give a new calibrator and interpolate cfg columns.\n",
    "inference_df.augment(calibrator)\n",
    "inference_df.augment(upsample_cfg)\n",
    "\n",
    "# Get the relevant columns for looking at the Dice score and Image ECE\n",
    "metric_cols = [\n",
    "    \"calibrator\",\n",
    "    \"data_id\",\n",
    "    \"experiment_pretrained_seed\",\n",
    "    \"image_metric\",\n",
    "    \"loss_func\",\n",
    "    \"metric_score\",\n",
    "    \"model_pretrained_exp_root\",\n",
    "    \"split\",\n",
    "    \"upsample_cfg\",\n",
    "]\n",
    "\n",
    "# Take these columns of the inference_df, drop other columns and delete duplicate rows.\n",
    "metric_df = inference_df[metric_cols].drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_method(calibrator, loss_func):\n",
    "    return calibrator + f\" ({loss_func})\"\n",
    "\n",
    "metric_df.augment(train_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_df['train_method'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_df['image_metric'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shortened_train_method(train_method):\n",
    "    if train_method == 'Uncal (PixelCELoss)':\n",
    "        return 'UC-CE'\n",
    "    elif train_method == 'Uncal (SoftDiceLoss)':\n",
    "        return 'UC-SD'\n",
    "    elif train_method == 'SVLS (PixelCELoss)':\n",
    "        return 'SV-CE'\n",
    "    elif train_method == 'SVLS (SoftDiceLoss)':\n",
    "        return 'SV-SD'\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown train method {train_method}\")\n",
    "    \n",
    "metric_df.augment(shortened_train_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_df['shortened_train_method'] = metric_df['shortened_train_method'].astype('category')\n",
    "metric_df['shortened_train_method'] = metric_df['shortened_train_method'].cat.reorder_categories([\n",
    "    'UC-CE',\n",
    "    'UC-SD',\n",
    "    'SV-CE',\n",
    "    'SV-SD'\n",
    "])\n",
    "metric_df['upsample_cfg'] = metric_df['upsample_cfg'].astype('category')\n",
    "metric_df['upsample_cfg'] = metric_df['upsample_cfg'].cat.reorder_categories([\n",
    "    'bilinear align=True',\n",
    "    'bilinear align=False',\n",
    "    'nearest align=False',\n",
    "])\n",
    "\n",
    "custom_palette = {\n",
    "    'bilinear align=True': 'cornflowerblue',\n",
    "    'bilinear align=False': 'darkblue',\n",
    "    'nearest align=False': \"orangered\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the df for Dice loss\n",
    "dice_df = metric_df[metric_df['image_metric'] == 'Dice Loss']\n",
    "\n",
    "# Create the catplot\n",
    "g = sns.catplot(\n",
    "    data=dice_df,      # Ensure you use the 'data' parameter correctly.\n",
    "    x=\"shortened_train_method\",\n",
    "    y=\"metric_score\",\n",
    "    hue=\"upsample_cfg\",\n",
    "    col=\"experiment_pretrained_seed\",\n",
    "    kind=\"box\",\n",
    "    col_wrap=4,\n",
    "    sharex=False,\n",
    "    height=6,\n",
    "    palette=custom_palette,\n",
    ")\n",
    "\n",
    "# Set the y axis label to 'Dice Loss'\n",
    "g.set_ylabels(\"Dice Loss\")\n",
    "\n",
    "# For each subplot, add a line at y = 0 to show the error.\n",
    "for ax in g.axes.flat:\n",
    "    ax.axhline(0, ls='--', color='red')\n",
    "\n",
    "# Adjust the layout\n",
    "plt.subplots_adjust(top=0.85)\n",
    "g.fig.suptitle('Dice Loss per Method for Different Upsample Methods(Vessel)', fontsize=30)\n",
    "\n",
    "# Add some vertical spcace \n",
    "plt.subplots_adjust(hspace=0.25)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the df for Dice loss\n",
    "ece_df = metric_df[metric_df['image_metric'] == 'Image_ECE']\n",
    "\n",
    "# Create the catplot\n",
    "g = sns.catplot(\n",
    "    data=ece_df,      # Ensure you use the 'data' parameter correctly.\n",
    "    x=\"shortened_train_method\",\n",
    "    y=\"metric_score\",\n",
    "    hue=\"upsample_cfg\",\n",
    "    col=\"experiment_pretrained_seed\",\n",
    "    kind=\"box\",\n",
    "    col_wrap=4,\n",
    "    sharex=False,\n",
    "    height=6,\n",
    "    palette=custom_palette,\n",
    ")\n",
    "\n",
    "# Set the y axis label to 'Image ECE'\n",
    "g.set_ylabels(\"Image ECE\")\n",
    "\n",
    "# For each subplot, add a line at y = 0 to show the error.\n",
    "for ax in g.axes.flat:\n",
    "    ax.axhline(0, ls='--', color='red')\n",
    "\n",
    "# Adjust the layout\n",
    "plt.subplots_adjust(top=0.85)\n",
    "g.fig.suptitle('Image ECE per Method for Different Upsample Methods(Vessel)', fontsize=30)\n",
    "\n",
    "# Add some vertical spcace \n",
    "plt.subplots_adjust(hspace=0.25)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
