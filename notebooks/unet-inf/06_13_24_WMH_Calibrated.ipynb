{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/vbutoi/envs/UniverSegTF/lib/python3.9/site-packages/pydantic/_internal/_fields.py:149: UserWarning: Field \"model_outputs\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/storage/vbutoi/projects')\n",
    "sys.path.append('/storage/vbutoi/libraries')\n",
    "sys.path.append('/storage/vbutoi/projects/ESE')\n",
    "sys.path.append('/storage/vbutoi/projects/UniverSeg')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.set_context(\"talk\")\n",
    "\n",
    "import os \n",
    "os.environ['DATAPATH'] = ':'.join((\n",
    "       '/storage/vbutoi/datasets',\n",
    "))\n",
    "\n",
    "from ese.experiment.analysis.analyze_inf import load_cal_inference_stats\n",
    "# Results loader object does everything\n",
    "from ionpy.analysis import ResultsLoader\n",
    "from pathlib import Path\n",
    "root = Path(\"/storage/vbutoi/scratch/ESE\")\n",
    "rs = ResultsLoader()\n",
    "\n",
    "# For using code without restarting.\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# For using yaml configs.\n",
    "%load_ext yamlmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            require(\n                [\n                    \"notebook/js/codecell\",\n                    \"codemirror/mode/yaml/yaml\"\n                ],\n                function(cc){\n                    cc.CodeCell.options_default.highlight_modes.magic_yaml = {\n                        reg: [\"^%%yaml\"]\n                    }\n                }\n            );\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%yaml results_cfg \n",
    "\n",
    "log:\n",
    "    root: /storage/vbutoi/scratch/ESE/inference\n",
    "    inference_groups: \n",
    "        - '06_12_24_WMH_CalibratedMultiAnno'\n",
    "\n",
    "options:\n",
    "    add_dice_loss_rows: True\n",
    "    drop_nan_metric_rows: True \n",
    "    remove_shared_columns: False\n",
    "    equal_rows_per_cfg_assert: False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished loading inference stats.\n",
      "Log amounts: root                                                                                                log_set                                              \n",
      "/storage/vbutoi/scratch/ESE/inference/06_12_24_WMH_CalibratedMutliAnno/WMH_Individual_ImageBasedTS  20240612_210908-BDSR-88395e62f19e112fc6db8e248df897f2    19769\n",
      "                                                                                                    20240612_210912-EXYJ-1a5de3afe07e626f4564143e45cbc0be    19769\n",
      "                                                                                                    20240612_210916-GDTT-3c52662bd7bdc3c7e6029cea4aeafe7b    19769\n",
      "                                                                                                    20240612_210921-TVPO-99bda1188b2b284de9b2d6d459839bb0    19769\n",
      "                                                                                                    20240612_210924-BGAK-f0b2652eff448c3144d200d20b53c8ac    13259\n",
      "                                                                                                    20240612_210929-ZLEH-b5250b9a3f6658ef4fe595df9c0a5f47    13259\n",
      "                                                                                                    20240612_210933-K0Y5-eabab13255d3e883fef19e72c83967d3    13259\n",
      "                                                                                                    20240612_210937-7X53-4d04a945eb1c8030f182eb47551190ab    13259\n",
      "/storage/vbutoi/scratch/ESE/inference/06_12_24_WMH_CalibratedMutliAnno/WMH_Individual_LocalTS       20240612_210941-4R3T-cb3e8ed80eec48088bd3ddb09029cbc9    19769\n",
      "                                                                                                    20240612_210945-VUWS-82b985a729d7876e2e7bc78297172ddc    19769\n",
      "                                                                                                    20240612_210949-6QVR-42bfa97ff3b1183334be48d179c85adf    19769\n",
      "                                                                                                    20240612_210954-3WJK-b59e9456645aa5f0b6eb162a9d485bf8    19769\n",
      "                                                                                                    20240612_210958-J1GY-082f2ab11651f6cf32f01557c56f7146    13259\n",
      "                                                                                                    20240612_211002-FS3B-a1328c040faccfa9df958882b5737775    13259\n",
      "                                                                                                    20240612_211006-4TC0-7a93191739cc3f1b65e257e93421960d    13259\n",
      "                                                                                                    20240612_211011-YITY-d9d1750e93d8ccb2d73e85f458deafd6    13259\n",
      "/storage/vbutoi/scratch/ESE/inference/06_12_24_WMH_CalibratedMutliAnno/WMH_Individual_Uncalibrated  20240612_210834-JWJX-5dd86d82d6c034a5fbf281e76eea3247    19769\n",
      "                                                                                                    20240612_210839-MQMY-88b05ef21da0eafb1dbc4fa9bba2a408    19769\n",
      "                                                                                                    20240612_210843-FO1S-d528545d31275df9a0c27458eb9515b4    19769\n",
      "                                                                                                    20240612_210847-HWI3-c9310f63ed36fa94acae4f976f925980    19769\n",
      "                                                                                                    20240612_210851-BX3A-3531cd3c372f612b99be3fd34511b6a3    13259\n",
      "                                                                                                    20240612_210855-SGQG-e3935b8f3973e2ae4c083b423df9e6c6    13259\n",
      "                                                                                                    20240612_210859-14Q4-325f66900be2607b24a742d02f849207    13259\n",
      "                                                                                                    20240612_210903-LTND-366f9b8edca28cda24a28a23be44db57    13259\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "inference_df = load_cal_inference_stats(\n",
    "    results_cfg=results_cfg,\n",
    "    load_cached=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the purpose of this experiment, we only care about a few columns in particular:\n",
    "exp_columns = [\n",
    "    \"calibrator\",\n",
    "    \"data_id\",\n",
    "    \"gt_volume\",\n",
    "    \"hard_volume\",\n",
    "    \"soft_volume\",\n",
    "    \"pretrained_seed\", \n",
    "    \"slice_idx\",\n",
    "    \"split\",\n",
    "    \"task\"\n",
    "]\n",
    "# Take these columns of the inference_df, drop other columns.\n",
    "experiment_df = inference_df[exp_columns]\n",
    "# Remove the duplicate rows.\n",
    "experiment_df = experiment_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accumulate the volumes.\n",
    "volume_df = experiment_df.groupby([\"data_id\", \"calibrator\", \"task\", \"pretrained_seed\", \"split\"]).agg(\n",
    "    gt_volume=(\"gt_volume\", \"sum\"),\n",
    "    hard_volume=(\"hard_volume\", \"sum\"),\n",
    "    soft_volume=(\"soft_volume\", \"sum\"),\n",
    ").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute a few metrics that are important for comparison.\n",
    "\n",
    "# Make two new columns, one for the soft volume error and one for the hard volume error.\n",
    "volume_df['soft_volume_error'] = volume_df['soft_volume'] - volume_df['gt_volume']\n",
    "volume_df['hard_volume_error'] = volume_df['hard_volume'] - volume_df['gt_volume']\n",
    "\n",
    "# Make the normalized metric that divides the error by the ground truth volume.\n",
    "volume_df['soft_norm_volume_error'] = volume_df['soft_volume_error'] / volume_df['gt_volume']\n",
    "volume_df['hard_norm_volume_error'] = volume_df['hard_volume_error'] / volume_df['gt_volume']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library Funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_error_df(raw_df, groupby_keys):\n",
    "    # Make a clone of the volume df.\n",
    "    input_df = raw_df.copy()\n",
    "    # Melt the dataframe to have a single column for the error.\n",
    "    error_df = pd.melt(\n",
    "        input_df,\n",
    "        id_vars=groupby_keys,\n",
    "        value_vars=[\"soft_volume_error\", \"hard_volume_error\"],\n",
    "        var_name=\"volume_type\",\n",
    "        value_name=\"error\",\n",
    "    )\n",
    "    # Make some columns that are useful for plotting.\n",
    "    error_df['abs_error'] = error_df['error'].abs()\n",
    "    error_df['log_abs_error'] = error_df['error'].abs().apply(lambda x: np.log(x + 1))\n",
    "    # Return the melted dataframe.\n",
    "    return error_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_volume_types(input_df):\n",
    "    # Make a clone of the input_df\n",
    "    df = input_df.copy()\n",
    "    # Drop all the rows where calibrator != Uncalibrated AND the volume_type is hard_volume_error.\n",
    "    df = df[~((df['calibrator'] != 'Uncalibrated') & (df['volume_type'] == 'hard_volume_error'))]\n",
    "    # Then we augment the volume_type with the calibrator name.\n",
    "    def volume_type(calibrator, volume_type):\n",
    "        if calibrator == \"Uncalibrated\":\n",
    "            return \"Uncalibrated_\" + \"_\".join(volume_type.split(\"_\")[:-1])\n",
    "        else:\n",
    "            return calibrator + \"_soft_volume\"\n",
    "    df['volume_type'] = df.apply(lambda x: volume_type(x['calibrator'], x['volume_type']), axis=1)\n",
    "    # Return the augmented dataframe.\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 1: Looking at one annotator on Amsterdam, let's look at how the volumetric comparison looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"The following 'id_vars' are not present in the DataFrame: ['hard_volumesplit']\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Make some columns that are useful for plotting.\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m raw_melted_error_df \u001b[38;5;241m=\u001b[39m \u001b[43mprepare_error_df\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvolume_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroupby_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcalibrator\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpretrained_seed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgt_volume\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msoft_volume\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhard_volume\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msplit\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtask\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Process the volume types.\u001b[39;00m\n\u001b[1;32m     13\u001b[0m melted_error_df \u001b[38;5;241m=\u001b[39m process_volume_types(raw_melted_error_df)\n",
      "Cell \u001b[0;32mIn[7], line 5\u001b[0m, in \u001b[0;36mprepare_error_df\u001b[0;34m(raw_df, groupby_keys)\u001b[0m\n\u001b[1;32m      3\u001b[0m input_df \u001b[38;5;241m=\u001b[39m raw_df\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Melt the dataframe to have a single column for the error.\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m error_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmelt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mid_vars\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroupby_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue_vars\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msoft_volume_error\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhard_volume_error\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvar_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvolume_type\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43merror\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Make some columns that are useful for plotting.\u001b[39;00m\n\u001b[1;32m     13\u001b[0m error_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mabs_error\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m error_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mabs()\n",
      "File \u001b[0;32m~/envs/UniverSegTF/lib/python3.9/site-packages/pandas/core/reshape/melt.py:77\u001b[0m, in \u001b[0;36mmelt\u001b[0;34m(frame, id_vars, value_vars, var_name, value_name, col_level, ignore_index)\u001b[0m\n\u001b[1;32m     75\u001b[0m         missing \u001b[38;5;241m=\u001b[39m Index(com\u001b[38;5;241m.\u001b[39mflatten(id_vars))\u001b[38;5;241m.\u001b[39mdifference(cols)\n\u001b[1;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m missing\u001b[38;5;241m.\u001b[39mempty:\n\u001b[0;32m---> 77\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\n\u001b[1;32m     78\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe following \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid_vars\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m are not present \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     79\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124min the DataFrame: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(missing)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     80\u001b[0m             )\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     82\u001b[0m     id_vars \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mKeyError\u001b[0m: \"The following 'id_vars' are not present in the DataFrame: ['hard_volumesplit']\""
     ]
    }
   ],
   "source": [
    "# Make some columns that are useful for plotting.\n",
    "raw_melted_error_df = prepare_error_df(volume_df, groupby_keys=[\n",
    "    \"calibrator\", \n",
    "    \"data_id\", \n",
    "    \"pretrained_seed\", \n",
    "    \"gt_volume\", \n",
    "    \"soft_volume\", \n",
    "    \"hard_volume\",\n",
    "    \"split\",\n",
    "    \"task\", \n",
    "])\n",
    "# Process the volume types.\n",
    "melted_error_df = process_volume_types(raw_melted_error_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, we look at how we perform with standard difference on the Amsterdam hospital."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_1_df = melted_error_df.select(task='Amsterdam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.catplot(\n",
    "    exp_1_df,\n",
    "    x=\"data_id\",\n",
    "    y=\"error\",\n",
    "    hue=\"volume_type\",\n",
    "    col=\"split\",\n",
    "    aspect=3,\n",
    "    height=8,\n",
    "    sharey=False,\n",
    ")\n",
    "# For each subplot make a line at y = 0 to show the error.\n",
    "for ax in g.axes.flat:\n",
    "    ax.axhline(0, ls='--', color='red')\n",
    "\n",
    "# Adjust the layout\n",
    "plt.subplots_adjust(top=0.85)\n",
    "g.fig.suptitle('Soft/Hard Volumetric Error', fontsize=30)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.catplot(\n",
    "    exp_1_df,\n",
    "    x=\"data_id\",\n",
    "    y=\"log_abs_error\",\n",
    "    hue=\"volume_type\",\n",
    "    col=\"split\",\n",
    "    aspect=3,\n",
    "    height=8,\n",
    "    sharey=False,\n",
    ")\n",
    "# For each subplot make a line at y = 0 to show the error.\n",
    "for ax in g.axes.flat:\n",
    "    ax.axhline(0, ls='--', color='red')\n",
    "\n",
    "# Adjust the layout\n",
    "plt.subplots_adjust(top=0.85)\n",
    "g.fig.suptitle('Absolute Soft/Hard Volumetric Log Error', fontsize=30)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's look at the same thing but this time also for Singapore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_2_df = melted_error_df.select(task='Singapore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.catplot(\n",
    "    exp_2_df,\n",
    "    x=\"data_id\",\n",
    "    y=\"error\",\n",
    "    hue=\"volume_type\",\n",
    "    col=\"split\",\n",
    "    aspect=3,\n",
    "    height=8,\n",
    "    sharey=False,\n",
    ")\n",
    "# For each subplot make a line at y = 0 to show the error.\n",
    "for ax in g.axes.flat:\n",
    "    ax.axhline(0, ls='--', color='red')\n",
    "\n",
    "# Adjust the layout\n",
    "plt.subplots_adjust(top=0.85)\n",
    "g.fig.suptitle('Singapore Soft/Hard Volumetric Error', fontsize=30)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.catplot(\n",
    "    exp_2_df,\n",
    "    x=\"data_id\",\n",
    "    y=\"log_abs_error\",\n",
    "    hue=\"volume_type\",\n",
    "    col=\"split\",\n",
    "    aspect=3,\n",
    "    height=8,\n",
    "    sharey=False,\n",
    ")\n",
    "# For each subplot make a line at y = 0 to show the error.\n",
    "for ax in g.axes.flat:\n",
    "    ax.axhline(0, ls='--', color='red')\n",
    "\n",
    "# Adjust the layout\n",
    "plt.subplots_adjust(top=0.85)\n",
    "g.fig.suptitle('Singapore Absolute Soft/Hard Volumetric Log Error', fontsize=30)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
