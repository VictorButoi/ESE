{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/storage/vbutoi/projects')\n",
    "sys.path.append('/storage/vbutoi/libraries')\n",
    "sys.path.append('/storage/vbutoi/projects/ESE')\n",
    "sys.path.append('/storage/vbutoi/projects/UniverSeg')\n",
    "\n",
    "from ionpy.analysis import ResultsLoader\n",
    "from ese.experiment.experiment import CalibrationExperiment\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "import os \n",
    "os.environ['DATAPATH'] = ':'.join((\n",
    "       '/storage/vbutoi/datasets',\n",
    "))\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '1' \n",
    "\n",
    "%load_ext yamlmagic\n",
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results loader object does everything\n",
    "rs = ResultsLoader()\n",
    "root = \"/storage/vbutoi/scratch/ESE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = f\"{root}/WMH_aug_runs\"\n",
    "\n",
    "dfc = rs.load_configs(\n",
    "    path,\n",
    "    properties=False,\n",
    ")\n",
    "\n",
    "df = rs.load_metrics(dfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_exp = rs.get_experiment(\n",
    "    df=df,\n",
    "    exp_class=CalibrationExperiment,\n",
    "    metric=\"val-dice_score\",\n",
    "    checkpoint=\"max-val-dice_score\",\n",
    "    device=\"cuda\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_exp.vis_loss_curves(height=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%yaml dataset_cfg \n",
    "\n",
    "_class: ese.experiment.datasets.WMH\n",
    "annotator: observer_o12\n",
    "axis: 0\n",
    "split: cal \n",
    "num_slices: 1\n",
    "slicing: midslice \n",
    "task: Amsterdam \n",
    "version: 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ionpy.experiment.util import absolute_import\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataset_cls = absolute_import(dataset_cfg.pop(\"_class\"))\n",
    "WMH_Dataset = dataset_cls(**dataset_cfg)\n",
    "wmh_dataloader = DataLoader(WMH_Dataset, batch_size=1, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import einops\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from ese.experiment.metrics.grouping.portion_loss import get_perpix_boundary_dist, get_perpix_group_size\n",
    "from ese.experiment.metrics.grouping.regions import get_label_region_sizes\n",
    "from ionpy.util.torchutils import to_device\n",
    "\n",
    "def get_dataset_perf(\n",
    "        exp, \n",
    "        dataloader, \n",
    "        ):\n",
    "    items = []\n",
    "    with torch.no_grad():\n",
    "        for subj_idx, batch in tqdm(enumerate(dataloader), total=len(dataloader)):\n",
    "            # Get your image label pair and define some regions.\n",
    "            x, y = to_device(batch, exp.device)\n",
    "            # Reshape to a good size\n",
    "            x = einops.rearrange(x, \"b c h w -> (b c) 1 h w\")\n",
    "            y = einops.rearrange(y, \"b c h w -> (b c) 1 h w\")\n",
    "            # Get the prediction\n",
    "            yhat = exp.model(x)  \n",
    "            # Extract predictions\n",
    "            soft_pred = torch.sigmoid(yhat)\n",
    "            # Get the hard prediction\n",
    "            hard_pred = (soft_pred > 0.5).float()\n",
    "            # Squeeze our tensors\n",
    "            x = x.squeeze().cpu().numpy()\n",
    "            y = y.squeeze().cpu().numpy()\n",
    "            soft_pred = soft_pred.squeeze().cpu().numpy()\n",
    "            hard_pred = hard_pred.squeeze().cpu().numpy()\n",
    "            # Get some performance metrics\n",
    "            accuracy_map = (hard_pred==y).astype(np.float32)\n",
    "            perf_per_dist = get_perpix_boundary_dist(y_pred=hard_pred)\n",
    "            perf_per_regsize = get_perpix_group_size(y_pred=hard_pred)\n",
    "            # Get region sizes\n",
    "            gt_lab_region_sizes = get_label_region_sizes(label_map=y)\n",
    "            pred_lab_region_sizes = get_label_region_sizes(label_map=hard_pred)\n",
    "            # Wrap it in an item\n",
    "            items.append({\n",
    "                \"subject_id\": subj_idx,\n",
    "                \"image\": x,\n",
    "                \"label_map\": y,\n",
    "                \"conf_map\": soft_pred,\n",
    "                \"pred_map\": hard_pred,\n",
    "                \"perpix_accuracies\": accuracy_map,\n",
    "                \"perf_per_dist\": perf_per_dist,\n",
    "                \"perf_per_regsize\": perf_per_regsize,\n",
    "                \"gt_lab_region_sizes\": gt_lab_region_sizes,\n",
    "                \"pred_lab_region_sizes\": pred_lab_region_sizes\n",
    "            })\n",
    "    return items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_perf is a dict where each item is the subj id\n",
    "# with the y, ypred, yloss, ydice\n",
    "predictions_list = get_dataset_perf(\n",
    "    exp=best_exp, \n",
    "    dataloader=wmh_dataloader\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ese.experiment.analysis.inference import get_pixelinfo_df\n",
    "\n",
    "pixel_preds_df = get_pixelinfo_df(predictions_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pixel_preds_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution of Pixel Accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data=pixel_preds_df, y=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution of Pixel Accuracies vs Label "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data=pixel_preds_df, x=\"label\", y=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Distribution Predicted Region Sizes Over Images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ese.experiment.analysis.err_diagrams import viz_region_size_distribution\n",
    "\n",
    "viz_region_size_distribution(\n",
    "    data_points=predictions_list,\n",
    "    hue=\"label_map_type\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ese.experiment.analysis.err_diagrams import viz_region_size_distribution\n",
    "\n",
    "viz_region_size_distribution(\n",
    "    data_points=predictions_list,\n",
    "    hue=\"label_map_type\",\n",
    "    row_split=\"label\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution of Pixel Accuracies vs Distance to a Boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(data=pixel_preds_df, x=\"dist_to_boundary\", y=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_labels = pixel_preds_df['label'].unique()\n",
    "color_dict = {\n",
    "    0.0: \"blue\",\n",
    "    1.0: \"orange\"\n",
    "}\n",
    "for l_idx, lab in enumerate(unique_labels):\n",
    "    sns.lineplot(\n",
    "        data=pixel_preds_df[pixel_preds_df['label']==lab], \n",
    "        x=\"dist_to_boundary\", \n",
    "        y=\"accuracy\",\n",
    "        color=sns.color_palette(\"tab10\")[l_idx]\n",
    "        )\n",
    "    plt.title(f\"Label {lab}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution Pixel Accuracies vs Predicted Size of Region (that pixel is in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(data=pixel_preds_df, x=\"group_size\", y=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_labels = pixel_preds_df['label'].unique()\n",
    "for l_idx, lab in enumerate(unique_labels):\n",
    "    sns.lineplot(\n",
    "        data=pixel_preds_df[pixel_preds_df['label']==lab],\n",
    "        x=\"group_size\", \n",
    "        y=\"accuracy\",\n",
    "        color=sns.color_palette(\"tab10\")[l_idx]\n",
    "        )\n",
    "    plt.title(f\"Label {lab}\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UniverSegTF",
   "language": "python",
   "name": "universegtf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
