{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/storage/vbutoi/projects')\n",
    "sys.path.append('/storage/vbutoi/libraries')\n",
    "sys.path.append('/storage/vbutoi/projects/ESE')\n",
    "sys.path.append('/storage/vbutoi/projects/UniverSeg')\n",
    "\n",
    "from ionpy.analysis import ResultsLoader\n",
    "from ese.experiment.experiment import CalibrationExperiment\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "import os \n",
    "os.environ['DATAPATH'] = ':'.join((\n",
    "       '/storage/vbutoi/datasets',\n",
    "))\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '1' \n",
    "\n",
    "%load_ext yamlmagic\n",
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results loader object does everything\n",
    "rs = ResultsLoader()\n",
    "root = \"/storage/vbutoi/scratch/ESE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = f\"{root}/WMH_aug_runs\"\n",
    "\n",
    "dfc = rs.load_configs(\n",
    "    path,\n",
    "    properties=False,\n",
    ")\n",
    "\n",
    "df = rs.load_metrics(dfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_exp = rs.get_experiment(\n",
    "    df=df,\n",
    "    exp_class=CalibrationExperiment,\n",
    "    metric=\"val-dice_score\",\n",
    "    checkpoint=\"max-val-dice_score\",\n",
    "    device=\"cuda\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_exp.vis_loss_curves(height=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%yaml dataset_cfg \n",
    "\n",
    "_class: ese.experiment.datasets.WMH\n",
    "annotator: observer_o12\n",
    "axis: 0\n",
    "split: cal \n",
    "num_slices: 1\n",
    "slicing: midslice \n",
    "task: Amsterdam \n",
    "version: 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ionpy.experiment.util import absolute_import\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataset_cls = absolute_import(dataset_cfg.pop(\"_class\"))\n",
    "WMH_Dataset = dataset_cls(**dataset_cfg)\n",
    "wmh_dataloader = DataLoader(WMH_Dataset, batch_size=1, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import einops\n",
    "from tqdm.notebook import tqdm\n",
    "from ese.experiment.metrics.grouping.portion_loss import accuracy_vs_boundary_dist, accuracy_vs_instancesize, accuracy_vs_label\n",
    "from ese.experiment.metrics.grouping.regions import get_label_region_sizes\n",
    "from ionpy.util.torchutils import to_device\n",
    "\n",
    "def get_dataset_perf(\n",
    "        exp, \n",
    "        dataloader, \n",
    "        ):\n",
    "\n",
    "    items = []\n",
    "    with torch.no_grad():\n",
    "        for subj_idx, batch in tqdm(enumerate(dataloader), total=len(dataloader)):\n",
    "            # Get your image label pair and define some regions.\n",
    "            x, y = to_device(batch, exp.device)\n",
    "            # Reshape to a good size\n",
    "            x = einops.rearrange(x, \"b c h w -> (b c) 1 h w\")\n",
    "            y = einops.rearrange(y, \"b c h w -> (b c) 1 h w\")\n",
    "            # Get the prediction\n",
    "            yhat = exp.model(x)  \n",
    "            # Extract predictions\n",
    "            soft_pred = torch.sigmoid(yhat)\n",
    "            # Get the hard prediction\n",
    "            hard_pred = (soft_pred > 0.5).float()\n",
    "            # Squeeze our tensors\n",
    "            x = x.squeeze().cpu().numpy()\n",
    "            y = y.squeeze().cpu().numpy()\n",
    "            soft_pred = soft_pred.squeeze().cpu().numpy()\n",
    "            hard_pred = hard_pred.squeeze().cpu().numpy()\n",
    "            # Get some performance metrics\n",
    "            perf_per_label = accuracy_vs_label(\n",
    "                y_pred=hard_pred, \n",
    "                y_true=y\n",
    "                )\n",
    "            perf_per_dist = accuracy_vs_boundary_dist(\n",
    "                y_pred=hard_pred,\n",
    "                y_true=y\n",
    "                )\n",
    "            perf_per_regsize = accuracy_vs_instancesize(\n",
    "                y_pred=hard_pred, \n",
    "                y_true=y\n",
    "                )\n",
    "            gt_lab_region_sizes = get_label_region_sizes(\n",
    "                label_map=y\n",
    "                )\n",
    "            pred_lab_region_sizes = get_label_region_sizes(\n",
    "                label_map=hard_pred\n",
    "                )\n",
    "            # Wrap it in an item\n",
    "            items.append({\n",
    "                \"subject_id\": subj_idx,\n",
    "                \"image\": x,\n",
    "                \"label_map\": y,\n",
    "                \"conf_map\": soft_pred,\n",
    "                \"pred_map\": hard_pred,\n",
    "                \"perf_per_dist\": perf_per_dist,\n",
    "                \"per_per_label\": perf_per_label,\n",
    "                \"perf_per_regsize\": perf_per_regsize,\n",
    "                \"gt_lab_region_sizes\": gt_lab_region_sizes,\n",
    "                \"pred_lab_region_sizes\": pred_lab_region_sizes\n",
    "            })\n",
    "    return items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_perf is a dict where each item is the subj id\n",
    "# with the y, ypred, yloss, ydice\n",
    "predictions_list = get_dataset_perf(\n",
    "    exp=best_exp, \n",
    "    dataloader=wmh_dataloader\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution Pixel Accuracies Over Images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ese.experiment.analysis.err_diagrams import viz_accuracy_distribution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# viz_accuracy_distribution(\n",
    "#     datapoints=predictions_list,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Distribution Predicted Region Sizes Over Images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ese.experiment.analysis.err_diagrams import viz_region_size_distribution\n",
    "\n",
    "viz_region_size_distribution(\n",
    "    data_points=predictions_list,\n",
    "    hue=\"label_map_type\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ese.experiment.analysis.err_diagrams import viz_region_size_distribution\n",
    "\n",
    "viz_region_size_distribution(\n",
    "    data_points=predictions_list,\n",
    "    hue=\"label_map_type\",\n",
    "    row_split=\"label\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution Pixel Accuracies vs Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_accuracy_distribution(\n",
    "    data_points=predictions_list,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution Pixel Accuracies vs Distance to a Boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_accuracy_distribution(\n",
    "    data_points=predictions_list,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution Pixel Accuracies vs Predicted Size of Region (that pixel is in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_accuracy_distribution(\n",
    "    data_points=predictions_list,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UniverSegTF",
   "language": "python",
   "name": "universegtf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
