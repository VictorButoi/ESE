{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage/vbutoi/projects/ionpy/pandas/register.py:47: UserWarning: registration of accessor <class 'ionpy.pandas.register.register_series_method.<locals>.inner.<locals>.AccessorMethod'> under name 'fillNA' for type <class 'pandas.core.series.Series'> is overriding a preexisting attribute with the same name.\n",
      "  register_series_accessor(method.__name__)(AccessorMethod)\n",
      "/storage/vbutoi/projects/ionpy/pandas/register.py:47: UserWarning: registration of accessor <class 'ionpy.pandas.register.register_series_method.<locals>.inner.<locals>.AccessorMethod'> under name 'isNA' for type <class 'pandas.core.series.Series'> is overriding a preexisting attribute with the same name.\n",
      "  register_series_accessor(method.__name__)(AccessorMethod)\n",
      "/storage/vbutoi/projects/ionpy/pandas/register.py:47: UserWarning: registration of accessor <class 'ionpy.pandas.register.register_series_method.<locals>.inner.<locals>.AccessorMethod'> under name 'notNA' for type <class 'pandas.core.series.Series'> is overriding a preexisting attribute with the same name.\n",
      "  register_series_accessor(method.__name__)(AccessorMethod)\n",
      "/storage/vbutoi/projects/ionpy/pandas/register.py:47: UserWarning: registration of accessor <class 'ionpy.pandas.register.register_series_method.<locals>.inner.<locals>.AccessorMethod'> under name 'is_constant' for type <class 'pandas.core.series.Series'> is overriding a preexisting attribute with the same name.\n",
      "  register_series_accessor(method.__name__)(AccessorMethod)\n",
      "/storage/vbutoi/projects/ionpy/pandas/register.py:26: UserWarning: registration of accessor <class 'ionpy.pandas.register.register_dataframe_method.<locals>.inner.<locals>.AccessorMethod'> under name 'drop_constant' for type <class 'pandas.core.frame.DataFrame'> is overriding a preexisting attribute with the same name.\n",
      "  register_dataframe_accessor(method.__name__)(AccessorMethod)\n",
      "/storage/vbutoi/projects/ionpy/pandas/register.py:26: UserWarning: registration of accessor <class 'ionpy.pandas.register.register_dataframe_method.<locals>.inner.<locals>.AccessorMethod'> under name 'constants' for type <class 'pandas.core.frame.DataFrame'> is overriding a preexisting attribute with the same name.\n",
      "  register_dataframe_accessor(method.__name__)(AccessorMethod)\n",
      "/storage/vbutoi/projects/ionpy/pandas/register.py:26: UserWarning: registration of accessor <class 'ionpy.pandas.register.register_dataframe_method.<locals>.inner.<locals>.AccessorMethod'> under name 'to_categories' for type <class 'pandas.core.frame.DataFrame'> is overriding a preexisting attribute with the same name.\n",
      "  register_dataframe_accessor(method.__name__)(AccessorMethod)\n",
      "/storage/vbutoi/projects/ionpy/pandas/register.py:26: UserWarning: registration of accessor <class 'ionpy.pandas.register.register_dataframe_method.<locals>.inner.<locals>.AccessorMethod'> under name 'select' for type <class 'pandas.core.frame.DataFrame'> is overriding a preexisting attribute with the same name.\n",
      "  register_dataframe_accessor(method.__name__)(AccessorMethod)\n",
      "/storage/vbutoi/projects/ionpy/pandas/register.py:26: UserWarning: registration of accessor <class 'ionpy.pandas.register.register_dataframe_method.<locals>.inner.<locals>.AccessorMethod'> under name 'augment' for type <class 'pandas.core.frame.DataFrame'> is overriding a preexisting attribute with the same name.\n",
      "  register_dataframe_accessor(method.__name__)(AccessorMethod)\n",
      "/storage/vbutoi/projects/ionpy/pandas/register.py:26: UserWarning: registration of accessor <class 'ionpy.pandas.register.register_dataframe_method.<locals>.inner.<locals>.AccessorMethod'> under name 'broadcast' for type <class 'pandas.core.frame.DataFrame'> is overriding a preexisting attribute with the same name.\n",
      "  register_dataframe_accessor(method.__name__)(AccessorMethod)\n",
      "/storage/vbutoi/projects/ionpy/pandas/register.py:26: UserWarning: registration of accessor <class 'ionpy.pandas.register.register_dataframe_method.<locals>.inner.<locals>.AccessorMethod'> under name 'unique_per_col' for type <class 'pandas.core.frame.DataFrame'> is overriding a preexisting attribute with the same name.\n",
      "  register_dataframe_accessor(method.__name__)(AccessorMethod)\n",
      "/storage/vbutoi/projects/ionpy/pandas/register.py:26: UserWarning: registration of accessor <class 'ionpy.pandas.register.register_dataframe_method.<locals>.inner.<locals>.AccessorMethod'> under name 'constants_subset' for type <class 'pandas.core.frame.DataFrame'> is overriding a preexisting attribute with the same name.\n",
      "  register_dataframe_accessor(method.__name__)(AccessorMethod)\n",
      "/storage/vbutoi/projects/ionpy/pandas/register.py:26: UserWarning: registration of accessor <class 'ionpy.pandas.register.register_dataframe_method.<locals>.inner.<locals>.AccessorMethod'> under name 'smooth' for type <class 'pandas.core.frame.DataFrame'> is overriding a preexisting attribute with the same name.\n",
      "  register_dataframe_accessor(method.__name__)(AccessorMethod)\n",
      "/storage/vbutoi/projects/ionpy/pandas/register.py:26: UserWarning: registration of accessor <class 'ionpy.pandas.register.register_dataframe_method.<locals>.inner.<locals>.AccessorMethod'> under name 'augment_from_attrs' for type <class 'pandas.core.frame.DataFrame'> is overriding a preexisting attribute with the same name.\n",
      "  register_dataframe_accessor(method.__name__)(AccessorMethod)\n",
      "/storage/vbutoi/projects/ionpy/pandas/unix.py:12: UserWarning: registration of accessor <class 'ionpy.pandas.unix.UnixAccessor'> under name 'unix' for type <class 'pandas.core.series.Series'> is overriding a preexisting attribute with the same name.\n",
      "  class UnixAccessor:\n",
      "/local/vbutoi/envs/UniverSegTF/lib/python3.9/site-packages/pydantic/_internal/_fields.py:149: UserWarning: Field \"model_outputs\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/storage/vbutoi/projects')\n",
    "sys.path.append('/storage/vbutoi/libraries')\n",
    "sys.path.append('/storage/vbutoi/projects/ESE')\n",
    "sys.path.append('/storage/vbutoi/projects/UniverSeg')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.set_context(\"talk\")\n",
    "\n",
    "import os \n",
    "os.environ['DATAPATH'] = ':'.join((\n",
    "       '/storage/vbutoi/datasets',\n",
    "))\n",
    "\n",
    "from ese.experiment.analysis.analyze_inf import load_cal_inference_stats\n",
    "# Results loader object does everything\n",
    "from ionpy.analysis import ResultsLoader\n",
    "from pathlib import Path\n",
    "root = Path(\"/storage/vbutoi/scratch/ESE\")\n",
    "rs = ResultsLoader()\n",
    "\n",
    "# For using code without restarting.\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# For using yaml configs.\n",
    "%load_ext yamlmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            require(\n                [\n                    \"notebook/js/codecell\",\n                    \"codemirror/mode/yaml/yaml\"\n                ],\n                function(cc){\n                    cc.CodeCell.options_default.highlight_modes.magic_yaml = {\n                        reg: [\"^%%yaml\"]\n                    }\n                }\n            );\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%yaml results_cfg \n",
    "\n",
    "log:\n",
    "    root: /storage/vbutoi/scratch/ESE/inference\n",
    "    inference_groups: \n",
    "        - '05_27_24_SW_Pairwise'\n",
    "\n",
    "options:\n",
    "    add_dice_loss_rows: True\n",
    "    drop_nan_metric_rows: True \n",
    "    remove_shared_columns: False\n",
    "    equal_rows_per_cfg_assert: False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading submitit directory: /storage/vbutoi/scratch/ESE/inference/05_27_24_SW_Pairwise/SpineWeb_Ensemble_Uncalibrated/submitit\n",
      "Dropping (datapoint, metric) pairs with NaN metric score. Dropped from 180 -> 180 rows.\n",
      "Finished loading inference stats.\n",
      "Log amounts: log.root                                                                                   log_set                                              \n",
      "/storage/vbutoi/scratch/ESE/inference/05_27_24_SW_Pairwise/SpineWeb_Ensemble_Uncalibrated  20240527_142731-AAOU-5c830be441acb83898d6c552a0ee3207    195\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "inference_df = load_cal_inference_stats(\n",
    "    results_cfg=results_cfg,\n",
    "    load_cached=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# # Load all of the preds so we can compare them\n",
    "# loaded_pred_dict = {}\n",
    "# for pred_hash_id in inference_df['pred_hash'].unique():\n",
    "#     # Get the rows corresponding to the hash\n",
    "#     pred_rows = inference_df[inference_df['pred_hash'] == pred_hash_id]\n",
    "#     # Get the log set corresponding to the hash\n",
    "#     log_root = pred_rows['root'].unique()[0]\n",
    "#     log_set = pred_rows['log_set'].unique()[0]\n",
    "#     # Load the prediction pickle\n",
    "#     with open(f'{log_root}/{log_set}/preds/{pred_hash_id}.pkl', 'rb') as f:\n",
    "#         loaded_pred_dict[pred_hash_id] = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'subj_id_1': 'Subject04', 'subj_id_2': 'Subject13', 'sup_id_1': 0, 'sup_id_2': 0, 'dice_1': 0.5622857213020325, 'dice_2': 0.6280752420425415, 'ece_1': 0.0026665482073439666, 'ece_2': 0.002120967234077455, 'mean_dice': 0.595180481672287, 'mean_ece': 0.0023937577207107106, 'gt_volume_diff': -47, 'gt_volume_quot': 0.8588588588588588, 'soft_volume_diff': -180.789794921875, 'soft_volume_quot': 0.7379549291607969, 'hard_volume_diff': -137, 'hard_volume_quot': 0.7472324723247232}\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 54\u001b[0m\n\u001b[1;32m     35\u001b[0m pair_record \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubj_id_1\u001b[39m\u001b[38;5;124m'\u001b[39m: subj_id_1,\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubj_id_2\u001b[39m\u001b[38;5;124m'\u001b[39m: subj_id_2,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhard_volume_quot\u001b[39m\u001b[38;5;124m'\u001b[39m: hard_volume_quot,\n\u001b[1;32m     52\u001b[0m }\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28mprint\u001b[39m(pair_record)\n\u001b[0;32m---> 54\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# Add the record to the list\u001b[39;00m\n\u001b[1;32m     56\u001b[0m pw_error_list\u001b[38;5;241m.\u001b[39mappend(pair_record)\n",
      "\u001b[0;31mValueError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "unique_subj_ids = inference_df['data_id'].unique()\n",
    "\n",
    "pw_error_list = []\n",
    "# Iterate through all the pair-wise comparisons.\n",
    "for (subj_id_1, subj_id_2) in list(itertools.combinations(unique_subj_ids, 2)):\n",
    "    if subj_id_1 != subj_id_2:\n",
    "        # Get the dfs corresponding to these two ids:\n",
    "        data_id_1_df = inference_df[inference_df['data_id'] == subj_id_1]\n",
    "        data_id_2_df = inference_df[inference_df['data_id'] == subj_id_2]\n",
    "        # Get the unique support indices.\n",
    "        unique_sup_ids_1 = data_id_1_df['sup_idx'].unique()\n",
    "        unique_sup_ids_2 = data_id_2_df['sup_idx'].unique()\n",
    "        for (sup_id_1, sup_id_2) in list(itertools.product(unique_sup_ids_1, unique_sup_ids_2)):\n",
    "            # Get the dfs corresponding to these sup ids\n",
    "            sup_id_1_df = data_id_1_df[data_id_1_df['sup_idx'] == sup_id_1].reset_index(drop=True)\n",
    "            sup_id_2_df = data_id_2_df[data_id_2_df['sup_idx'] == sup_id_2].reset_index(drop=True)\n",
    "            # Now we can get differences in volume by looking at the differences.\n",
    "            gt_volume_diff = sup_id_2_df['gt_volume'].values[0] - sup_id_1_df['gt_volume'].values[0]\n",
    "            gt_volume_quot = sup_id_2_df['gt_volume'].values[0] / sup_id_1_df['gt_volume'].values[0]\n",
    "            # Get the soft pred vol diff\n",
    "            soft_volume_diff = sup_id_2_df['soft_volume'].values[0] - sup_id_1_df['soft_volume'].values[0]\n",
    "            soft_volume_quot = sup_id_2_df['soft_volume'].values[0] / sup_id_1_df['soft_volume'].values[0]\n",
    "            # Get the hard pred vol diff\n",
    "            hard_volume_diff = sup_id_2_df['hard_volume'].values[0] - sup_id_1_df['hard_volume'].values[0]\n",
    "            hard_volume_quot = sup_id_2_df['hard_volume'].values[0] / sup_id_1_df['hard_volume'].values[0]\n",
    "            # Get the Dice information from each of the dataframes\n",
    "            dice_1 = sup_id_1_df[sup_id_1_df['image_metric'] == 'Dice']['metric_score'].iloc[0]\n",
    "            dice_2 = sup_id_2_df[sup_id_2_df['image_metric'] == 'Dice']['metric_score'].iloc[0]\n",
    "            # Get the calibration information from each of the dataframes\n",
    "            ece_1 = sup_id_1_df[sup_id_1_df['image_metric'] == 'Image_ECE']['metric_score'].iloc[0]\n",
    "            ece_2 = sup_id_2_df[sup_id_2_df['image_metric'] == 'Image_ECE']['metric_score'].iloc[0]\n",
    "            # Place all of these into a record\n",
    "            pair_record = {\n",
    "                'subj_id_1': subj_id_1,\n",
    "                'subj_id_2': subj_id_2,\n",
    "                'sup_id_1': sup_id_1,\n",
    "                'sup_id_2': sup_id_2,\n",
    "                'dice_1': dice_1,\n",
    "                'dice_2': dice_2,\n",
    "                'ece_1': ece_1,\n",
    "                'ece_2': ece_2,\n",
    "                'mean_dice': np.mean([dice_1, dice_2]),\n",
    "                'mean_ece': np.mean([ece_1, ece_2]),\n",
    "                'gt_volume_diff': gt_volume_diff,\n",
    "                'gt_volume_quot': gt_volume_quot,\n",
    "                'soft_volume_diff': soft_volume_diff,\n",
    "                'soft_volume_quot': soft_volume_quot,\n",
    "                'hard_volume_diff': hard_volume_diff,\n",
    "                'hard_volume_quot': hard_volume_quot,\n",
    "            }\n",
    "            # Add the record to the list\n",
    "            pw_error_list.append(pair_record)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
