{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/storage/vbutoi/projects')\n",
    "sys.path.append('/storage/vbutoi/libraries')\n",
    "sys.path.append('/storage/vbutoi/projects/ESE')\n",
    "sys.path.append('/storage/vbutoi/projects/UniverSeg')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.set_context(\"talk\")\n",
    "\n",
    "import os \n",
    "os.environ['DATAPATH'] = ':'.join((\n",
    "       '/storage/vbutoi/datasets',\n",
    "))\n",
    "\n",
    "from ese.experiment.analysis.analyze_inf import load_cal_inference_stats\n",
    "# Results loader object does everything\n",
    "from ionpy.analysis import ResultsLoader\n",
    "from pathlib import Path\n",
    "root = Path(\"/storage/vbutoi/scratch/ESE\")\n",
    "rs = ResultsLoader()\n",
    "\n",
    "# For using code without restarting.\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# For using yaml configs.\n",
    "%load_ext yamlmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%yaml results_cfg \n",
    "\n",
    "log:\n",
    "    root: /storage/vbutoi/scratch/ESE/inference\n",
    "    inference_groups: \n",
    "        - '05_27_24_SW_SoftVols'\n",
    "\n",
    "options:\n",
    "    add_dice_loss_rows: True\n",
    "    drop_nan_metric_rows: True \n",
    "    remove_shared_columns: False\n",
    "    equal_rows_per_cfg_assert: False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_df = load_cal_inference_stats(\n",
    "    results_cfg=results_cfg,\n",
    "    load_cached=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to compare how Dice relates to ECE, this means we need to pivot our dataframe\n",
    "inference_df_piv = inference_df.pivot(index=['exp_name', 'data_id', 'sup_idx', 'pred_hash'], columns='image_metric', values='metric_score').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(\n",
    "    data=inference_df_piv,\n",
    "    x='data_id',\n",
    "    y='Dice',\n",
    "    kind='boxen',\n",
    "    errorbar='sd',\n",
    "    height=5,\n",
    "    aspect=3,\n",
    "    legend_out=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(\n",
    "    data=inference_df_piv,\n",
    "    x='data_id',\n",
    "    y='Image_ECE',\n",
    "    kind='boxen',\n",
    "    errorbar='sd',\n",
    "    height=5,\n",
    "    aspect=3,\n",
    "    legend_out=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_df_piv.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melt the dataframe\n",
    "inference_df_melted = pd.melt(inference_df, id_vars=['data_id', 'sup_idx', 'pred_hash'], value_vars=['gt_volume', 'soft_volume', 'hard_volume'], var_name='Volume_Type', value_name='Volume')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(\n",
    "    data=inference_df_melted,\n",
    "    x='data_id',\n",
    "    y='Volume',\n",
    "    hue='Volume_Type',\n",
    "    kind='boxen',\n",
    "    errorbar='sd',\n",
    "    height=5,\n",
    "    aspect=3,\n",
    "    legend_out=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melt the dataframe\n",
    "inference_df_piv_melted = pd.melt(inference_df_piv, id_vars=['data_id', 'sup_idx', 'pred_hash', 'Image_ECE'], value_vars=['SoftVolumeError', 'HardVolumeError'], var_name='Pred_Type', value_name='Measurement_Error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(\n",
    "    data=inference_df_piv_melted,\n",
    "    x='Image_ECE',\n",
    "    y='Measurement_Error',\n",
    "    hue='Pred_Type',\n",
    "    col='data_id',\n",
    "    height=5,\n",
    "    alpha=0.8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot KDE plots of the measurement error for the different kinds of pred_type\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "sns.kdeplot(\n",
    "    data=inference_df_piv_melted,\n",
    "    x='Measurement_Error',\n",
    "    hue='Pred_Type',\n",
    "    common_norm=False,\n",
    "    fill=True,\n",
    "    alpha=0.5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the prediction hashes of the preds per subject with the lowest ECE\n",
    "min_ece_preds = inference_df_piv.groupby(['data_id', 'sup_idx'])['Image_ECE'].idxmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_ece_preds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
