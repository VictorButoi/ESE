{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/storage/vbutoi/projects')\n",
    "sys.path.append('/storage/vbutoi/libraries')\n",
    "sys.path.append('/storage/vbutoi/projects/ESE')\n",
    "sys.path.append('/storage/vbutoi/projects/UniverSeg')\n",
    "\n",
    "from ionpy.analysis import ResultsLoader\n",
    "from ese.experiment.experiment import CalibrationExperiment\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "import os \n",
    "os.environ['DATAPATH'] = ':'.join((\n",
    "       '/storage/vbutoi/datasets',\n",
    "))\n",
    "\n",
    "# Results loader object does everything\n",
    "rs = ResultsLoader()\n",
    "root = \"/storage/vbutoi/scratch/ESE\"\n",
    "\n",
    "%load_ext yamlmagic\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = f\"{root}/WMH_aug_runs\"\n",
    "\n",
    "dfc = rs.load_configs(\n",
    "    path,\n",
    "    properties=False,\n",
    ")\n",
    "\n",
    "df = rs.load_metrics(dfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '1'\n",
    "\n",
    "best_exp = rs.get_best_experiment(\n",
    "    df=df,\n",
    "    exp_class=CalibrationExperiment,\n",
    "    device=\"cuda\"\n",
    ")\n",
    "best_exp.build_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_exp.vis_loss_curves(height=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import einops\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from ionpy.util.torchutils import to_device\n",
    "from ese.experiment.metrics.grouping.portion_loss import get_perpix_boundary_dist, get_perpix_group_size\n",
    "from ese.experiment.metrics.grouping.regions import get_label_region_sizes\n",
    "\n",
    "def get_dataset_perf(\n",
    "        exp, \n",
    "        split=\"val\",\n",
    "        ):\n",
    "    dataloader = exp.val_dl if split==\"val\" else exp.train_dl\n",
    "    items = []\n",
    "    with torch.no_grad():\n",
    "        for subj_idx, batch in tqdm(enumerate(dataloader), total=len(dataloader)):\n",
    "            # Get your image label pair and define some regions.\n",
    "            x, y = to_device(batch, exp.device)\n",
    "            # Reshape to a good size\n",
    "            x = einops.rearrange(x, \"b c h w -> (b c) 1 h w\")\n",
    "            y = einops.rearrange(y, \"b c h w -> (b c) 1 h w\")\n",
    "            # Get the prediction\n",
    "            yhat = exp.model(x)  \n",
    "            # Extract predictions\n",
    "            soft_pred = torch.sigmoid(yhat)\n",
    "            # Get the hard prediction\n",
    "            hard_pred = (soft_pred > 0.5).float()\n",
    "            # Squeeze our tensors\n",
    "            x = x.squeeze().cpu().numpy()\n",
    "            y = y.squeeze().cpu().numpy()\n",
    "            hard_pred = hard_pred.squeeze().cpu().numpy()\n",
    "            # For the soft prediction, make sure to flip the confidences below 0.5\n",
    "            soft_pred[soft_pred < 0.5] = 1 - soft_pred[soft_pred < 0.5]\n",
    "            soft_pred = soft_pred.squeeze().cpu().numpy()\n",
    "            # Get some performance metrics\n",
    "            accuracy_map = (hard_pred==y).astype(np.float32)\n",
    "            perf_per_dist = get_perpix_boundary_dist(y_pred=hard_pred)\n",
    "            perf_per_regsize = get_perpix_group_size(y_pred=hard_pred)\n",
    "            # Get region sizes\n",
    "            gt_lab_region_sizes = get_label_region_sizes(label_map=y)\n",
    "            pred_lab_region_sizes = get_label_region_sizes(label_map=hard_pred)\n",
    "            # Wrap it in an item\n",
    "            items.append({\n",
    "                \"subject_id\": subj_idx,\n",
    "                \"image\": x,\n",
    "                \"label_map\": y,\n",
    "                \"conf_map\": soft_pred,\n",
    "                \"pred_map\": hard_pred,\n",
    "                \"perpix_accuracies\": accuracy_map,\n",
    "                \"perf_per_dist\": perf_per_dist,\n",
    "                \"perf_per_regsize\": perf_per_regsize,\n",
    "                \"gt_lab_region_sizes\": gt_lab_region_sizes,\n",
    "                \"pred_lab_region_sizes\": pred_lab_region_sizes\n",
    "            })\n",
    "    return items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_perf is a dict where each item is the subj id\n",
    "# with the y, ypred, yloss, ydice\n",
    "predictions_list = get_dataset_perf(\n",
    "    exp=best_exp, \n",
    "    split=\"val\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ese.experiment.analysis.inference import get_pixelinfo_df\n",
    "\n",
    "pixel_preds_df = get_pixelinfo_df(predictions_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution of Pixel Confidences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))  # Adjust the width and height as needed\n",
    "g = sns.kdeplot(data=pixel_preds_df, x=\"conf\", clip=(0, 1))\n",
    "g.set_title(\"Distribution of Pixel Confidences\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution of Pixel Accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 10))  # Adjust the width and height as needed\n",
    "g = sns.barplot(data=pixel_preds_df, y=\"accuracy\")\n",
    "g.set_title(\"Average Pixel-wise Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_preds_df['conf'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution of Pixel Confidences vs Label "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))  # Adjust the width and height as needed\n",
    "g = sns.kdeplot(data=pixel_preds_df, x=\"conf\", hue=\"label\", common_norm=False, clip=(0.5, 1))\n",
    "g.set_title(\"Distribution of Pixel Confidences\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution of Pixel Accuracies vs Label "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))  # Adjust the width and height as needed\n",
    "g = sns.barplot(data=pixel_preds_df, x=\"label\", y=\"accuracy\")\n",
    "g.set_title(\"Average Pixel-wise Accuracy per Label\")\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Distribution Predicted Region Sizes Over Images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ese.experiment.analysis.err_diagrams import viz_region_size_distribution\n",
    "\n",
    "viz_region_size_distribution(\n",
    "    data_points=predictions_list,\n",
    "    hue=\"label_map_type\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ese.experiment.analysis.err_diagrams import viz_region_size_distribution\n",
    "\n",
    "viz_region_size_distribution(\n",
    "    data_points=predictions_list,\n",
    "    hue=\"label_map_type\",\n",
    "    row_split=\"label\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution of Pixel Accuracies vs Distance to a Boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(data=pixel_preds_df, x=\"dist_to_boundary\", y=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_labels = pixel_preds_df['label'].unique()\n",
    "color_dict = {\n",
    "    0.0: \"blue\",\n",
    "    1.0: \"orange\"\n",
    "}\n",
    "for l_idx, lab in enumerate(unique_labels):\n",
    "    sns.lineplot(\n",
    "        data=pixel_preds_df[pixel_preds_df['label']==lab], \n",
    "        x=\"dist_to_boundary\", \n",
    "        y=\"accuracy\",\n",
    "        color=sns.color_palette(\"tab10\")[l_idx]\n",
    "        )\n",
    "    plt.title(f\"Label {lab}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution Pixel Accuracies vs Predicted Size of Region (that pixel is in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(data=pixel_preds_df, x=\"group_size\", y=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_labels = pixel_preds_df['label'].unique()\n",
    "for l_idx, lab in enumerate(unique_labels):\n",
    "    sns.lineplot(\n",
    "        data=pixel_preds_df[pixel_preds_df['label']==lab],\n",
    "        x=\"group_size\", \n",
    "        y=\"accuracy\",\n",
    "        color=sns.color_palette(\"tab10\")[l_idx]\n",
    "        )\n",
    "    plt.title(f\"Label {lab}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Super Weird Plot Time: Distance to Boundary vs Parent Size, hue accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_labels = pixel_preds_df['label'].unique()\n",
    "for l_idx, lab in enumerate(unique_labels):\n",
    "    sns.scatterplot(\n",
    "        data=pixel_preds_df[pixel_preds_df['label']==lab],\n",
    "        x=\"group_size\", \n",
    "        y=\"dist_to_boundary\",\n",
    "        hue=\"accuracy\"\n",
    "        )\n",
    "    plt.title(f\"Label {lab}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From ToySquare, we want to look at dist to boundary vs (confidence) and (accuracy) on the same plot.j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_labels = pixel_preds_df['label'].unique()\n",
    "color_dict = {\n",
    "    0.0: \"blue\",\n",
    "    1.0: \"orange\"\n",
    "}\n",
    "for l_idx, lab in enumerate(unique_labels):\n",
    "    plt.figure(figsize=(15, 10))  # Adjust the width and height as needed\n",
    "    label_df = pixel_preds_df[pixel_preds_df['label']==lab]\n",
    "    label_df_melted = label_df.melt(id_vars='dist_to_boundary', value_vars=['conf', 'accuracy'], var_name='y', value_name='value')\n",
    "    sns.lineplot(\n",
    "        data=label_df_melted,\n",
    "        x=\"dist_to_boundary\", \n",
    "        y=\"value\",\n",
    "        hue='y'\n",
    "        )\n",
    "    plt.title(f\"Label {lab}\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UniverSegTF",
   "language": "python",
   "name": "universegtf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
