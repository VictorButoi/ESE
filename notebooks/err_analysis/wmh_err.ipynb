{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/storage/vbutoi/projects')\n",
    "sys.path.append('/storage/vbutoi/libraries')\n",
    "sys.path.append('/storage/vbutoi/projects/ESE')\n",
    "sys.path.append('/storage/vbutoi/projects/UniverSeg')\n",
    "\n",
    "import seaborn as sns\n",
    "from ionpy.analysis import ResultsLoader\n",
    "from ese.experiment.experiment.ese_exp import CalibrationExperiment\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "import os \n",
    "os.environ['DATAPATH'] = ':'.join((\n",
    "       '/storage/vbutoi/datasets',\n",
    "))\n",
    "\n",
    "# Results loader object does everything\n",
    "rs = ResultsLoader()\n",
    "root = \"/storage/vbutoi/scratch/ESE/\"\n",
    "\n",
    "%load_ext yamlmagic\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ese.experiment.analysis.inference import load_cal_inference_stats\n",
    "\n",
    "inference_path = f\"{root}/inference/11_13_23_WMH_SUME_Analysis\"\n",
    "\n",
    "cal_inference_info = load_cal_inference_stats(\n",
    "    log_dir=inference_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_inference_info.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = cal_inference_info['metadata']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will take in a dictionary of pixel meters and a metadata dataframe\n",
    "# from which to select the log_set corresponding to particular attributes, then \n",
    "# we index into the dictionary to get the corresponding pixel meters.\n",
    "def select_pixel_dict(pixel_meter_logdict, metadata, kwargs):\n",
    "    # Select the metadata\n",
    "    metadata = metadata.select(**kwargs)\n",
    "    # Get the log set\n",
    "    assert len(metadata) == 1, \"More than one log set found.\"\n",
    "    log_set = metadata['log_set'].iloc[0]\n",
    "    # Return the pixel dict\n",
    "    return pixel_meter_logdict[log_set]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pixel-level Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ese.experiment.analysis.err_diagrams import viz_accuracy_vs_confidence\n",
    "\n",
    "# for split in [\"train\", \"val\", \"cal\"]: \n",
    "#     split_preds_dict = select_pixel_dict(\n",
    "#         pixel_meter_logdict=cal_inference_info[\"pixel_info_dicts\"], \n",
    "#         metadata=cal_inference_info[\"metadata\"],\n",
    "#         kwargs={\"dataset.split\": split}\n",
    "#     ) \n",
    "#     # Plot the accuracy vs confidence for this split.\n",
    "#     viz_accuracy_vs_confidence(\n",
    "#         split_preds_dict,\n",
    "#         title=f\"WMH Confidence vs Accuracy per (Bin and Predicted Label, {split} split)\",\n",
    "#         x=\"pred_label\",\n",
    "#         col=\"bin_num\",\n",
    "#         kind=\"bar\",\n",
    "#         add_avg=False,\n",
    "#         facet_kws={'sharey': False, 'sharex': False}\n",
    "#         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ese.experiment.analysis.err_diagrams import viz_accuracy_vs_confidence\n",
    "\n",
    "for split in [\"cal\"]: \n",
    "    split_preds_dict = select_pixel_dict(\n",
    "        pixel_meter_logdict=cal_inference_info[\"pixel_info_dicts\"], \n",
    "        metadata=cal_inference_info[\"metadata\"],\n",
    "        kwargs={\"dataset.split\": split}\n",
    "    ) \n",
    "    # Plot the accuracy vs confidence for this split.\n",
    "    viz_accuracy_vs_confidence(\n",
    "        split_preds_dict,\n",
    "        title=f\"WMH Confidence vs Accuracy per (Bin and Num Neighbors, split: {split})\",\n",
    "        x=\"num_neighbors\",\n",
    "        col=\"bin_num\",\n",
    "        kind=\"bar\",\n",
    "        add_avg=False,\n",
    "        add_proportion=True,\n",
    "        facet_kws={'sharey': False, 'sharex': False},\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image-level Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_info_df = cal_inference_info['image_info_df']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ese.experiment.analysis.utils import reorder_splits\n",
    "\n",
    "unique_image_df = reorder_splits(image_info_df.drop_constant())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now using seaborn's FacetGrid to create the KDE plots for the 'accuracy' column for each 'split'.\n",
    "g = sns.FacetGrid(unique_image_df, hue=\"qual_metric\", row=\"qual_metric\", sharex=True, sharey=False)\n",
    "g = g.map(sns.kdeplot, \"qual_score\", fill=True)\n",
    "\n",
    "# Adjusting the layout\n",
    "g.fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_image_df[\"cal_metric_type\"] = unique_image_df[\"cal_metric\"].apply(lambda x: x.split(\" \")[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ese.experiment.analysis.err_diagrams import viz_cal_metric_corr\n",
    "\n",
    "# viz_cal_metric_corr(\n",
    "#     unique_image_df,\n",
    "#     title=\"WMH Calibration Metric NEGATED Correlation\",\n",
    "#     negate=True,\n",
    "#     height=7\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ese.experiment.analysis.err_diagrams import viz_cal_metric_corr\n",
    "\n",
    "viz_cal_metric_corr(\n",
    "    unique_image_df,\n",
    "    title=\"WMH Calibration Metric NEGATED Correlation\",\n",
    "    row=\"cal_metric_type\",\n",
    "    negate=True,\n",
    "    height=7\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UniverSegTF",
   "language": "python",
   "name": "universegtf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
