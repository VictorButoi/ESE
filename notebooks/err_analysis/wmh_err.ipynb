{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/storage/vbutoi/projects')\n",
    "sys.path.append('/storage/vbutoi/libraries')\n",
    "sys.path.append('/storage/vbutoi/projects/ESE')\n",
    "sys.path.append('/storage/vbutoi/projects/UniverSeg')\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "import os \n",
    "os.environ['DATAPATH'] = ':'.join((\n",
    "       '/storage/vbutoi/datasets',\n",
    "))\n",
    "\n",
    "# Results loader object does everything\n",
    "from ionpy.analysis import ResultsLoader\n",
    "from pathlib import Path\n",
    "root = Path(\"/storage/vbutoi/scratch/ESE\")\n",
    "rs = ResultsLoader()\n",
    "\n",
    "# For using code without restarting.\n",
    "%load_ext autoreload\n",
    "%autoreload \n",
    "# For using yaml configs.\n",
    "%load_ext yamlmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ese.experiment.analysis.inference import load_cal_inference_stats\n",
    "\n",
    "inference_path = root / \"inference/12_17_23_WMH_GlobalAnalysis\"\n",
    "dataset = \"WMH\"\n",
    "\n",
    "cal_inference_info = load_cal_inference_stats(\n",
    "    log_dir=inference_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['pixel_info_dicts', 'image_info_df', 'metadata'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cal_inference_info.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = cal_inference_info['metadata']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_name = list(cal_inference_info[\"pixel_info_dicts\"].keys())[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Barplot Pixel-level Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ese.experiment.analysis.err_diagrams import viz_accuracy_vs_confidence\n",
    "# from ese.experiment.analysis.utils import select_pixel_dict\n",
    "\n",
    "# for split in [\"cal\"]: \n",
    "#     split_preds_dict = select_pixel_dict(\n",
    "#         pixel_meter_logdict=cal_inference_info[\"pixel_info_dicts\"], \n",
    "#         metadata=cal_inference_info[\"metadata\"],\n",
    "#         kwargs={\"dataset.split\": split}\n",
    "#     ) \n",
    "#     # Plot the accuracy vs confidence for this split.\n",
    "#     viz_accuracy_vs_confidence(\n",
    "#         split_preds_dict,\n",
    "#         title=f\"{dataset} Confidence vs Accuracy per (Bin and Predicted Label, {split} split)\",\n",
    "#         x=\"pred_label\",\n",
    "#         col=\"bin_num\",\n",
    "#         kind=\"bar\",\n",
    "#         facet_kws={'sharey': True, 'sharex': False}\n",
    "#         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ese.experiment.analysis.err_diagrams import viz_accuracy_vs_confidence\n",
    "\n",
    "# # Plot the accuracy vs confidence for this split.\n",
    "# viz_accuracy_vs_confidence(\n",
    "#     cal_inference_info[\"pixel_info_dicts\"][record_name],\n",
    "#     title=f\"{dataset} Confidence vs Accuracy per (Bin and Num Neighbors)\",\n",
    "#     x=\"num_neighbors\",\n",
    "#     col=\"bin_num\",\n",
    "#     relative_props=True,\n",
    "#     facet_kws={'sharey': True, 'sharex': False},\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ese.experiment.analysis.err_diagrams import viz_accuracy_vs_confidence\n",
    "\n",
    "# for label in [0, 1]: \n",
    "#     # Plot the accuracy vs confidence for this split.\n",
    "#     viz_accuracy_vs_confidence(\n",
    "#         cal_inference_info[\"pixel_info_dicts\"][record_name],\n",
    "#         title=f\"{dataset} Confidence vs Accuracy per (Bin and Num Neighbors, label: {label})\",\n",
    "#         x=\"num_neighbors\",\n",
    "#         col=\"bin_num\",\n",
    "#         relative_props=False,\n",
    "#         add_edge_props=True,\n",
    "#         label=label,\n",
    "#         facet_kws={'sharey': True, 'sharex': False},\n",
    "#         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at the metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for GlobalBinStats\nkwargs\n  unexpected keyword argument: 'ignore_index' (type=type_error)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mese\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperiment\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ece_loss \n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mece_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpixel_preds_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcal_inference_info\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpixel_info_dicts\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrecord_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/envs/UniverSegTF/lib/python3.9/site-packages/pydantic/decorator.py:40\u001b[0m, in \u001b[0;36mpydantic.decorator.validate_arguments.validate.wrapper_function\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/envs/UniverSegTF/lib/python3.9/site-packages/pydantic/decorator.py:134\u001b[0m, in \u001b[0;36mpydantic.decorator.ValidatedFunction.call\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/envs/UniverSegTF/lib/python3.9/site-packages/pydantic/decorator.py:206\u001b[0m, in \u001b[0;36mpydantic.decorator.ValidatedFunction.execute\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/storage/vbutoi/projects/ESE/ese/experiment/metrics/ece.py:44\u001b[0m, in \u001b[0;36mece_loss\u001b[0;34m(y_pred, y_true, pixel_preds_dict, num_bins, square_diff, conf_interval, stats_info_dict, from_logits, return_dict, ignore_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# Get the statistics either from images or pixel meter dict.\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_global:\n\u001b[0;32m---> 44\u001b[0m     cal_info \u001b[38;5;241m=\u001b[39m \u001b[43mglobal_bin_stats\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpixel_preds_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m        \u001b[49m\u001b[43msquare_diff\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msquare_diff\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweighted\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_index\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m: \n\u001b[1;32m     51\u001b[0m     cal_info \u001b[38;5;241m=\u001b[39m bin_stats(\n\u001b[1;32m     52\u001b[0m         y_pred\u001b[38;5;241m=\u001b[39my_pred,\n\u001b[1;32m     53\u001b[0m         y_true\u001b[38;5;241m=\u001b[39my_true,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     59\u001b[0m         ignore_index\u001b[38;5;241m=\u001b[39mignore_index\n\u001b[1;32m     60\u001b[0m     )\n",
      "File \u001b[0;32m~/envs/UniverSegTF/lib/python3.9/site-packages/pydantic/decorator.py:40\u001b[0m, in \u001b[0;36mpydantic.decorator.validate_arguments.validate.wrapper_function\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/envs/UniverSegTF/lib/python3.9/site-packages/pydantic/decorator.py:133\u001b[0m, in \u001b[0;36mpydantic.decorator.ValidatedFunction.call\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/envs/UniverSegTF/lib/python3.9/site-packages/pydantic/decorator.py:130\u001b[0m, in \u001b[0;36mpydantic.decorator.ValidatedFunction.init_model_instance\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/envs/UniverSegTF/lib/python3.9/site-packages/pydantic/main.py:341\u001b[0m, in \u001b[0;36mpydantic.main.BaseModel.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValidationError\u001b[0m: 1 validation error for GlobalBinStats\nkwargs\n  unexpected keyword argument: 'ignore_index' (type=type_error)"
     ]
    }
   ],
   "source": [
    "from ese.experiment.metrics import ece_loss \n",
    "\n",
    "print(ece_loss(pixel_preds_dict=cal_inference_info[\"pixel_info_dicts\"][record_name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image-level Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_info_df = cal_inference_info['image_info_df']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ese.experiment.analysis.utils import reorder_splits\n",
    "\n",
    "unique_image_df = reorder_splits(image_info_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ese.experiment.analysis.err_diagrams import viz_quality_metric_distributions\n",
    "\n",
    "viz_quality_metric_distributions(\n",
    "    unique_image_df, \n",
    "    title=f\"{dataset} Quality Metric Distributions\",\n",
    "    col_wrap=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ese.experiment.analysis.err_diagrams import viz_calibration_metric_distributions\n",
    "\n",
    "viz_calibration_metric_distributions(\n",
    "    unique_image_df, \n",
    "    title=f\"{dataset} Calibration Metric Score Distributions\",\n",
    "    col_wrap=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ese.experiment.analysis.err_diagrams import viz_cal_metric_corr\n",
    "\n",
    "viz_cal_metric_corr(\n",
    "    unique_image_df,\n",
    "    title=f\"{dataset} Calibration Metric Score Correlation\",\n",
    "    heatmap_row=\"qual_metric\",\n",
    "    heatmap_col=\"cal_metric\",\n",
    "    col=\"cal_metric_type\",\n",
    "    height=7\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_qm_sorted = unique_image_df.sort_values(by=[\"qual_metric\", \"cal_metric_type\"])\n",
    "g = sns.relplot(\n",
    "    df_qm_sorted, \n",
    "    x=\"cal_m_score\", \n",
    "    y=\"qual_score\", \n",
    "    col=\"cal_metric\", \n",
    "    row=\"qual_metric\", \n",
    "    height=3.5, \n",
    "    aspect=1,\n",
    "    facet_kws={'sharey': False, 'sharex': False}\n",
    "    )\n",
    "# g.set(xlim=(0, 1), ylim=(0, 1))\n",
    "g.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g = sns.relplot(\n",
    "#     df_qm_sorted, \n",
    "#     x=\"log_true_lab_amount\", \n",
    "#     y=\"qual_score\", \n",
    "#     hue=\"qual_metric\", \n",
    "#     col=\"qual_metric\", \n",
    "#     row=\"label\",\n",
    "#     height=4, \n",
    "#     aspect=1,\n",
    "#     facet_kws={'sharey': False, 'sharex': False}\n",
    "#     )\n",
    "# #g.set(ylim=(0, 1))\n",
    "# g.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g = sns.relplot(\n",
    "#     df_qm_sorted, \n",
    "#     x=\"log_true_lab_amount\", \n",
    "#     y=\"cal_m_score\", \n",
    "#     hue=\"cal_metric\", \n",
    "#     col=\"cal_metric\", \n",
    "#     row=\"label\",\n",
    "#     height=4,\n",
    "#     aspect=1,\n",
    "#     facet_kws={'sharey': False, 'sharex': False}\n",
    "#     )\n",
    "# g.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UniverSegTF",
   "language": "python",
   "name": "universegtf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
