{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "sys.path.append(\"/storage/vbutoi/projects\")\n",
    "sys.path.append(\"/storage/vbutoi/libraries\")\n",
    "sys.path.append(\"/storage/vbutoi/projects/voxel\")\n",
    "sys.path.append(\"/storage/vbutoi/projects/ESE\")\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "%load_ext yamlmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%yaml drive_thunder_cfg\n",
    "\n",
    "seed: 42\n",
    "version: 0.2\n",
    "resample: (1, 1, 2)\n",
    "root: \"/storage/vbutoi/datasets/ISLES\"\n",
    "dst_folder: \"thunder_isles\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ionpy.util import Config\n",
    "\n",
    "gen_cfg = Config(drive_thunder_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import pathlib\n",
    "# import voxel as vx\n",
    "# from tqdm import tqdm\n",
    "\n",
    "#  # Get the dictionary version of the config.\n",
    "# config = gen_cfg.to_dict()\n",
    "\n",
    "# # Append version to our paths\n",
    "# version = str(config[\"version\"])\n",
    "# splits_seed = 42\n",
    "# splits_ratio = (0.6, 0.2, 0.1, 0.1)\n",
    "\n",
    "# # Append version to our paths\n",
    "# proc_root = pathlib.Path(config[\"root\"]) / 'raw_data' / 'organized_data'\n",
    "# dst_dir = pathlib.Path(config[\"root\"]) / config[\"dst_folder\"] / version\n",
    "\n",
    "# isl_raw_root = proc_root / 'raw_data'\n",
    "# isl_prc_root = proc_root / 'derivatives'\n",
    "\n",
    "# ## Iterate through each datacenter, axis  and build it as a task\n",
    "# # with ThunderDB.open(str(dst_dir), \"c\") as db:\n",
    "    \n",
    "# # Iterate through the examples.\n",
    "# # Key track of the ids\n",
    "# subjects = [] \n",
    "\n",
    "# vol_list = []   \n",
    "# seg_list = []\n",
    "\n",
    "# subj_list = list(os.listdir(isl_raw_root))\n",
    "# for subj_name in tqdm(os.listdir(isl_raw_root), total=len(subj_list)):\n",
    "\n",
    "#     # Paths to the image and segmentation\n",
    "#     img_dir = isl_raw_root / subj_name / 'ses-02' / f'{subj_name}_ses-02_dwi.nii.gz' \n",
    "#     seg_dir = isl_prc_root / subj_name / 'ses-02' / f'{subj_name}_ses-02_lesion-msk.nii.gz'\n",
    "\n",
    "#     # Load the image and segmentation.\n",
    "#     vol = vx.load_volume(img_dir)\n",
    "#     seg = vx.load_volume(seg_dir)\n",
    "\n",
    "#     # append the volume and segmentation\n",
    "#     vol_list.append(vol)\n",
    "#     seg_list.append(seg)\n",
    "\n",
    "#     # Crop the image to non-zero values\n",
    "#     # cropped_img_vol_obj = vol.crop_to_nonzero()\n",
    "#     # cropped_seg_vol_obj = seg.resample_like(cropped_img_vol_obj, mode='nearest')\n",
    "\n",
    "#     # # Get the spacing \n",
    "#     # resized_img_vol_obj = cropped_img_vol_obj.resize((1, 1, 2))\n",
    "#     # resized_seg_vol_obj = cropped_seg_vol_obj.resize((1, 1, 2))\n",
    "\n",
    "#     # # Get out the tensors as numpy arrays\n",
    "#     # img_vol_arr = resized_img_vol_obj.tensor.numpy().squeeze()\n",
    "#     # seg_vol_arr = resized_seg_vol_obj.tensor.numpy().squeeze()\n",
    "\n",
    "#     # # Normalize the img_vol_arr to be between 0 and 1\n",
    "#     # img_vol_arr = (img_vol_arr - img_vol_arr.min()) / (img_vol_arr.max() - img_vol_arr.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.stack([v.geometry.slice_spacing for v in vol_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is_ = torch.cat([v.geometry.in_plane_spacing for v in vol_list])\n",
    "# ss_ = torch.stack([v.geometry.slice_spacing for v in vol_list])\n",
    "\n",
    "# print('is:', is_.mean(), is_.median())\n",
    "# print('ss:', ss_.mean(), ss_.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ese.datasets.utils import thunderify_ISLES\n",
    "\n",
    "thunderify_ISLES(gen_cfg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UniverSegTF",
   "language": "python",
   "name": "universegtf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
