{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Imports\n",
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "sys.path.append('/storage/vbutoi/projects')\n",
    "sys.path.append('/storage/vbutoi/libraries')\n",
    "sys.path.append('/storage/vbutoi/projects/ESE')\n",
    "sys.path.append('/storage/vbutoi/projects/UniverSegDev')\n",
    "\n",
    "# Regular schema dictates that we put DATAPATH\n",
    "os.environ['DATAPATH'] = ':'.join((\n",
    "       '/storage/vbutoi/datasets',\n",
    "))\n",
    "os.environ['WANDB_NOTEBOOK_NAME'] = 'calibrate.ipynb'\n",
    "\n",
    "from ionpy.util import Config\n",
    "\n",
    "# Setup direcrtories\n",
    "root = Path(\"/storage/vbutoi/scratch/ESE\")\n",
    "scratch_root = Path(\"/storage/vbutoi/scratch/ESE\")\n",
    "code_root = Path(\"/storage/vbutoi/projects/ESE\")\n",
    "\n",
    "%load_ext yamlmagic\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%yaml default_cfg\n",
    "\n",
    "# We can change the lr and weight decay mid run.\n",
    "# Usually we are going to load the old optimizer state.\n",
    "# optim:\n",
    "#   weight_decay: 0.0 \n",
    "#   lr: 1.0e-4\n",
    "\n",
    "# Optionally we can change the loss function.\n",
    "# loss_func: \n",
    "#   _class: '?'\n",
    "#   from_logits: True\n",
    "#   batch_reduction: 'mean' \n",
    "\n",
    "train:\n",
    "  epochs: '?' # How much longer to train for.\n",
    "  load_chkpt: '?' # Which model do we load\n",
    "  pretrained_dir: '?' # Which runs are we restarting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%yaml callbacks_cfg\n",
    "\n",
    "callbacks:\n",
    "  step:\n",
    "    - ese.callbacks.ShowPredictions\n",
    "  epoch:\n",
    "    - ese.callbacks.WandbLogger\n",
    "    - ionpy.callbacks.ETA\n",
    "    - ionpy.callbacks.JobProgress\n",
    "    - ionpy.callbacks.TerminateOnNaN\n",
    "    - ionpy.callbacks.PrintLogged\n",
    "    - ionpy.callbacks.ModelCheckpoint:\n",
    "        monitor: dice_score\n",
    "        phase: val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%yaml experiment_cfg \n",
    "\n",
    "name: \"OCTA_FULLRES_LTS_LongRuns_RESTARTED\" # We will treat this as a NEW EXPERIMENT.\n",
    "\n",
    "train:\n",
    "    epochs: 100\n",
    "    load_chkpt: 'last'\n",
    "    pretrained_dir: \n",
    "        - \"/storage/vbutoi/scratch/ESE/training/08_07_24_OCTA_FULLRES_SoftDice\"\n",
    "        - \"/storage/vbutoi/scratch/ESE/training/08_07_24_OCTA_FULLRES_CrossEntropy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ese.analysis.analysis_utils.submit_utils import get_ese_restart_configs\n",
    "\n",
    "# Get the configs for the different runs.\n",
    "base_cfg = Config(default_cfg).update([callbacks_cfg])\n",
    "\n",
    "restart_cfgs = get_ese_restart_configs(\n",
    "    exp_cfg=experiment_cfg,\n",
    "    base_cfg=base_cfg\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(restart_cfgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ese.experiment import run_ese_exp, submit_ese_exps, CalibrationExperiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ####### Run individual jobs\n",
    "# run_ese_exp(\n",
    "#     config=restart_cfgs[0], \n",
    "#     experiment_class=CalibrationExperiment,\n",
    "#     run_name='debug',\n",
    "#     show_examples=True,\n",
    "#     track_wandb=False,\n",
    "#     gpu='0',\n",
    "#     # gpu='4',\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Run Batch Jobs\n",
    "submit_ese_exps(\n",
    "    config_list=cal_cfgs,\n",
    "    experiment_class=PostHocExperiment,\n",
    "    track_wandb=True,\n",
    "    available_gpus=['0', '1', '2', '3']\n",
    "    # available_gpus=['4', '5', '6', '7']\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UniverSegTF",
   "language": "python",
   "name": "universegtf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
