{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/storage/vbutoi/projects')\n",
    "sys.path.append('/storage/vbutoi/libraries')\n",
    "sys.path.append('/storage/vbutoi/projects/ESE')\n",
    "sys.path.append('/storage/vbutoi/projects/UniverSeg')\n",
    "import torch\n",
    "torch.set_printoptions(linewidth=200)\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "import os \n",
    "os.environ['DATAPATH'] = ':'.join((\n",
    "       '/storage/vbutoi/datasets',\n",
    "))\n",
    "\n",
    "# Results loader object does everything\n",
    "from ionpy.analysis import ResultsLoader\n",
    "from pathlib import Path\n",
    "root = Path(\"/storage/vbutoi/scratch/ESE\")\n",
    "rs = ResultsLoader()\n",
    "\n",
    "# For using code without restarting.\n",
    "%load_ext autoreload\n",
    "%autoreload \n",
    "# For using yaml configs.\n",
    "%load_ext yamlmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_exp_name = \"training/01_03_24_WMH_Ensemble\"\n",
    "\n",
    "dfc = rs.load_configs(\n",
    "    root / training_exp_name,\n",
    "    properties=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%yaml inference_config\n",
    "\n",
    "log:\n",
    "    root: '?'\n",
    "    log_interval: 5\n",
    "    log_image_stats: True \n",
    "    log_pixel_stats: False \n",
    "    ignore_index: 0 \n",
    "    show_examples: False \n",
    "\n",
    "experiment:\n",
    "    seed: 42\n",
    "\n",
    "data:\n",
    "    split: cal \n",
    "    slicing: dense_full \n",
    "    input_type: volume \n",
    "    preload: '?' \n",
    "\n",
    "dataloader:\n",
    "    batch_size: 1 \n",
    "    num_workers: 0\n",
    "    pin_memory: True \n",
    "\n",
    "calibration:\n",
    "    conf_interval_start: 0.5\n",
    "    conf_interval_end: 1.0\n",
    "    num_bins: 10\n",
    "    neighborhood_width: 3\n",
    "    square_diff: False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%yaml model_cfg\n",
    "\n",
    "model:\n",
    "    pretrained_exp_root : '?' \n",
    "    checkpoint: '?' \n",
    "    ensemble: '?' \n",
    "    ensemble_pre_softmax: '?'\n",
    "    ensemble_combine_fn: '?' \n",
    "    pretrained_select_metric: \"val-dice_score\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%yaml metrics_cfg \n",
    "\n",
    "qual_metrics:\n",
    "    # - Edge_ECE:\n",
    "    #     _fn: ese.experiment.metrics.ece.edge_ece_loss\n",
    "    #     metric_type: calibration\n",
    "    # - ECW_ECE:\n",
    "    #     _fn: ese.experiment.metrics.ece.ecw_ece_loss\n",
    "    #     metric_type: calibration\n",
    "    - Dice:\n",
    "        _fn: ionpy.metrics.segmentation.dice_score\n",
    "        from_logits: True\n",
    "        batch_reduction: 'mean' \n",
    "        ignore_empty_labels: True \n",
    "        ignore_index: 0 # Ignore background class when reporting.\n",
    "        metric_type: quality\n",
    "\n",
    "\n",
    "# cal_metrics:\n",
    "#     - ECE:\n",
    "#         _fn: ese.experiment.metrics.ece.ece_loss\n",
    "#     - CW_ECE:\n",
    "#         _fn: ese.experiment.metrics.ece.cw_ece_loss\n",
    "#     - ELM:\n",
    "#         _fn: ese.experiment.metrics.elm.elm_loss\n",
    "#     - CW_ELM:\n",
    "#         _fn: ese.experiment.metrics.elm.cw_elm_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ionpy.util import dict_product, Config\n",
    "from ionpy.util.config import check_missing\n",
    "from ese.scripts.utils import gather_exp_paths\n",
    "\n",
    "# Get the training experiment paths.\n",
    "##################################################\n",
    "### For ensembles, define the root dir.\n",
    "# ensemble_root = \"/storage/vbutoi/scratch/ESE/training/01_08_24_WMH_Ensemble\"\n",
    "# pretrained_exp_paths = gather_exp_paths(ensemble_root)\n",
    "# checkpoint = \"max-val-dice_score\" \n",
    "\n",
    "ensemble_root = \"/storage/vbutoi/scratch/ESE/calibration/01_07_24_WMH_EnsembleLTS\"\n",
    "pretrained_exp_paths = gather_exp_paths(ensemble_root)\n",
    "checkpoint = \"min-val-ece_loss\"\n",
    "\n",
    "# Make presets for the different runnning configurations.\n",
    "##################################################\n",
    "# If you want to run inference on individual networks, use this.\n",
    "individual_network_args = {\n",
    "    'model.pretrained_exp_root': pretrained_exp_paths, # Note this is a list of train exp paths.\n",
    "    'model.ensemble': [False],\n",
    "    'model.ensemble_pre_softmax': [None],\n",
    "    'model.ensemble_combine_fn': [None],\n",
    "}\n",
    "\n",
    "# If you want to run inference on ensembles, use this.\n",
    "ensemble_network_args = {\n",
    "    'model.pretrained_exp_root': [ensemble_root],\n",
    "    'model.ensemble': [True],\n",
    "    'model.ensemble_pre_softmax': [True, False],\n",
    "    'model.ensemble_combine_fn': ['mean', 'max'],\n",
    "}\n",
    "\n",
    "# Get the inference options.\n",
    "##################################################\n",
    "log_root = str(root / \"inference/01_08_24_WMH_EnsembleLTS\")\n",
    "dataset_options = {\n",
    "    'log.root': [log_root],\n",
    "    'model.checkpoint': [checkpoint],\n",
    "    'data.preload': [False]\n",
    "}\n",
    "\n",
    "# dataset_options.update(individual_network_args)\n",
    "dataset_options.update(ensemble_network_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the configs.\n",
    "##################################################\n",
    "base_cfg = Config(inference_config).update([model_cfg, metrics_cfg])\n",
    "\n",
    "cfgs = []\n",
    "for cfg_update in dict_product(dataset_options):\n",
    "    new_cfg = base_cfg.update(cfg_update)\n",
    "    check_missing(new_cfg) # Verify there are no ? in config.\n",
    "    cfgs.append(new_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cfgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ese.experiment.experiment import run_ese_exp, submit_ese_exps\n",
    "from ese.experiment.analysis.inference import get_cal_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Run individual jobs\n",
    "run_ese_exp(\n",
    "    config=cfgs[0], \n",
    "    job_func=get_cal_stats,\n",
    "    run_name='debug',\n",
    "    gpu='0',\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ####### Run Batch Jobs\n",
    "# submit_ese_exps(\n",
    "#     exp_root=log_root,\n",
    "#     job_func=get_cal_stats,\n",
    "#     config_list=cfgs,\n",
    "#     available_gpus=['0', '1', '2', '3']\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UniverSegTF",
   "language": "python",
   "name": "universegtf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
