{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/storage/vbutoi/projects')\n",
    "sys.path.append('/storage/vbutoi/libraries')\n",
    "sys.path.append('/storage/vbutoi/projects/ESE')\n",
    "sys.path.append('/storage/vbutoi/projects/UniverSeg')\n",
    "import torch\n",
    "torch.set_printoptions(linewidth=200)\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "import os \n",
    "os.environ['DATAPATH'] = ':'.join((\n",
    "       '/storage/vbutoi/datasets',\n",
    "))\n",
    "\n",
    "# Results loader object does everything\n",
    "from ionpy.analysis import ResultsLoader\n",
    "from pathlib import Path\n",
    "root = Path(\"/storage/vbutoi/scratch/ESE\")\n",
    "rs = ResultsLoader()\n",
    "\n",
    "\n",
    "# For using code without restarting.\n",
    "%load_ext autoreload\n",
    "%autoreload \n",
    "# For using yaml configs.\n",
    "%load_ext yamlmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "872fec4d458a475ba340ba364ea0d157",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_exp_name = \"training/01_03_24_WMH_Ensemble\"\n",
    "\n",
    "dfc = rs.load_configs(\n",
    "    root / training_exp_name,\n",
    "    properties=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            require(\n                [\n                    \"notebook/js/codecell\",\n                    \"codemirror/mode/yaml/yaml\"\n                ],\n                function(cc){\n                    cc.CodeCell.options_default.highlight_modes.magic_yaml = {\n                        reg: [\"^%%yaml\"]\n                    }\n                }\n            );\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%yaml inference_config\n",
    "\n",
    "log:\n",
    "    root: '?'\n",
    "    log_interval: 5\n",
    "    log_image_stats: '?' \n",
    "    log_pixel_stats: '?' \n",
    "    show_examples: '?' \n",
    "    ignore_index: 0 \n",
    "\n",
    "experiment:\n",
    "    seed: 42\n",
    "\n",
    "data:\n",
    "    split: cal \n",
    "    slicing: dense_full \n",
    "    input_type: volume \n",
    "    preload: '?' \n",
    "\n",
    "dataloader:\n",
    "    batch_size: 1 \n",
    "    num_workers: 0\n",
    "    pin_memory: True \n",
    "\n",
    "calibration:\n",
    "    conf_interval_start: 0.5\n",
    "    conf_interval_end: 1.0\n",
    "    num_bins: 10\n",
    "    neighborhood_width: 3\n",
    "    square_diff: False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            require(\n                [\n                    \"notebook/js/codecell\",\n                    \"codemirror/mode/yaml/yaml\"\n                ],\n                function(cc){\n                    cc.CodeCell.options_default.highlight_modes.magic_yaml = {\n                        reg: [\"^%%yaml\"]\n                    }\n                }\n            );\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%yaml model_cfg\n",
    "\n",
    "model:\n",
    "    pretrained_exp_root : '?' \n",
    "    checkpoint: '?' \n",
    "    ensemble: '?' \n",
    "    ensemble_pre_softmax: '?'\n",
    "    ensemble_combine_fn: '?' \n",
    "    pretrained_select_metric: \"val-dice_score\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            require(\n                [\n                    \"notebook/js/codecell\",\n                    \"codemirror/mode/yaml/yaml\"\n                ],\n                function(cc){\n                    cc.CodeCell.options_default.highlight_modes.magic_yaml = {\n                        reg: [\"^%%yaml\"]\n                    }\n                }\n            );\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%yaml metrics_cfg \n",
    "\n",
    "qual_metrics:\n",
    "    - Dice:\n",
    "        _fn: ese.experiment.metrics.dice_score\n",
    "        from_logits: True\n",
    "        batch_reduction: 'mean' \n",
    "        ignore_empty_labels: False # This is a WMH specific setting.\n",
    "        ignore_index: 0 # Ignore background class when reporting.\n",
    "        metric_type: quality\n",
    "    - HD95:\n",
    "        _fn: ese.experiment.metrics.hd95\n",
    "        from_logits: True\n",
    "        batch_reduction: 'mean' \n",
    "        ignore_empty_labels: False # This is a WMH specific setting.\n",
    "        ignore_index: 0 # Ignore background class when reporting.\n",
    "        metric_type: quality\n",
    "\n",
    "cal_metrics:\n",
    "    - ECE:\n",
    "        _fn: ese.experiment.metrics.ece.ece_loss\n",
    "    - Edge_ECE:\n",
    "        _fn: ese.experiment.metrics.ece.edge_ece_loss\n",
    "    - CW_ECE:\n",
    "        _fn: ese.experiment.metrics.ece.cw_ece_loss\n",
    "    - ELM:\n",
    "        _fn: ese.experiment.metrics.elm.elm_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ionpy.util import dict_product, Config\n",
    "from ionpy.util.config import check_missing\n",
    "from ese.scripts.utils import gather_exp_paths\n",
    "\n",
    "def get_ese_inference_configs(\n",
    "        calibrator, \n",
    "        do_ensemble: bool, \n",
    "        log_image_stats: bool,\n",
    "        log_pixel_stats: bool,\n",
    "        group_string: str,\n",
    "        preload: bool = False, \n",
    "        show_examples: bool = False,\n",
    "        ):\n",
    "    # Define the paths for the uncailbrated networks.\n",
    "    ##################################################\n",
    "    if calibrator is None:\n",
    "        calibrator = \"Uncalibrated\"\n",
    "        ensemble_root = \"/storage/vbutoi/scratch/ESE/training/01_08_24_WMH_Ensemble\"\n",
    "        checkpoint = \"max-val-dice_score\" \n",
    "    # Define the paths for the calibrated networks.\n",
    "    ##################################################\n",
    "    else:\n",
    "        ensemble_root = f\"/storage/vbutoi/scratch/ESE/calibration/01_07_24_WMH_Ensemble{calibrator}\"\n",
    "        checkpoint = \"min-val-ece_loss\"\n",
    "\n",
    "    # Set a few things that will be consistent for all runs.\n",
    "    ##################################################\n",
    "    default_config_options = {\n",
    "        'model.checkpoint': [checkpoint],\n",
    "        'data.preload': [preload],\n",
    "        'log.show_examples': [show_examples],\n",
    "        'log.log_image_stats': [log_image_stats],\n",
    "        'log.log_pixel_stats': [log_pixel_stats]\n",
    "    }\n",
    "\n",
    "    exp_root = root / \"inference\" / (group_string)\n",
    "    # Make presets for the different runnning configurations.\n",
    "    ##################################################\n",
    "    # If you want to run inference on ensembles, use this.\n",
    "    if do_ensemble:\n",
    "        advanced_args = {\n",
    "            'log.root': [str(exp_root / \"WMH_Ensemble_{calibrator}\")],\n",
    "            'model.pretrained_exp_root': [ensemble_root],\n",
    "            'model.ensemble': [True],\n",
    "            'model.ensemble_pre_softmax': [True, False],\n",
    "            'model.ensemble_combine_fn': ['mean', 'max'],\n",
    "        }\n",
    "    # If you want to run inference on individual networks, use this.\n",
    "    else:\n",
    "        advanced_args = {\n",
    "            'log.root': [str(exp_root / \"WMH_Individual_{calibrator}\")],\n",
    "            'model.pretrained_exp_root': gather_exp_paths(ensemble_root), # Note this is a list of train exp paths.\n",
    "            'model.ensemble': [False],\n",
    "            'model.ensemble_pre_softmax': [None],\n",
    "            'model.ensemble_combine_fn': [None],\n",
    "        }\n",
    "    # Combine the default and advanced arguments.\n",
    "    default_config_options.update(advanced_args)\n",
    "    log_root = default_config_options['log.root'][0]\n",
    "    return default_config_options, log_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calibrators\n",
    "# None\n",
    "# TempScaling\n",
    "# VectorScaling\n",
    "# DirichletScaling\n",
    "# LTS\n",
    "\n",
    "from datetime import datetime\n",
    "# Get today's date\n",
    "today_date = datetime.now()\n",
    "# Format the date as MM_DD_YY\n",
    "formatted_date = today_date.strftime(\"%m_%d_%y\")\n",
    "\n",
    "# Get the configs for the different runs.\n",
    "dataset_options, log_root = get_ese_inference_configs(\n",
    "    calibrator=None, \n",
    "    do_ensemble=False, \n",
    "    group_string=f\"{formatted_date}_PixelStats\",\n",
    "    log_image_stats=True,\n",
    "    log_pixel_stats=True,\n",
    "    show_examples=False,\n",
    "    preload=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the configs.\n",
    "##################################################\n",
    "base_cfg = Config(inference_config).update([model_cfg, metrics_cfg])\n",
    "\n",
    "cfgs = []\n",
    "for cfg_update in dict_product(dataset_options):\n",
    "    new_cfg = base_cfg.update(cfg_update)\n",
    "    check_missing(new_cfg) # Verify there are no ? in config.\n",
    "    cfgs.append(new_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cfgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ese.experiment.experiment import run_ese_exp, submit_ese_exps\n",
    "from ese.experiment.analysis.inference import get_cal_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set seed: 43\n",
      "Set seed: 42\n",
      "-> Working on slice #0 out of 86 (0.00%)\r"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'cal_metric_cfgs'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m###### Run individual jobs\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mrun_ese_exp\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfgs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjob_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_cal_stats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdebug\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgpu\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m0\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m)\u001b[49m \n",
      "File \u001b[0;32m~/envs/UniverSegTF/lib/python3.9/site-packages/pydantic/decorator.py:40\u001b[0m, in \u001b[0;36mpydantic.decorator.validate_arguments.validate.wrapper_function\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/envs/UniverSegTF/lib/python3.9/site-packages/pydantic/decorator.py:134\u001b[0m, in \u001b[0;36mpydantic.decorator.ValidatedFunction.call\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/envs/UniverSegTF/lib/python3.9/site-packages/pydantic/decorator.py:206\u001b[0m, in \u001b[0;36mpydantic.decorator.ValidatedFunction.execute\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/storage/vbutoi/projects/ESE/ese/experiment/experiment/runner.py:60\u001b[0m, in \u001b[0;36mrun_ese_exp\u001b[0;34m(config, gpu, show_examples, track_wandb, run_name, experiment_class, job_func)\u001b[0m\n\u001b[1;32m     55\u001b[0m     slite\u001b[38;5;241m.\u001b[39mrun_exp(\n\u001b[1;32m     56\u001b[0m         exp_class\u001b[38;5;241m=\u001b[39mexperiment_class,\n\u001b[1;32m     57\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrun_args\n\u001b[1;32m     58\u001b[0m     )\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 60\u001b[0m     \u001b[43mslite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_job\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjob_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjob_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrun_args\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/envs/UniverSegTF/lib/python3.9/site-packages/pydantic/decorator.py:40\u001b[0m, in \u001b[0;36mpydantic.decorator.validate_arguments.validate.wrapper_function\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/envs/UniverSegTF/lib/python3.9/site-packages/pydantic/decorator.py:134\u001b[0m, in \u001b[0;36mpydantic.decorator.ValidatedFunction.call\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/envs/UniverSegTF/lib/python3.9/site-packages/pydantic/decorator.py:206\u001b[0m, in \u001b[0;36mpydantic.decorator.ValidatedFunction.execute\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/storage/vbutoi/projects/ionpy/slite/runner.py:43\u001b[0m, in \u001b[0;36mrun_job\u001b[0;34m(job_func, config, available_gpus)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m available_gpus \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     42\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_VISIBLE_DEVICES\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(available_gpus)\n\u001b[0;32m---> 43\u001b[0m \u001b[43mjob_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/envs/UniverSegTF/lib/python3.9/site-packages/pydantic/decorator.py:40\u001b[0m, in \u001b[0;36mpydantic.decorator.validate_arguments.validate.wrapper_function\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/envs/UniverSegTF/lib/python3.9/site-packages/pydantic/decorator.py:134\u001b[0m, in \u001b[0;36mpydantic.decorator.ValidatedFunction.call\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/envs/UniverSegTF/lib/python3.9/site-packages/pydantic/decorator.py:206\u001b[0m, in \u001b[0;36mpydantic.decorator.ValidatedFunction.execute\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/storage/vbutoi/projects/ESE/ese/experiment/analysis/inference.py:218\u001b[0m, in \u001b[0;36mget_cal_stats\u001b[0;34m(cfg)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWorking on batch #\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m out of\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(dataloader), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{:.2f}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(batch_idx \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(dataloader) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m), end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    217\u001b[0m \u001b[38;5;66;03m# Run the forward loop\u001b[39;00m\n\u001b[0;32m--> 218\u001b[0m \u001b[43mforward_loop_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minference_exp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[43m    \u001b[49m\u001b[43minference_cfg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimage_level_records\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimage_level_records\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpixel_meter_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpixel_meter_dict\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;66;03m# Save the records every so often, to get intermediate results. Note, because of data_ids\u001b[39;00m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;66;03m# this can contain fewer than 'log interval' many items.\u001b[39;00m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_idx \u001b[38;5;241m%\u001b[39m cfg[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlog\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlog_interval\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/envs/UniverSegTF/lib/python3.9/site-packages/pydantic/decorator.py:40\u001b[0m, in \u001b[0;36mpydantic.decorator.validate_arguments.validate.wrapper_function\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/envs/UniverSegTF/lib/python3.9/site-packages/pydantic/decorator.py:134\u001b[0m, in \u001b[0;36mpydantic.decorator.ValidatedFunction.call\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/envs/UniverSegTF/lib/python3.9/site-packages/pydantic/decorator.py:206\u001b[0m, in \u001b[0;36mpydantic.decorator.ValidatedFunction.execute\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/storage/vbutoi/projects/ESE/ese/experiment/analysis/inference.py:281\u001b[0m, in \u001b[0;36mvolume_forward_loop\u001b[0;34m(exp, batch_idx, batch, inference_cfg, image_level_records, pixel_meter_dict)\u001b[0m\n\u001b[1;32m    272\u001b[0m output_dict \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    273\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m\"\u001b[39m: image_cuda,\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mytrue\u001b[39m\u001b[38;5;124m\"\u001b[39m: label_map_cuda\u001b[38;5;241m.\u001b[39mlong(),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mslice_idx\u001b[39m\u001b[38;5;124m\"\u001b[39m: slice_idx \n\u001b[1;32m    279\u001b[0m }\n\u001b[1;32m    280\u001b[0m \u001b[38;5;66;03m# Get the calibration item info.  \u001b[39;00m\n\u001b[0;32m--> 281\u001b[0m \u001b[43mget_calibration_item_info\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_idx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnum_slices\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mslice_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43minference_cfg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minference_cfg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimage_level_records\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimage_level_records\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpixel_meter_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpixel_meter_dict\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/envs/UniverSegTF/lib/python3.9/site-packages/pydantic/decorator.py:40\u001b[0m, in \u001b[0;36mpydantic.decorator.validate_arguments.validate.wrapper_function\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/envs/UniverSegTF/lib/python3.9/site-packages/pydantic/decorator.py:134\u001b[0m, in \u001b[0;36mpydantic.decorator.ValidatedFunction.call\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/envs/UniverSegTF/lib/python3.9/site-packages/pydantic/decorator.py:206\u001b[0m, in \u001b[0;36mpydantic.decorator.ValidatedFunction.execute\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/storage/vbutoi/projects/ESE/ese/experiment/analysis/inference.py:379\u001b[0m, in \u001b[0;36mget_calibration_item_info\u001b[0;34m(data_idx, output_dict, inference_cfg, image_level_records, pixel_meter_dict, ignore_index)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;66;03m# Run a check on the image_level stats for a single image are the same as the pixel level stats.\u001b[39;00m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;66;03m# This is just a sanity check. NOTE: data_idx has a small bug that if the inputs are volumes that \u001b[39;00m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;66;03m# have different numbers of slices, then the data_idx will not be correct but the first will be correct.\u001b[39;00m\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (data_idx \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m (check_image_stats \u001b[38;5;129;01mand\u001b[39;00m check_pixel_stats ): \n\u001b[0;32m--> 379\u001b[0m     \u001b[43mglobal_cal_sanity_check\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m        \u001b[49m\u001b[43minference_cfg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minference_cfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcal_metric_errors_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcal_metric_errors_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpixel_meter_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpixel_meter_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_index\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/storage/vbutoi/projects/ESE/ese/experiment/analysis/inference.py:584\u001b[0m, in \u001b[0;36mglobal_cal_sanity_check\u001b[0;34m(inference_cfg, cal_metric_errors_dict, pixel_meter_dict, ignore_index)\u001b[0m\n\u001b[1;32m    575\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mglobal_cal_sanity_check\u001b[39m(\n\u001b[1;32m    576\u001b[0m         inference_cfg: \u001b[38;5;28mdict\u001b[39m, \n\u001b[1;32m    577\u001b[0m         cal_metric_errors_dict: \u001b[38;5;28mdict\u001b[39m, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[38;5;66;03m# is the same as the image level calibration score (only true when we are working with a single\u001b[39;00m\n\u001b[1;32m    583\u001b[0m     \u001b[38;5;66;03m# image.\u001b[39;00m\n\u001b[0;32m--> 584\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m cal_metric \u001b[38;5;129;01min\u001b[39;00m \u001b[43minference_cfg\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcal_metric_cfgs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m:\n\u001b[1;32m    585\u001b[0m         \u001b[38;5;66;03m# Get the calibration error. \u001b[39;00m\n\u001b[1;32m    586\u001b[0m         cal_met_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(cal_metric\u001b[38;5;241m.\u001b[39mkeys())[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    587\u001b[0m         image_level_cal_score \u001b[38;5;241m=\u001b[39m cal_metric_errors_dict[cal_met_name]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'cal_metric_cfgs'"
     ]
    }
   ],
   "source": [
    "###### Run individual jobs\n",
    "run_ese_exp(\n",
    "    config=cfgs[0], \n",
    "    job_func=get_cal_stats,\n",
    "    run_name='debug',\n",
    "    gpu='0',\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ####### Run Batch Jobs\n",
    "# submit_ese_exps(\n",
    "#     exp_root=log_root,\n",
    "#     job_func=get_cal_stats,\n",
    "#     config_list=cfgs,\n",
    "#     available_gpus=['0', '1', '2', '3']\n",
    "#     # available_gpus=['4', '5', '6', '7']\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UniverSegTF",
   "language": "python",
   "name": "universegtf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
