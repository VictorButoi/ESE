{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/storage/vbutoi/projects')\n",
    "sys.path.append('/storage/vbutoi/libraries')\n",
    "sys.path.append('/storage/vbutoi/projects/ESE')\n",
    "sys.path.append('/storage/vbutoi/projects/UniverSeg')\n",
    "import torch\n",
    "torch.set_printoptions(linewidth=200)\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "import os \n",
    "os.environ['DATAPATH'] = ':'.join((\n",
    "       '/storage/vbutoi/datasets',\n",
    "))\n",
    "\n",
    "# Results loader object does everything\n",
    "from ionpy.analysis import ResultsLoader\n",
    "from pathlib import Path\n",
    "root = Path(\"/storage/vbutoi/scratch/ESE\")\n",
    "rs = ResultsLoader()\n",
    "\n",
    "# For using code without restarting.\n",
    "%load_ext autoreload\n",
    "%autoreload \n",
    "# For using yaml configs.\n",
    "%load_ext yamlmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_exp_name = \"training/10_23_23_Dense_WMH\"\n",
    "\n",
    "dfc = rs.load_configs(\n",
    "    root / training_exp_name,\n",
    "    properties=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%yaml inference_config\n",
    "\n",
    "log:\n",
    "    root: '?'\n",
    "    log_interval: 50\n",
    "    track_image_level: True\n",
    "    track_pixel_level: True \n",
    "\n",
    "model:\n",
    "    exp_root : '?'\n",
    "    num_workers: 1  \n",
    "\n",
    "dataset:\n",
    "    split: '?' \n",
    "    slicing: dense_full \n",
    "    input_type: volume \n",
    "\n",
    "calibration:\n",
    "    binarize: True\n",
    "    conf_interval_start: 0.5\n",
    "    conf_interval_end: 1.0\n",
    "    num_bins: 10\n",
    "    neighborhood_width: 3\n",
    "    square_diff: True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%yaml cal_metrics_cfg \n",
    "\n",
    "cal_metrics:\n",
    "    - ECE:\n",
    "        func: ese.experiment.metrics.ECE\n",
    "    - TL_ECE:\n",
    "        func: ese.experiment.metrics.TL_ECE\n",
    "    - CW_ECE:\n",
    "        func: ese.experiment.metrics.CW_ECE\n",
    "    - LoMS:\n",
    "        func: ese.experiment.metrics.LoMS\n",
    "    - TL_LoMS:\n",
    "        func: ese.experiment.metrics.TL_LoMS\n",
    "    - CW_LoMS:\n",
    "        func: ese.experiment.metrics.CW_LoMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ionpy.util import dict_product, Config\n",
    "\n",
    "# Need to define the experiment name\n",
    "inference_exp_root = str(root / \"inference/12_06_23_WMH_Debug\")\n",
    "\n",
    "# Get the inference options.\n",
    "##################################################\n",
    "dataset_options = {\n",
    "    'log.root': [inference_exp_root],\n",
    "    'model.exp_root': [str(root / training_exp_name)],\n",
    "    'dataset.split': ['cal'],\n",
    "}\n",
    "\n",
    "base_cfg = Config(inference_config).update(cal_metrics_cfg)\n",
    "\n",
    "cfgs = []\n",
    "for cfg_update in dict_product(dataset_options):\n",
    "    new_cfg = base_cfg.update(cfg_update)\n",
    "    cfgs.append(new_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ese.experiment.analysis.inference import get_cal_stats\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "\n",
    "get_cal_stats(cfgs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ionpy.slite.submit import submit_jobs\n",
    "# from ese.experiment.analysis.inference import get_cal_stats\n",
    "\n",
    "# submit_jobs(\n",
    "#     exp_root=inference_exp_root,\n",
    "#     config_list=cfgs, \n",
    "#     job_func=get_cal_stats,\n",
    "#     available_gpus=[\"0\"]\n",
    "#     )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UniverSegTF",
   "language": "python",
   "name": "universegtf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
