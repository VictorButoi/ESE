{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/storage/vbutoi/projects')\n",
    "sys.path.append('/storage/vbutoi/libraries')\n",
    "sys.path.append('/storage/vbutoi/projects/ESE')\n",
    "sys.path.append('/storage/vbutoi/projects/UniverSeg')\n",
    "import torch\n",
    "torch.set_printoptions(linewidth=200)\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "import os \n",
    "os.environ['DATAPATH'] = ':'.join((\n",
    "       '/storage/vbutoi/datasets',\n",
    "))\n",
    "\n",
    "# Results loader object does everything\n",
    "from ionpy.analysis import ResultsLoader\n",
    "from pathlib import Path\n",
    "root = Path(\"/storage/vbutoi/scratch/ESE\")\n",
    "rs = ResultsLoader()\n",
    "\n",
    "from datetime import datetime\n",
    "# Get today's date\n",
    "today_date = datetime.now()\n",
    "# Format the date as MM_DD_YY\n",
    "formatted_date = today_date.strftime(\"%m_%d_%y\")\n",
    "\n",
    "# For using code without restarting.\n",
    "%load_ext autoreload\n",
    "%autoreload \n",
    "# For using yaml configs.\n",
    "%load_ext yamlmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "104a74d1f03e4832b9522f8bc667fc0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_exp_name = \"training/01_03_24_WMH_Ensemble\"\n",
    "\n",
    "dfc = rs.load_configs(\n",
    "    root / training_exp_name,\n",
    "    properties=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            require(\n                [\n                    \"notebook/js/codecell\",\n                    \"codemirror/mode/yaml/yaml\"\n                ],\n                function(cc){\n                    cc.CodeCell.options_default.highlight_modes.magic_yaml = {\n                        reg: [\"^%%yaml\"]\n                    }\n                }\n            );\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%yaml inference_config\n",
    "\n",
    "log:\n",
    "    root: '?'\n",
    "    log_interval: 5\n",
    "    log_image_stats: True \n",
    "    log_pixel_stats: False \n",
    "    show_examples: '?' \n",
    "    ignore_index: 0 \n",
    "\n",
    "experiment:\n",
    "    seed: 42\n",
    "\n",
    "data:\n",
    "    split: cal \n",
    "    slicing: dense_full \n",
    "    input_type: volume \n",
    "    preload: '?' \n",
    "\n",
    "dataloader:\n",
    "    batch_size: 1 \n",
    "    num_workers: 0\n",
    "    pin_memory: True \n",
    "\n",
    "calibration:\n",
    "    conf_interval_start: 0.5\n",
    "    conf_interval_end: 1.0\n",
    "    num_bins: 10\n",
    "    neighborhood_width: 3\n",
    "    square_diff: False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            require(\n                [\n                    \"notebook/js/codecell\",\n                    \"codemirror/mode/yaml/yaml\"\n                ],\n                function(cc){\n                    cc.CodeCell.options_default.highlight_modes.magic_yaml = {\n                        reg: [\"^%%yaml\"]\n                    }\n                }\n            );\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%yaml model_cfg\n",
    "\n",
    "model:\n",
    "    pretrained_exp_root : '?' \n",
    "    checkpoint: '?' \n",
    "    ensemble: '?' \n",
    "    ensemble_pre_softmax: '?'\n",
    "    ensemble_combine_fn: '?' \n",
    "    pretrained_select_metric: \"val-dice_score\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            require(\n                [\n                    \"notebook/js/codecell\",\n                    \"codemirror/mode/yaml/yaml\"\n                ],\n                function(cc){\n                    cc.CodeCell.options_default.highlight_modes.magic_yaml = {\n                        reg: [\"^%%yaml\"]\n                    }\n                }\n            );\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%yaml metrics_cfg \n",
    "\n",
    "qual_metrics:\n",
    "    # - Edge_ECE:\n",
    "    #     _fn: ese.experiment.metrics.ece.edge_ece_loss\n",
    "    #     metric_type: calibration\n",
    "    # - ECW_ECE:\n",
    "    #     _fn: ese.experiment.metrics.ece.ecw_ece_loss\n",
    "    #     metric_type: calibration\n",
    "    - Dice:\n",
    "        _fn: ese.experiment.metrics.dice_score\n",
    "        from_logits: True\n",
    "        batch_reduction: 'mean' \n",
    "        ignore_empty_labels: False # This is a WMH specific setting.\n",
    "        ignore_index: 0 # Ignore background class when reporting.\n",
    "        metric_type: quality\n",
    "    - HD95:\n",
    "        _fn: ese.experiment.metrics.hd95\n",
    "        from_logits: True\n",
    "        batch_reduction: 'mean' \n",
    "        ignore_empty_labels: False # This is a WMH specific setting.\n",
    "        ignore_index: 0 # Ignore background class when reporting.\n",
    "        metric_type: quality\n",
    "\n",
    "\n",
    "# cal_metrics:\n",
    "#     - ECE:\n",
    "#         _fn: ese.experiment.metrics.ece.ece_loss\n",
    "#     - CW_ECE:\n",
    "#         _fn: ese.experiment.metrics.ece.cw_ece_loss\n",
    "#     - ELM:\n",
    "#         _fn: ese.experiment.metrics.elm.elm_loss\n",
    "#     - CW_ELM:\n",
    "#         _fn: ese.experiment.metrics.elm.cw_elm_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ionpy.util import dict_product, Config\n",
    "from ionpy.util.config import check_missing\n",
    "from ese.scripts.utils import gather_exp_paths\n",
    "\n",
    "def get_ese_inference_configs(\n",
    "        calibrator, \n",
    "        do_ensemble, \n",
    "        add_string=\"\",\n",
    "        preload=False, \n",
    "        show_examples=False\n",
    "        ):\n",
    "    # Define the paths for the uncailbrated networks.\n",
    "    ##################################################\n",
    "    if calibrator is None:\n",
    "        calibrator = \"Uncalibrated\"\n",
    "        ensemble_root = \"/storage/vbutoi/scratch/ESE/training/01_08_24_WMH_Ensemble\"\n",
    "        checkpoint = \"max-val-dice_score\" \n",
    "    # Define the paths for the calibrated networks.\n",
    "    ##################################################\n",
    "    else:\n",
    "        ensemble_root = f\"/storage/vbutoi/scratch/ESE/calibration/01_07_24_WMH_Ensemble{calibrator}\"\n",
    "        checkpoint = \"min-val-ece_loss\"\n",
    "\n",
    "    # Set a few things that will be consistent for all runs.\n",
    "    ##################################################\n",
    "    default_config_options = {\n",
    "        'model.checkpoint': [checkpoint],\n",
    "        'data.preload': [preload],\n",
    "        'log.show_examples': [show_examples],\n",
    "    }\n",
    "\n",
    "    # Make presets for the different runnning configurations.\n",
    "    ##################################################\n",
    "    # If you want to run inference on ensembles, use this.\n",
    "    if do_ensemble:\n",
    "        advanced_args = {\n",
    "            'log.root': [str(root / f\"inference/{formatted_date}{add_string}/WMH_Ensemble_{calibrator}\")],\n",
    "            'model.pretrained_exp_root': [ensemble_root],\n",
    "            'model.ensemble': [True],\n",
    "            'model.ensemble_pre_softmax': [True, False],\n",
    "            'model.ensemble_combine_fn': ['mean', 'max'],\n",
    "        }\n",
    "    # If you want to run inference on individual networks, use this.\n",
    "    else:\n",
    "        advanced_args = {\n",
    "            'log.root': [str(root / f\"inference/{formatted_date}{add_string}/WMH_Individual_{calibrator}\")],\n",
    "            'model.pretrained_exp_root': gather_exp_paths(ensemble_root), # Note this is a list of train exp paths.\n",
    "            'model.ensemble': [False],\n",
    "            'model.ensemble_pre_softmax': [None],\n",
    "            'model.ensemble_combine_fn': [None],\n",
    "        }\n",
    "    # Combine the default and advanced arguments.\n",
    "    default_config_options.update(advanced_args)\n",
    "    log_root = default_config_options['log.root'][0]\n",
    "    return default_config_options, log_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calibrators\n",
    "# None\n",
    "# TempScaling\n",
    "# VectorScaling\n",
    "# DirichletScaling\n",
    "# LTS\n",
    "# Get the configs for the different runs.\n",
    "dataset_options, log_root = get_ese_inference_configs(\n",
    "    calibrator='LTS', \n",
    "    do_ensemble=True, \n",
    "    add_string=\"_wLabAmounts\",\n",
    "    preload=False,\n",
    "    show_examples=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the configs.\n",
    "##################################################\n",
    "base_cfg = Config(inference_config).update([model_cfg, metrics_cfg])\n",
    "\n",
    "cfgs = []\n",
    "for cfg_update in dict_product(dataset_options):\n",
    "    new_cfg = base_cfg.update(cfg_update)\n",
    "    check_missing(new_cfg) # Verify there are no ? in config.\n",
    "    cfgs.append(new_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cfgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ese.experiment.experiment import run_ese_exp, submit_ese_exps\n",
    "from ese.experiment.analysis.inference import get_cal_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set seed: 42\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ed88fb213a2454c85956f0a4cfb4ed1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set seed: 42\n",
      "Set seed: 42\n",
      "Set seed: 40\n",
      "Set seed: 40\n",
      "Set seed: 43\n",
      "Set seed: 43\n",
      "Set seed: 41\n",
      "Set seed: 41\n",
      "Set seed: 42\n",
      "-> Working on slice #0 out of 86 (0.00%)\r"
     ]
    },
    {
     "ename": "EinopsError",
     "evalue": " Error while processing rearrange-reduction pattern \"b h w -> b 1 h w\".\n Input tensor shape: torch.Size([1, 2, 256, 256]). Additional info: {}.\n Expected 3 dimensions, got 4",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEinopsError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m~/envs/UniverSegTF/lib/python3.9/site-packages/einops/einops.py:412\u001b[0m, in \u001b[0;36mreduce\u001b[0;34m(tensor, pattern, reduction, **axes_lengths)\u001b[0m\n\u001b[1;32m    411\u001b[0m     recipe \u001b[38;5;241m=\u001b[39m _prepare_transformation_recipe(pattern, reduction, axes_lengths\u001b[38;5;241m=\u001b[39mhashable_axes_lengths)\n\u001b[0;32m--> 412\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_apply_recipe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecipe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m EinopsError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/envs/UniverSegTF/lib/python3.9/site-packages/einops/einops.py:235\u001b[0m, in \u001b[0;36m_apply_recipe\u001b[0;34m(recipe, tensor, reduction_type)\u001b[0m\n\u001b[1;32m    233\u001b[0m backend \u001b[38;5;241m=\u001b[39m get_backend(tensor)\n\u001b[1;32m    234\u001b[0m init_shapes, reduced_axes, axes_reordering, added_axes, final_shapes \u001b[38;5;241m=\u001b[39m \\\n\u001b[0;32m--> 235\u001b[0m     \u001b[43m_reconstruct_from_shape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecipe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    236\u001b[0m tensor \u001b[38;5;241m=\u001b[39m backend\u001b[38;5;241m.\u001b[39mreshape(tensor, init_shapes)\n",
      "File \u001b[0;32m~/envs/UniverSegTF/lib/python3.9/site-packages/einops/einops.py:165\u001b[0m, in \u001b[0;36m_reconstruct_from_shape_uncached\u001b[0;34m(self, shape)\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(shape) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_composite_axes):\n\u001b[0;32m--> 165\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m EinopsError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m dimensions, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_composite_axes), \u001b[38;5;28mlen\u001b[39m(shape)))\n\u001b[1;32m    167\u001b[0m ellipsis_shape: List[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mEinopsError\u001b[0m: Expected 3 dimensions, got 4",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mEinopsError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m###### Run individual jobs\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mrun_ese_exp\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfgs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjob_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_cal_stats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdebug\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgpu\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m0\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m)\u001b[49m \n",
      "File \u001b[0;32m~/envs/UniverSegTF/lib/python3.9/site-packages/pydantic/decorator.py:40\u001b[0m, in \u001b[0;36mpydantic.decorator.validate_arguments.validate.wrapper_function\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/envs/UniverSegTF/lib/python3.9/site-packages/pydantic/decorator.py:134\u001b[0m, in \u001b[0;36mpydantic.decorator.ValidatedFunction.call\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/envs/UniverSegTF/lib/python3.9/site-packages/pydantic/decorator.py:206\u001b[0m, in \u001b[0;36mpydantic.decorator.ValidatedFunction.execute\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/storage/vbutoi/projects/ESE/ese/experiment/experiment/runner.py:60\u001b[0m, in \u001b[0;36mrun_ese_exp\u001b[0;34m(config, gpu, show_examples, track_wandb, run_name, experiment_class, job_func)\u001b[0m\n\u001b[1;32m     55\u001b[0m     slite\u001b[38;5;241m.\u001b[39mrun_exp(\n\u001b[1;32m     56\u001b[0m         exp_class\u001b[38;5;241m=\u001b[39mexperiment_class,\n\u001b[1;32m     57\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrun_args\n\u001b[1;32m     58\u001b[0m     )\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 60\u001b[0m     \u001b[43mslite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_job\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjob_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjob_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrun_args\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/envs/UniverSegTF/lib/python3.9/site-packages/pydantic/decorator.py:40\u001b[0m, in \u001b[0;36mpydantic.decorator.validate_arguments.validate.wrapper_function\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/envs/UniverSegTF/lib/python3.9/site-packages/pydantic/decorator.py:134\u001b[0m, in \u001b[0;36mpydantic.decorator.ValidatedFunction.call\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/envs/UniverSegTF/lib/python3.9/site-packages/pydantic/decorator.py:206\u001b[0m, in \u001b[0;36mpydantic.decorator.ValidatedFunction.execute\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/storage/vbutoi/projects/ionpy/slite/runner.py:41\u001b[0m, in \u001b[0;36mrun_job\u001b[0;34m(job_func, config, available_gpus)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# Set the visible gpu.\u001b[39;00m\n\u001b[1;32m     40\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_VISIBLE_DEVICES\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(available_gpus)\n\u001b[0;32m---> 41\u001b[0m \u001b[43mjob_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/envs/UniverSegTF/lib/python3.9/site-packages/pydantic/decorator.py:40\u001b[0m, in \u001b[0;36mpydantic.decorator.validate_arguments.validate.wrapper_function\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/envs/UniverSegTF/lib/python3.9/site-packages/pydantic/decorator.py:134\u001b[0m, in \u001b[0;36mpydantic.decorator.ValidatedFunction.call\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/envs/UniverSegTF/lib/python3.9/site-packages/pydantic/decorator.py:206\u001b[0m, in \u001b[0;36mpydantic.decorator.ValidatedFunction.execute\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/storage/vbutoi/projects/ESE/ese/experiment/analysis/inference.py:217\u001b[0m, in \u001b[0;36mget_cal_stats\u001b[0;34m(cfg)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWorking on batch #\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m out of\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(dataloader), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{:.2f}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(batch_idx \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(dataloader) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m), end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    216\u001b[0m \u001b[38;5;66;03m# Run the forward loop\u001b[39;00m\n\u001b[0;32m--> 217\u001b[0m \u001b[43mforward_loop_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minference_exp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[43m    \u001b[49m\u001b[43minference_cfg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimage_level_records\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimage_level_records\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpixel_meter_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpixel_meter_dict\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;66;03m# Save the records every so often, to get intermediate results. Note, because of data_ids\u001b[39;00m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;66;03m# this can contain fewer than 'log interval' many items.\u001b[39;00m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_idx \u001b[38;5;241m%\u001b[39m cfg[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlog\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlog_interval\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/envs/UniverSegTF/lib/python3.9/site-packages/pydantic/decorator.py:40\u001b[0m, in \u001b[0;36mpydantic.decorator.validate_arguments.validate.wrapper_function\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/envs/UniverSegTF/lib/python3.9/site-packages/pydantic/decorator.py:134\u001b[0m, in \u001b[0;36mpydantic.decorator.ValidatedFunction.call\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/envs/UniverSegTF/lib/python3.9/site-packages/pydantic/decorator.py:206\u001b[0m, in \u001b[0;36mpydantic.decorator.ValidatedFunction.execute\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/storage/vbutoi/projects/ESE/ese/experiment/analysis/inference.py:265\u001b[0m, in \u001b[0;36mvolume_forward_loop\u001b[0;34m(exp, batch_idx, batch, inference_cfg, image_level_records, pixel_meter_dict)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# Get the prediction and don't track gradients.\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 265\u001b[0m     exp_output \u001b[38;5;241m=\u001b[39m \u001b[43mexp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_cuda\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpredict_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# Wrap the outputs into a dictionary.\u001b[39;00m\n\u001b[1;32m    267\u001b[0m output_dict \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    268\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m\"\u001b[39m: image_cuda,\n\u001b[1;32m    269\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mytrue\u001b[39m\u001b[38;5;124m\"\u001b[39m: label_map_cuda\u001b[38;5;241m.\u001b[39mlong(),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    273\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mslice_idx\u001b[39m\u001b[38;5;124m\"\u001b[39m: slice_idx \n\u001b[1;32m    274\u001b[0m }\n",
      "File \u001b[0;32m/storage/vbutoi/projects/ESE/ese/experiment/experiment/ensemble_exp.py:149\u001b[0m, in \u001b[0;36mEnsembleInferenceExperiment.predict\u001b[0;34m(self, x, multi_class, threshold, combine_fn)\u001b[0m\n\u001b[1;32m    144\u001b[0m prob_map \u001b[38;5;241m=\u001b[39m combine_fn(\n\u001b[1;32m    145\u001b[0m     ensemble_model_outputs, \n\u001b[1;32m    146\u001b[0m     pre_softmax\u001b[38;5;241m=\u001b[39mmodel_cfg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensemble_pre_softmax\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    147\u001b[0m     )\n\u001b[1;32m    148\u001b[0m \u001b[38;5;66;03m# Get the hard prediction and probabilities\u001b[39;00m\n\u001b[0;32m--> 149\u001b[0m prob_map, pred_map \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_pred_map\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprob_map\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmulti_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmulti_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[43m    \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthreshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfrom_logits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# The combine_fn already returns probs.\u001b[39;49;00m\n\u001b[1;32m    154\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;66;03m# Return the outputs\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mypred\u001b[39m\u001b[38;5;124m'\u001b[39m: prob_map, \n\u001b[1;32m    158\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124myhard\u001b[39m\u001b[38;5;124m'\u001b[39m: pred_map \n\u001b[1;32m    159\u001b[0m }\n",
      "File \u001b[0;32m~/envs/UniverSegTF/lib/python3.9/site-packages/pydantic/decorator.py:40\u001b[0m, in \u001b[0;36mpydantic.decorator.validate_arguments.validate.wrapper_function\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/envs/UniverSegTF/lib/python3.9/site-packages/pydantic/decorator.py:134\u001b[0m, in \u001b[0;36mpydantic.decorator.ValidatedFunction.call\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/envs/UniverSegTF/lib/python3.9/site-packages/pydantic/decorator.py:206\u001b[0m, in \u001b[0;36mpydantic.decorator.ValidatedFunction.execute\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/storage/vbutoi/projects/ESE/ese/experiment/experiment/utils.py:33\u001b[0m, in \u001b[0;36mprocess_pred_map\u001b[0;34m(conf_map, multi_class, threshold, from_logits, return_logits)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;66;03m# Add back the channel dimension (1)\u001b[39;00m\n\u001b[1;32m     32\u001b[0m     pred_map \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(conf_map, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 33\u001b[0m     pred_map \u001b[38;5;241m=\u001b[39m \u001b[43meinops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrearrange\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred_map\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mb h w -> b 1 h w\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;66;03m# Get the prediction\u001b[39;00m\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m from_logits:\n",
      "File \u001b[0;32m~/envs/UniverSegTF/lib/python3.9/site-packages/einops/einops.py:483\u001b[0m, in \u001b[0;36mrearrange\u001b[0;34m(tensor, pattern, **axes_lengths)\u001b[0m\n\u001b[1;32m    481\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRearrange can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt be applied to an empty list\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    482\u001b[0m     tensor \u001b[38;5;241m=\u001b[39m get_backend(tensor[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mstack_on_zeroth_dimension(tensor)\n\u001b[0;32m--> 483\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrearrange\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43maxes_lengths\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/envs/UniverSegTF/lib/python3.9/site-packages/einops/einops.py:420\u001b[0m, in \u001b[0;36mreduce\u001b[0;34m(tensor, pattern, reduction, **axes_lengths)\u001b[0m\n\u001b[1;32m    418\u001b[0m     message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m Input is list. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    419\u001b[0m message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAdditional info: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(axes_lengths)\n\u001b[0;32m--> 420\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m EinopsError(message \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(e))\n",
      "\u001b[0;31mEinopsError\u001b[0m:  Error while processing rearrange-reduction pattern \"b h w -> b 1 h w\".\n Input tensor shape: torch.Size([1, 2, 256, 256]). Additional info: {}.\n Expected 3 dimensions, got 4"
     ]
    }
   ],
   "source": [
    "###### Run individual jobs\n",
    "run_ese_exp(\n",
    "    config=cfgs[0], \n",
    "    job_func=get_cal_stats,\n",
    "    run_name='debug',\n",
    "    gpu='0',\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ####### Run Batch Jobs\n",
    "# submit_ese_exps(\n",
    "#     exp_root=log_root,\n",
    "#     job_func=get_cal_stats,\n",
    "#     config_list=cfgs,\n",
    "#     available_gpus=['0', '1', '2', '3']\n",
    "#     # available_gpus=['4', '5', '6', '7']\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
