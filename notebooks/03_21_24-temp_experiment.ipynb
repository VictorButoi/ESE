{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/storage/vbutoi/projects')\n",
    "sys.path.append('/storage/vbutoi/libraries')\n",
    "sys.path.append('/storage/vbutoi/projects/ESE')\n",
    "sys.path.append('/storage/vbutoi/projects/UniverSeg')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.set_context(\"talk\")\n",
    "\n",
    "import os \n",
    "os.environ['DATAPATH'] = ':'.join((\n",
    "       '/storage/vbutoi/datasets',\n",
    "))\n",
    "\n",
    "# Results loader object does everything\n",
    "from ionpy.analysis import ResultsLoader\n",
    "from pathlib import Path\n",
    "root = Path(\"/storage/vbutoi/scratch/ESE\")\n",
    "rs = ResultsLoader()\n",
    "\n",
    "# For using code without restarting.\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# For using yaml configs.\n",
    "%load_ext yamlmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%yaml results_cfg \n",
    "\n",
    "log:\n",
    "    root: /storage/vbutoi/scratch/ESE/inference\n",
    "    inference_groups: \n",
    "        - \"03_21_24_RandomCircles_TET_pt2\"\n",
    "    \n",
    "calibration:\n",
    "    metric_cfg_file: \"/storage/vbutoi/projects/ESE/ese/experiment/configs/inference/Calibration_Metrics.yaml\"\n",
    "\n",
    "options:\n",
    "    add_baseline_rows: False \n",
    "    load_pixel_meters: False \n",
    "    add_dice_loss_rows: True\n",
    "    drop_nan_metric_rows: True \n",
    "    load_groupavg_metrics: False\n",
    "    remove_shared_columns: False\n",
    "    equal_rows_per_cfg_assert: True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ese.experiment.analysis.analyze_inf import load_cal_inference_stats\n",
    "\n",
    "image_info_df = load_cal_inference_stats(\n",
    "    results_cfg=results_cfg,\n",
    "    load_cached=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_info_df['ensemble.member_temps'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "def temp_1(member_temps):\n",
    "    return ast.literal_eval(member_temps)[0]\n",
    "\n",
    "\n",
    "def temp_2(member_temps):\n",
    "    return ast.literal_eval(member_temps)[1]\n",
    "\n",
    "image_info_df.augment(temp_1)\n",
    "image_info_df.augment(temp_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only the rows corresponding to group methods\n",
    "image_info_df = image_info_df[image_info_df['model_type'] == 'group']\n",
    "\n",
    "image_info_df['method_name'] = image_info_df['method_name'].astype('category')\n",
    "image_info_df['method_name'] = image_info_df['method_name'].cat.reorder_categories([\n",
    "    'Ensemble (mean, probs)', \n",
    "])\n",
    "\n",
    "image_info_df['split'] = image_info_df['split'].astype('category')\n",
    "image_info_df['split'] = image_info_df['split'].cat.reorder_categories([\n",
    "    'val',\n",
    "    'cal'\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's looks at how the dice score varies as a function of the two temperatures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_by_config(in_df):\n",
    "    grouped_df = in_df.groupby([\n",
    "        'ensemble_hash',\n",
    "        'method_name',\n",
    "        'calibrator',\n",
    "        'split',\n",
    "        'member_temps',\n",
    "        'temp_1',\n",
    "        'temp_2',\n",
    "        'num_ensemble_members',\n",
    "    ])\n",
    "    # Mean over the metric_score columns\n",
    "    meaned_groups =  grouped_df.agg({'metric_score': 'mean'}).reset_index()\n",
    "    # Drop the NaN rows\n",
    "    grouped_cfg = meaned_groups.dropna().reset_index(drop=True)\n",
    "    return grouped_cfg\n",
    "\n",
    "val_dice_metric_df = group_by_config(image_info_df.select(\n",
    "    image_metric='Dice',\n",
    "    split='val'\n",
    "))\n",
    "\n",
    "cal_dice_metric_df = group_by_config(image_info_df.select(\n",
    "    image_metric='Dice',\n",
    "    split='cal'\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pivot_df = val_dice_metric_df.pivot_table(\n",
    "    index='temp_1',\n",
    "    columns='temp_2',\n",
    "    values='metric_score',\n",
    "    aggfunc='mean'\n",
    ")\n",
    "\n",
    "cal_pivot_df = cal_dice_metric_df.pivot_table(\n",
    "    index='temp_1',\n",
    "    columns='temp_2',\n",
    "    values='metric_score',\n",
    "    aggfunc='mean'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 12))  # Adjust the size of the figure as desired\n",
    "\n",
    "g = sns.heatmap(\n",
    "    data=val_pivot_df,\n",
    "    annot=True,\n",
    "    cmap='coolwarm',\n",
    "    fmt='.3f'\n",
    ")\n",
    "\n",
    "g.set_title('Validation Split Dice Score vs Temp 1 vs Temp 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 12))  # Adjust the size of the figure as desired\n",
    "\n",
    "g = sns.heatmap(\n",
    "    data=cal_pivot_df,\n",
    "    annot=True,\n",
    "    cmap='coolwarm',\n",
    "    fmt='.3f'\n",
    ")\n",
    "\n",
    "g.set_title('Calibration Split Dice Score vs Temp 1 vs Temp 2')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UniverSegTF",
   "language": "python",
   "name": "universegtf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
